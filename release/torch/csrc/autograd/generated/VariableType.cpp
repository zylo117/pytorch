#include "VariableType.h"

// generated from tools/autograd/templates/VariableType.cpp

#include "torch/csrc/autograd/variable.h"
#include "torch/csrc/autograd/function.h"
#include "torch/csrc/autograd/edge.h"
#include "torch/csrc/autograd/grad_mode.h"
#include "torch/csrc/autograd/saved_variable.h"
#include "torch/csrc/autograd/generated/Functions.h"
#include "torch/csrc/autograd/functions/tensor.h"
#include "torch/csrc/autograd/functions/basic_ops.h"
#include "torch/csrc/jit/tracer.h"
#include "torch/csrc/jit/symbolic_variable.h"
#include "torch/csrc/jit/tensor_conversions.h"
#include "torch/csrc/utils/variadic.h"

#include <initializer_list>
#include <iostream>
#include <functional>
#include <cstddef>

#ifdef _MSC_VER
#ifdef Type
#undef Type
#endif
#endif

using namespace at;
using namespace torch::autograd::generated;

namespace torch { namespace autograd {
// Helper methods for working with Attributes (torch/csrc/jit/attributes.h)

// The overloaded accessors are convenient for the generated code (since we
// don't want to make the codegen do the dispatch manually)
static void setattr(jit::Node* n, jit::Symbol name, int64_t v)             { n->i_(name, v); }
static void setattr(jit::Node* n, jit::Symbol name, const at::Scalar& v)   { n->t_(name, v.toTensor()); }
static void setattr(jit::Node* n, jit::Symbol name, SparseTensor s)        { n->t_(name, s.tref); }
static void setattr(jit::Node* n, jit::Symbol name, const at::IntList& v)  { n->is_(name, v); }
static void setattr(jit::Node* n, jit::Symbol name, bool v)                { n->i_(name, v); }
static void setattr(jit::Node* n, jit::Symbol name, double v)              { n->f_(name, v); }
static void setattr(jit::Node* n, jit::Symbol name, std::string v)         { n->s_(name, v); }
template<std::size_t N>
static void setattr(jit::Node* n, jit::Symbol name, std::array<bool, N> v) { n->is_(name, std::vector<int64_t>(v.begin(), v.end())); }

template<typename T>
static jit::Value* createConstant(jit::Node* n, T value) {
  return n->owningGraph()->createConstant(jit::as_tensor(value))->insertBefore(n)->output();
}

template<typename T>
static void genericInsertInput(jit::Node* n, size_t idx, T value) {
  n->insertInput(idx, createConstant(n, value));
}

void failPositionalAttr() {
  throw std::runtime_error("unsupported type in setposattr. File a bug report!");
}

static void setposattr(jit::Node* n, size_t idx, const char *name, int64_t v)             { genericInsertInput(n, idx, v); }
static void setposattr(jit::Node* n, size_t idx, const char *name, const at::Scalar& v)   { genericInsertInput(n, idx, v); }
static void setposattr(jit::Node* n, size_t idx, const char *name, SparseTensor s)        { failPositionalAttr(); }
static void setposattr(jit::Node* n, size_t idx, const char *name, const at::IntList& v)  {
  using ArgumentStash = jit::tracer::ArgumentStash;
  if (ArgumentStash::hasIntList(name)) {
    auto info = ArgumentStash::popIntList(name);
    for (size_t i = 0; i < info.size(); ++i) {
      if (info[i] != nullptr) continue;
      info[i] = createConstant(n, v[i]);
    }
    jit::TensorType expected_type {at::kLong, -1, {}};
    for (jit::Value* v : info) {
      if (*v->type() != expected_type) {
        throw std::runtime_error(
          "Type mismatch in setposattr for IntList. Check that your program "
          "is valid without tracing, and please file a bug report if it is.");
      }
    }
    jit::WithInsertPoint insert_point{n};
    auto symbolic_info = fmap<jit::SymbolicVariable>(info);
    auto size = jit::SymbolicVariable::stack(symbolic_info, 0);
    n->insertInput(idx, size);
  } else {
    return genericInsertInput(n, idx, v);
  }
}
static void setposattr(jit::Node* n, size_t idx, const char *name, bool v)                { genericInsertInput(n, idx, v); }
static void setposattr(jit::Node* n, size_t idx, const char *name, double v)              { genericInsertInput(n, idx, v); }
template<std::size_t N>
static void setposattr(jit::Node* n, size_t idx, const char *name, std::array<bool, N> v) { failPositionalAttr(); }

VariableType::VariableType(Context* context, Type* baseType)
  : Type(context, /*is_variable_or_undefined=*/true)
  , baseType(baseType) {
  str = std::string("Variable[") + baseType->toString() + "]";
}

ScalarType VariableType::scalarType() const {
  return baseType->scalarType();
}
Backend VariableType::backend() const {
  return baseType->backend();
}
bool VariableType::is_cuda() const { return baseType->is_cuda(); }
bool VariableType::is_sparse() const { return baseType->is_sparse(); }
bool VariableType::is_distributed() const { return baseType->is_distributed(); }

std::unique_ptr<Storage> VariableType::storage() const {
  return baseType->storage();
}
std::unique_ptr<Storage> VariableType::storage(size_t size) const {
  return baseType->storage(size);
}
std::unique_ptr<Storage> VariableType::storageFromBlob(void * data, int64_t size, const std::function<void(void*)> & deleter) const {
  return baseType->storageFromBlob(data, size, deleter);
}
std::unique_ptr<Storage> VariableType::unsafeStorageFromTH(void * th_pointer, bool retain) const {
  return baseType->unsafeStorageFromTH(th_pointer, retain);
}
std::unique_ptr<Storage> VariableType::storageWithAllocator(int64_t size, std::unique_ptr<Allocator> allocator) const {
  return baseType->storageWithAllocator(size, std::move(allocator));
}
Tensor VariableType::unsafeTensorFromTH(void * th_pointer, bool retain) const {
  return make_variable(baseType->unsafeTensorFromTH(th_pointer, retain), /*requires_grad=*/false);
}
std::unique_ptr<Generator> VariableType::generator() const {
  return baseType->generator();
}

const char * VariableType::toString() const {
  return str.c_str();
}
size_t VariableType::elementSizeInBytes() const {
  return baseType->elementSizeInBytes();
}
Type & VariableType::toBackend(Backend b) const {
  return *getType(baseType->toBackend(b));
}
Type & VariableType::toScalarType(ScalarType s) const {
  return *getType(baseType->toScalarType(s));
}
TypeID VariableType::ID() const {
  throw std::runtime_error("VariableType::ID() not implemented");
}

const char * VariableType::typeString() {
  return "VariableType";
}

// Pre-condition: backend/scalar_type is a valid type in the type_registry
void register_variable_type_for(at::Context* context, at::Backend backend, at::ScalarType scalar_type) {
  auto* baseType = context->type_registry[static_cast<int>(at::IsVariable::NotVariable)][static_cast<int>(backend)][static_cast<int>(scalar_type)].get();
  AT_ASSERT(baseType);
  context->type_registry[static_cast<int>(at::IsVariable::Variable)][static_cast<int>(backend)][static_cast<int>(scalar_type)].reset(new VariableType(context, baseType));
}

struct VariableTypeRegistry {
  static constexpr int MaxTypes = static_cast<int>(at::TypeID::NumOptions);

  VariableTypeRegistry() {
    auto& context = at::globalContext();
    for (int p = 0; p < static_cast<int>(Backend::NumOptions); ++p) {
      for (int s = 0; s < static_cast<int>(ScalarType::NumOptions); s++) {
        auto baseType = context.type_registry[static_cast<int>(at::IsVariable::NotVariable)][p][s].get();
        if (baseType && baseType->backend() != Backend::Undefined) {
          register_variable_type_for(&context, static_cast<Backend>(p), static_cast<ScalarType>(s));
        }
      }
    }
  }

  std::once_flag init_flag;
};

static VariableTypeRegistry registry;

bool VariableType::isVariableType(const at::Type& type) {
  static const auto* undefined_ty = &globalContext().getType(at::Backend::Undefined, at::ScalarType::Undefined);
  return type.is_variable_or_undefined() && &type != undefined_ty;
}

at::Type* VariableType::getType(const at::Type& baseType) {
  return globalContext().type_registry[static_cast<int>(at::IsVariable::Variable)]
                                      [static_cast<int>(baseType.backend())]
                                      [static_cast<int>(baseType.scalarType())].get();
}

at::Type* VariableType::getType(const at::Tensor& tensor) {
  if (!tensor.defined()) {
    throw std::runtime_error("tensor is undefined");
  }
  return getType(tensor.type());
}

std::vector<at::Type*> VariableType::allCPUTypes() {
  auto& context = at::globalContext();
  std::vector<Type*> res;
  // CPU and Sparse CPU
  res.reserve(2 * static_cast<int>(ScalarType::NumOptions));
  for (auto p : { Backend::CPU, Backend::SparseCPU }) {
    for (int s = 0; s < static_cast<int>(ScalarType::NumOptions); s++) {
      auto* r = context.type_registry[static_cast<int>(at::IsVariable::Variable)][static_cast<int>(p)][s].get();
      if (r) res.emplace_back(r);
    }
  }
  return res;
}

std::vector<at::Type*> VariableType::allCUDATypes() {
  auto& context = at::globalContext();
  context.lazyInitCUDA();
  std::vector<Type*> res;
  // CUDA and Sparse CUDA
  res.reserve(2 * static_cast<int>(ScalarType::NumOptions));
  for (auto p : { Backend::CUDA, Backend::SparseCUDA }) {
    for (int s = 0; s < static_cast<int>(ScalarType::NumOptions); s++) {
      auto* r = context.type_registry[static_cast<int>(at::IsVariable::Variable)][static_cast<int>(p)][s].get();
      if (r) res.emplace_back(r);
    }
  }
  return res;
}

Variable & VariableType::checked_cast_variable(const Tensor & t, const char * name, int pos) {
  if (!t.defined()) {
    AT_ERROR("Expected a Tensor of type Variable but found an undefined Tensor for argument #", pos, " '", name, "'");
  }
  if (!isVariableType(t.type())) {
    AT_ERROR("Expected object of type Variable but found type ", t.type().toString(), " for argument #", pos, " '", name, "'");
  }
  return as_variable_ref(const_cast<Tensor&>(t));
}

Tensor & VariableType::unpack(const Tensor & t, const char * name, int pos) {
  return checked_cast_variable(t, name, pos).data();
}

SparseTensor VariableType::unpack(SparseTensor t, const char * name, int pos) {
  return SparseTensor(checked_cast_variable(t.tref, name, pos).data());
}

Tensor VariableType::unpack_opt(const Tensor & t, const char * name, int pos) {
  if (!t.defined()) {
    return Tensor();
  }
  return unpack(t, name, pos);
}

std::vector<at::Tensor> VariableType::unpack(at::TensorList tl, const char *name, int pos) {
  std::vector<at::Tensor> ret(tl.size());
  for (size_t i = 0; i < tl.size(); ++i) {
    const auto &t = tl[i];
    if (!t.defined()) {
      AT_ERROR("Expected a Tensor of type Variable but found an undefined Tensor at position #", i, " "
                    "for iterable argument #", pos, " '", name, "'");
    }
    if (!isVariableType(t.type())) {
      AT_ERROR("Expected object of type Variable but found type ", t.type().toString(), " at position #", i, " "
                    "for iterable argument #", pos, " '", name, "'");
    }
    ret[i] = static_cast<const Variable&>(t).data();
  }
  return ret;
}

// Assumed that saved tensor lists are never inplace outputs
static std::vector<SavedVariable> make_saved_variable_list(TensorList tensors) {
  return fmap(tensors, [](const Tensor& tensor) -> SavedVariable {
      return SavedVariable{tensor, false /* is output */}; });
}

static Tensor as_variable(Tensor tensor) {
  return make_variable(std::move(tensor), /*requires_grad=*/false);
}

static std::vector<Tensor> as_variable(TensorList tl) {
  return fmap(tl, [](const Tensor& t) -> Tensor {
      return make_variable(std::move(t), /*requires_grad=*/false);
  });
}

template <typename... Tensors, size_t... Is>
std::tuple<Tensors...> as_variable_impl(
    std::tuple<Tensors...> tensors,
    Indices<Is...>) {
  // Expand the integer parameter pack into a sequence of Variable
  // constructions. This turns into (boolean omitted):
  // Variable(std::get<0>(tensors)), Variable(std::get<1>(tensors)), ...
  return std::tuple<Tensors...>(
      as_variable(std::get<Is>(tensors))...);
}

// NB: Because this was not forward declared, recursive std::tuple won't work.
// You can probably rejigger this to make it supported if you really need it.
template <typename... Tensors>
std::tuple<Tensors...> as_variable(std::tuple<Tensors...> tensors) {
  // `sizeof...(Tensors)` gets us the size of the `Tensors` parameter pack at
  // compile time. We use it to parameterize a `MakeIndices` class, which will
  // expand into an Indices object containing the numbers 0 to
  // sizeof...(Tensors) - 1.
  return as_variable_impl(
      tensors, typename MakeIndices<sizeof...(Tensors)>::indices());
}

static Tensor as_view(const Tensor & base, Tensor tensor) {
  auto base_var = Variable(base);
  if (base_var.is_view()) {
    base_var = base_var.base();
  }
  return make_variable_view(std::move(base_var), std::move(tensor));
}

struct ComputeRequiresGrad : IterArgs<ComputeRequiresGrad> {
  bool out = false;
  using IterArgs<ComputeRequiresGrad>::operator();
  void operator()(const at::Tensor& tensor) {
    const auto& var = static_cast<const Variable&>(tensor);
    if (var.defined() && var.requires_grad()) {
      out = true;
    }
  }
  bool short_circuit() { return out; }
};

template<typename... Args>
static bool compute_requires_grad(Args&&... args) {
  if (!GradMode::is_enabled()) {
    return false;
  }
  return ComputeRequiresGrad().apply(std::forward<Args>(args)...).out;
}

static void check_no_requires_grad(const Tensor& tensor, const char* name) {
  auto& var = static_cast<const Variable&>(tensor);
  if (var.defined() && var.requires_grad()) {
    std::string msg = "the derivative for '";
    msg += name;
    msg += "' is not implemented";
    throw std::runtime_error(msg);
  }
}

static void check_inplace(const Tensor& tensor) {
  auto& var = static_cast<const Variable&>(tensor);
  if (var.requires_grad() && var.is_leaf() && GradMode::is_enabled()) {
    AT_ERROR(
      "a leaf Variable that requires grad has been used in an in-place operation.");
  }
}

static void throw_error_out_requires_grad(const char* name) {
  AT_ERROR(
      name, "(): functions with out=... arguments don't support automatic differentiation, "
      "but one of the arguments requires grad.");
}

// TODO: Blegh, bare references

static void rebase_history(Variable& var, std::shared_ptr<Function> grad_fn) {
  if (grad_fn && var.defined()) {
    grad_fn->set_num_inputs(1);
    var.rebase_history({std::move(grad_fn), 0});
  }
}

static void rebase_history(ArrayRef<Variable> vars, std::shared_ptr<Function> grad_fn) {
  if (grad_fn) {
    grad_fn->set_num_inputs(vars.size());
    uint32_t output_nr = 0;
    for (auto& var : vars) {
      if (var.defined()) {
        // TODO: eliminate const_cast
        const_cast<Variable&>(var).rebase_history({grad_fn, output_nr});
      }
      output_nr++;
    }
  }
}

static void set_history(ArrayRef<Variable> vars, std::shared_ptr<Function> grad_fn) {
  if (grad_fn) {
    grad_fn->set_num_inputs(vars.size());
    uint32_t output_nr = 0;
    for (auto& var : vars) {
      if (var.defined()) {
        // TODO: eliminate const_cast
        const_cast<Variable&>(var).set_gradient_edge({grad_fn, output_nr});
      }
      output_nr++;
    }
  }
}

struct Flatten : IterArgs<Flatten> {
  Flatten(variable_list& out) : out(out) {}
  variable_list& out;
  void operator()(const at::Tensor& x) { out.emplace_back(x); }
  void operator()(at::ArrayRef<at::Tensor> xs) {
    out.insert(out.end(), xs.begin(), xs.end());
  }
};

template<typename... Args> inline variable_list flatten(Args&&... args) {
  variable_list out;
  out.reserve(count_tensors(std::forward<Args>(args)...));
  Flatten(out).apply(std::forward<Args>(args)...);
  return out; // RVO
}

static void increment_version(Tensor & t) {
  as_variable_ref(t).bump_version();
}

static bool isFloatingPoint(ScalarType s) {
  return s == kFloat || s == kDouble || s == kHalf;
}

Tensor & VariableType::s_copy_(Tensor & self, const Tensor & src, bool non_blocking) const {
  // TODO: once copy is exposed in Declarations.yaml we may be able to bind
  // it automatically
  auto& self_ = unpack(self, "self", 0);
  auto& src_ = unpack(src, "src", 1);
  check_inplace(self);
  std::shared_ptr<CopyBackwards> grad_fn;
  auto requires_grad = compute_requires_grad(self, src);
  requires_grad &= isFloatingPoint(self.type().scalarType());
  if (requires_grad) {
    grad_fn = std::make_shared<CopyBackwards>();
    grad_fn->set_next_edges(collect_next_edges(self, src));
    grad_fn->set_num_inputs(1);
    grad_fn->src_type = &src.type();
    grad_fn->src_device = src.is_cuda() ? src.get_device() : -1;
  }
  baseType->s_copy_(self_, src_, non_blocking);
  increment_version(self);
  rebase_history(as_variable_ref( self ), std::move(grad_fn));
  return self;
}

Tensor & VariableType::_s_copy_from(const Tensor & self, Tensor & dst, bool non_blocking) const {
  AT_ERROR("copy_from does not support automatic differentiation; use copy_ instead");
}

Tensor & VariableType::resize_(Tensor & self, IntList size) const {
  auto& self_ = unpack(self, "self", 0);
  if (as_variable_ref(self).requires_grad()) {
    AT_ERROR("cannot resize variables that require grad");
  }
  baseType->resize_(self_, size);
  return self;
}

Tensor & VariableType::resize_as_(Tensor & self, const Tensor & the_template) const {
  auto& self_ = unpack(self, "self", 0);
  auto& the_template_ = unpack(the_template, "the_template", 1);
  if (as_variable_ref(self).requires_grad()) {
    AT_ERROR("cannot resize variables that require grad");
  }
  baseType->resize_as_(self_, the_template_);
  return self;
}

Tensor VariableType::contiguous(const Tensor & self) const {
  unpack(self, "self", 0);
  if (self.is_contiguous()) {
    return self;
  }
  return self.clone();
}

static std::vector<std::vector<int64_t>> to_args_sizes(TensorList tensors) {
  std::vector<std::vector<int64_t>> args_sizes(tensors.size());
  for (size_t i = 0; i < tensors.size(); ++i) {
    args_sizes[i] = tensors[i].sizes();
  }
  return args_sizes;
}

int64_t VariableType::storage_offset(const Tensor & self) const {
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->storage_offset(self_);
  return result;
}
int64_t VariableType::numel(const Tensor & self) const {
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->numel(self_);
  return result;
}
Tensor & VariableType::set_(Tensor & self, Storage & storage) const {
  profiler::RecordFunction profiler("set_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for set_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->set_(self_, storage);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::set_(Tensor & self, Storage & sourceStorage, int64_t storage_offset, IntList size, IntList stride) const {
  profiler::RecordFunction profiler("set_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for set_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->set_(self_, sourceStorage, storage_offset, size, stride);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::set_(Tensor & self, const Tensor & source) const {
  profiler::RecordFunction profiler("set_");
  auto& self_ = unpack(self, "self", 0);
  auto& source_ = unpack(source, "source", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, source )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for set_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, source ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, source )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::set, { self, source } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->set_(self_, source_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::set_(Tensor & self) const {
  profiler::RecordFunction profiler("set_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for set_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::set, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->set_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::_fill_(Tensor & self, Scalar value) const {
  profiler::RecordFunction profiler("_fill_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _fill_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_fill, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->_fill_(self_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::_fill_(Tensor & self, const Tensor & value) const {
  profiler::RecordFunction profiler("_fill_");
  auto& self_ = unpack(self, "self", 0);
  auto& value_ = unpack(value, "value", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, value )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _fill_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, value ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, value )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_fill, { self, value } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_fill_(self_, value_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
bool VariableType::is_contiguous(const Tensor & self) const {
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->is_contiguous(self_);
  return result;
}
bool VariableType::is_set_to(const Tensor & self, const Tensor & tensor) const {
  auto& self_ = unpack(self, "self", 0);
  auto& tensor_ = unpack(tensor, "tensor", 1);
  auto result = baseType->is_set_to(self_, tensor_);
  return result;
}
Tensor & VariableType::s_masked_fill_(Tensor & self, const Tensor & mask, Scalar value) const {
  profiler::RecordFunction profiler("masked_fill_");
  auto& self_ = unpack(self, "self", 0);
  auto& mask_ = unpack(mask, "mask", 1);
  check_inplace(self);
  std::shared_ptr<MaskedFillBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaskedFillBackward0>(new MaskedFillBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->mask_ = SavedVariable(mask, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mask )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::masked_fill, { self, mask } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->s_masked_fill_(self_, mask_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_masked_fill_(Tensor & self, const Tensor & mask, const Tensor & value) const {
  profiler::RecordFunction profiler("masked_fill_");
  auto& self_ = unpack(self, "self", 0);
  auto& mask_ = unpack(mask, "mask", 1);
  auto& value_ = unpack(value, "value", 2);
  check_inplace(self);
  std::shared_ptr<MaskedFillBackward1> grad_fn;
  if (compute_requires_grad( self, value )) {
    grad_fn = std::shared_ptr<MaskedFillBackward1>(new MaskedFillBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, value ));
    grad_fn->mask_ = SavedVariable(mask, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mask, value )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::masked_fill, { self, mask, value } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_masked_fill_(self_, mask_, value_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_masked_scatter_(Tensor & self, const Tensor & mask, const Tensor & source) const {
  profiler::RecordFunction profiler("masked_scatter_");
  auto& self_ = unpack(self, "self", 0);
  auto& mask_ = unpack(mask, "mask", 1);
  auto& source_ = unpack(source, "source", 2);
  check_inplace(self);
  std::shared_ptr<MaskedScatterBackward> grad_fn;
  if (compute_requires_grad( self, source )) {
    grad_fn = std::shared_ptr<MaskedScatterBackward>(new MaskedScatterBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, source ));
    grad_fn->mask_ = SavedVariable(mask, false);
    grad_fn->source_sizes = source.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mask, source )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::masked_scatter, { self, mask, source } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_masked_scatter_(self_, mask_, source_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_masked_select_out(Tensor & result, const Tensor & self, const Tensor & mask) const {
  profiler::RecordFunction profiler("masked_select_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& mask_ = unpack(mask, "mask", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("masked_select");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("masked_select");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mask )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::masked_select_out, { result, self, mask } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_masked_select_out(result_, self_, mask_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_masked_select(const Tensor & self, const Tensor & mask) const {
  profiler::RecordFunction profiler("masked_select");
  auto& self_ = unpack(self, "self", 0);
  auto& mask_ = unpack(mask, "mask", 1);
  std::shared_ptr<MaskedSelectBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaskedSelectBackward>(new MaskedSelectBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
    grad_fn->mask_ = SavedVariable(mask, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mask )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::masked_select, { self, mask } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_masked_select(self_, mask_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::nonzero_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("nonzero_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nonzero_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->nonzero_out(result_, self_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::nonzero(const Tensor & self) const {
  profiler::RecordFunction profiler("nonzero");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nonzero, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->nonzero(self_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::clone(const Tensor & self) const {
  profiler::RecordFunction profiler("clone");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<CloneBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CloneBackward>(new CloneBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clone, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->clone(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::view(const Tensor & self, IntList size) const {
  profiler::RecordFunction profiler("view");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ViewBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ViewBackward>(new ViewBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::view, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  auto result = as_view(self, baseType->view(self_, size));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::index_select_out(Tensor & result, const Tensor & self, int64_t dim, const Tensor & index) const {
  profiler::RecordFunction profiler("index_select_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& index_ = unpack(index, "index", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("index_select");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("index_select");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_select_out, { result, self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->index_select_out(result_, self_, dim, index_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::index_select(const Tensor & self, int64_t dim, const Tensor & index) const {
  profiler::RecordFunction profiler("index_select");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  std::shared_ptr<IndexSelectBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<IndexSelectBackward>(new IndexSelectBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_select, { self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->index_select(self_, dim, index_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_indexCopy_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) const {
  profiler::RecordFunction profiler("_indexCopy_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  auto& source_ = unpack(source, "source", 3);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, source )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _indexCopy_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, source ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, source )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_indexCopy, { self, index, source } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->_indexCopy_(self_, dim, index_, source_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::take_out(Tensor & result, const Tensor & self, const Tensor & index) const {
  profiler::RecordFunction profiler("take_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& index_ = unpack(index, "index", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("take");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("take");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::take_out, { result, self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->take_out(result_, self_, index_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::take(const Tensor & self, const Tensor & index) const {
  profiler::RecordFunction profiler("take");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 1);
  std::shared_ptr<TakeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TakeBackward>(new TakeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::take, { self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->take(self_, index_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::put_(Tensor & self, const Tensor & index, const Tensor & source, bool accumulate) const {
  profiler::RecordFunction profiler("put_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 1);
  auto& source_ = unpack(source, "source", 2);
  check_inplace(self);
  std::shared_ptr<PutBackward> grad_fn;
  if (compute_requires_grad( self, source )) {
    grad_fn = std::shared_ptr<PutBackward>(new PutBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, source ));
    grad_fn->index_ = SavedVariable(index, false);
    grad_fn->source_info = source;
    grad_fn->accumulate = accumulate;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, source )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::put, { self, index, source } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "accumulate", accumulate);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::accumulate, accumulate);
    }
  }
  baseType->put_(self_, index_, source_, accumulate);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::index_add_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) const {
  profiler::RecordFunction profiler("index_add_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  auto& source_ = unpack(source, "source", 3);
  check_inplace(self);
  std::shared_ptr<IndexAddBackward> grad_fn;
  if (compute_requires_grad( self, source )) {
    grad_fn = std::shared_ptr<IndexAddBackward>(new IndexAddBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, source ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, source )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_add, { self, index, source } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->index_add_(self_, dim, index_, source_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::index_fill_(Tensor & self, int64_t dim, const Tensor & index, Scalar value) const {
  profiler::RecordFunction profiler("index_fill_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  check_inplace(self);
  std::shared_ptr<IndexFillBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<IndexFillBackward0>(new IndexFillBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_fill, { self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->index_fill_(self_, dim, index_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::index_fill_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & value) const {
  profiler::RecordFunction profiler("index_fill_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  auto& value_ = unpack(value, "value", 3);
  check_inplace(self);
  std::shared_ptr<IndexFillBackward1> grad_fn;
  if (compute_requires_grad( self, value )) {
    grad_fn = std::shared_ptr<IndexFillBackward1>(new IndexFillBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, value ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, value )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_fill, { self, index, value } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->index_fill_(self_, dim, index_, value_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::unfold(const Tensor & self, int64_t dimension, int64_t size, int64_t step) const {
  profiler::RecordFunction profiler("unfold");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UnfoldBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UnfoldBackward>(new UnfoldBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dimension = dimension;
    grad_fn->size = size;
    grad_fn->step = step;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::unfold, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dimension", dimension);
      setposattr(trace_info.n, 2, "size", size);
      setposattr(trace_info.n, 3, "step", step);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dimension, dimension);
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::step, step);
    }
  }
  auto result = as_view(self, baseType->unfold(self_, dimension, size, step));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_range_out(Tensor & result, Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("_range_out");
  auto& result_ = unpack(result, "result", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_range_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "step", step);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::step, step);
    }
  }
  baseType->_range_out(result_, start, end, step);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_range(Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("_range");
  auto result = as_variable(baseType->_range(start, end, step));
  return result;
}
Tensor & VariableType::_arange_out(Tensor & result, Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("_arange_out");
  auto& result_ = unpack(result, "result", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_arange_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "step", step);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::step, step);
    }
  }
  baseType->_arange_out(result_, start, end, step);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_arange(Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("_arange");
  auto result = as_variable(baseType->_arange(start, end, step));
  return result;
}
Tensor & VariableType::_arange_out(Tensor & result, Scalar end) const {
  profiler::RecordFunction profiler("_arange_out");
  auto& result_ = unpack(result, "result", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_arange_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "end", end);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::end, end);
    }
  }
  baseType->_arange_out(result_, end);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_arange(Scalar end) const {
  profiler::RecordFunction profiler("_arange");
  auto result = as_variable(baseType->_arange(end));
  return result;
}
Tensor & VariableType::scatter_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & src) const {
  profiler::RecordFunction profiler("scatter_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  auto& src_ = unpack(src, "src", 3);
  check_inplace(self);
  std::shared_ptr<ScatterBackward0> grad_fn;
  if (compute_requires_grad( self, src )) {
    grad_fn = std::shared_ptr<ScatterBackward0>(new ScatterBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, src ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, src )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::scatter, { self, index, src } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->scatter_(self_, dim, index_, src_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::scatter_(Tensor & self, int64_t dim, const Tensor & index, Scalar value) const {
  profiler::RecordFunction profiler("scatter_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  check_inplace(self);
  std::shared_ptr<ScatterBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ScatterBackward1>(new ScatterBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::scatter, { self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->scatter_(self_, dim, index_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::scatter_add_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & src) const {
  profiler::RecordFunction profiler("scatter_add_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  auto& src_ = unpack(src, "src", 3);
  check_inplace(self);
  std::shared_ptr<ScatterAddBackward> grad_fn;
  if (compute_requires_grad( self, src )) {
    grad_fn = std::shared_ptr<ScatterAddBackward>(new ScatterAddBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, src ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, src )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::scatter_add, { self, index, src } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->scatter_add_(self_, dim, index_, src_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::gather_out(Tensor & result, const Tensor & self, int64_t dim, const Tensor & index) const {
  profiler::RecordFunction profiler("gather_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& index_ = unpack(index, "index", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("gather");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("gather");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gather_out, { result, self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->gather_out(result_, self_, dim, index_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::gather(const Tensor & self, int64_t dim, const Tensor & index) const {
  profiler::RecordFunction profiler("gather");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  std::shared_ptr<GatherBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<GatherBackward>(new GatherBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gather, { self, index } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->gather(self_, dim, index_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
void* VariableType::data_ptr(const Tensor & self) const {
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->data_ptr(self_);
  return result;
}
bool VariableType::equal(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("equal");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  auto result = baseType->equal(self_, other_);
  return result;
}
Tensor & VariableType::__and___out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__and___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__and___out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__and___out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::__and__(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__and__");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__and__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->__and__(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s___and___out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__and___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__and___out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___and___out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s___and__(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__and__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__and__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s___and__(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::__iand__(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__iand__");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __iand__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__iand__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__iand__(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s___iand__(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__iand__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __iand__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__iand__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___iand__(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::__or___out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__or___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__or___out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__or___out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::__or__(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__or__");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__or__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->__or__(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s___or___out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__or___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__or___out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___or___out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s___or__(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__or__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__or__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s___or__(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::__ior__(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__ior__");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __ior__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__ior__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__ior__(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s___ior__(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__ior__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __ior__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__ior__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___ior__(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::__xor___out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__xor___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__xor___out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__xor___out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::__xor__(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__xor__");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__xor__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->__xor__(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s___xor___out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__xor___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__xor___out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___xor___out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s___xor__(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__xor__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__xor__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s___xor__(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::__ixor__(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__ixor__");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __ixor__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__ixor__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__ixor__(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s___ixor__(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__ixor__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __ixor__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__ixor__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___ixor__(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::__lshift___out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__lshift___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__lshift___out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__lshift___out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::__lshift__(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__lshift__");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__lshift__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->__lshift__(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s___lshift___out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__lshift___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__lshift___out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___lshift___out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s___lshift__(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__lshift__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__lshift__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s___lshift__(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::__ilshift__(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__ilshift__");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __ilshift__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__ilshift__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__ilshift__(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s___ilshift__(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__ilshift__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __ilshift__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__ilshift__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___ilshift__(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::__rshift___out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__rshift___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__rshift___out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__rshift___out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::__rshift__(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__rshift__");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__rshift__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->__rshift__(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s___rshift___out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__rshift___out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__rshift___out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___rshift___out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s___rshift__(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__rshift__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__rshift__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s___rshift__(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::__irshift__(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("__irshift__");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __irshift__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__irshift__, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->__irshift__(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s___irshift__(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("__irshift__");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for __irshift__ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::__irshift__, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s___irshift__(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::lt_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("lt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lt_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->lt_out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::lt(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("lt");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->lt(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_lt_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("lt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lt_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_lt_out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_lt(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("lt");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lt, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_lt(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::lt_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("lt_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<LtBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LtBackward0>(new LtBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->lt_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_lt_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("lt_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<LtBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<LtBackward1>(new LtBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_info = other;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lt, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_lt_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::gt_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("gt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gt_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->gt_out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::gt(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("gt");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->gt(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_gt_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("gt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gt_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_gt_out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_gt(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("gt");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gt, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_gt(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::gt_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("gt_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<GtBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<GtBackward0>(new GtBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->gt_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_gt_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("gt_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<GtBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<GtBackward1>(new GtBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_info = other;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gt, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_gt_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::le_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("le_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::le_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->le_out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::le(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("le");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::le, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->le(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_le_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("le_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::le_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_le_out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_le(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("le");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::le, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_le(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::le_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("le_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<LeBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LeBackward0>(new LeBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::le, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->le_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_le_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("le_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<LeBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<LeBackward1>(new LeBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_info = other;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::le, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_le_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::ge_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("ge_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ge_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->ge_out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::ge(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("ge");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ge, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->ge(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_ge_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("ge_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ge_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_ge_out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_ge(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("ge");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ge, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_ge(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::ge_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("ge_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<GeBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<GeBackward0>(new GeBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ge, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->ge_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_ge_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("ge_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<GeBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<GeBackward1>(new GeBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_info = other;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ge, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_ge_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::eq_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("eq_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eq_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->eq_out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::eq(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("eq");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eq, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->eq(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_eq_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("eq_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eq_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_eq_out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_eq(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("eq");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eq, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_eq(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::eq_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("eq_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<EqBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<EqBackward0>(new EqBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eq, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->eq_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_eq_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("eq_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<EqBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<EqBackward1>(new EqBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_info = other;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eq, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_eq_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::ne_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("ne_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ne_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->ne_out(result_, self_, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::ne(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("ne");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ne, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->ne(self_, other));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_ne_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("ne_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ne_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_ne_out(result_, self_, other_);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_ne(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("ne");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ne, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_ne(self_, other_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::ne_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("ne_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<NeBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NeBackward0>(new NeBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ne, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->ne_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_ne_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("ne_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<NeBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<NeBackward1>(new NeBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_info = other;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ne, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_ne_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
std::tuple<Tensor &,Tensor &> VariableType::min_out(Tensor & min, Tensor & min_indices, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("min_out");
  auto& min_ = unpack(min, "min", 0);
  auto& min_indices_ = unpack(min_indices, "min_indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("min");
  }
  if (compute_requires_grad( min )) {
    throw_error_out_requires_grad("min");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( min, min_indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::min_out, { min, min_indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->min_out(min_, min_indices_, self_, dim, keepdim);
  increment_version(min);
  rebase_history(flatten( min ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {min, min_indices} );
  }
  return std::forward_as_tuple(min, min_indices);
}
std::tuple<Tensor,Tensor> VariableType::min(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("min");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MinBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MinBackward0>(new MinBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  Tensor min;
  Tensor min_indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::min, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  std::tie(min, min_indices) = as_variable(baseType->min(self_, dim, keepdim));
  set_history(flatten( min ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { min, min_indices } );
  }
  if (grad_fn) {
    grad_fn->min_indices_ = SavedVariable(min_indices, true);
  }
  return std::make_tuple(std::move(min), std::move(min_indices));
}
Tensor & VariableType::s_min_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("min_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("min");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("min");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::min_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_min_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_min(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("min");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<MinBackward2> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<MinBackward2>(new MinBackward2(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::min, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_min(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::min(const Tensor & self) const {
  profiler::RecordFunction profiler("min");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MinBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MinBackward1>(new MinBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::min, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->min(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
std::tuple<Tensor &,Tensor &> VariableType::max_out(Tensor & max, Tensor & max_indices, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("max_out");
  auto& max_ = unpack(max, "max", 0);
  auto& max_indices_ = unpack(max_indices, "max_indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("max");
  }
  if (compute_requires_grad( max )) {
    throw_error_out_requires_grad("max");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( max, max_indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_out, { max, max_indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->max_out(max_, max_indices_, self_, dim, keepdim);
  increment_version(max);
  rebase_history(flatten( max ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {max, max_indices} );
  }
  return std::forward_as_tuple(max, max_indices);
}
std::tuple<Tensor,Tensor> VariableType::max(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("max");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MaxBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaxBackward0>(new MaxBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  Tensor max;
  Tensor max_indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  std::tie(max, max_indices) = as_variable(baseType->max(self_, dim, keepdim));
  set_history(flatten( max ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { max, max_indices } );
  }
  if (grad_fn) {
    grad_fn->max_indices_ = SavedVariable(max_indices, true);
  }
  return std::make_tuple(std::move(max), std::move(max_indices));
}
Tensor & VariableType::s_max_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("max_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("max");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("max");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_max_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_max(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("max");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<MaxBackward2> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<MaxBackward2>(new MaxBackward2(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_max(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::max(const Tensor & self) const {
  profiler::RecordFunction profiler("max");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MaxBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaxBackward1>(new MaxBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->max(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
std::tuple<Tensor &,Tensor &> VariableType::kthvalue_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t k, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("kthvalue_out");
  auto& values_ = unpack(values, "values", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("kthvalue");
  }
  if (compute_requires_grad( values )) {
    throw_error_out_requires_grad("kthvalue");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( values, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kthvalue_out, { values, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "k", k);
      setposattr(trace_info.n, 4, "dim", dim);
      setposattr(trace_info.n, 5, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::k, k);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->kthvalue_out(values_, indices_, self_, k, dim, keepdim);
  increment_version(values);
  rebase_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {values, indices} );
  }
  return std::forward_as_tuple(values, indices);
}
std::tuple<Tensor,Tensor> VariableType::kthvalue(const Tensor & self, int64_t k, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("kthvalue");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<KthvalueBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<KthvalueBackward>(new KthvalueBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  Tensor values;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kthvalue, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "k", k);
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::k, k);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  std::tie(values, indices) = as_variable(baseType->kthvalue(self_, k, dim, keepdim));
  set_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { values, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(values), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::mode_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("mode_out");
  auto& values_ = unpack(values, "values", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("mode");
  }
  if (compute_requires_grad( values )) {
    throw_error_out_requires_grad("mode");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( values, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mode_out, { values, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->mode_out(values_, indices_, self_, dim, keepdim);
  increment_version(values);
  rebase_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {values, indices} );
  }
  return std::forward_as_tuple(values, indices);
}
std::tuple<Tensor,Tensor> VariableType::mode(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("mode");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ModeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ModeBackward>(new ModeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  Tensor values;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mode, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  std::tie(values, indices) = as_variable(baseType->mode(self_, dim, keepdim));
  set_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { values, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(values), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::median_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("median_out");
  auto& values_ = unpack(values, "values", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("median");
  }
  if (compute_requires_grad( values )) {
    throw_error_out_requires_grad("median");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( values, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::median_out, { values, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->median_out(values_, indices_, self_, dim, keepdim);
  increment_version(values);
  rebase_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {values, indices} );
  }
  return std::forward_as_tuple(values, indices);
}
std::tuple<Tensor,Tensor> VariableType::median(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("median");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MedianBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MedianBackward1>(new MedianBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  Tensor values;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::median, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  std::tie(values, indices) = as_variable(baseType->median(self_, dim, keepdim));
  set_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { values, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(values), std::move(indices));
}
Tensor VariableType::median(const Tensor & self) const {
  profiler::RecordFunction profiler("median");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MedianBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MedianBackward0>(new MedianBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::median, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->median(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
std::tuple<Tensor &,Tensor &> VariableType::sort_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t dim, bool descending) const {
  profiler::RecordFunction profiler("sort_out");
  auto& values_ = unpack(values, "values", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sort");
  }
  if (compute_requires_grad( values )) {
    throw_error_out_requires_grad("sort");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( values, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sort_out, { values, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "descending", descending);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::descending, descending);
    }
  }
  baseType->sort_out(values_, indices_, self_, dim, descending);
  increment_version(values);
  rebase_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {values, indices} );
  }
  return std::forward_as_tuple(values, indices);
}
std::tuple<Tensor,Tensor> VariableType::sort(const Tensor & self, int64_t dim, bool descending) const {
  profiler::RecordFunction profiler("sort");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SortBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SortBackward>(new SortBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
  }
  Tensor values;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sort, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "descending", descending);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::descending, descending);
    }
  }
  std::tie(values, indices) = as_variable(baseType->sort(self_, dim, descending));
  set_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { values, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(values), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::topk_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t k, int64_t dim, bool largest, bool sorted) const {
  profiler::RecordFunction profiler("topk_out");
  auto& values_ = unpack(values, "values", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("topk");
  }
  if (compute_requires_grad( values )) {
    throw_error_out_requires_grad("topk");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( values, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::topk_out, { values, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "k", k);
      setposattr(trace_info.n, 4, "dim", dim);
      setposattr(trace_info.n, 5, "largest", largest);
      setposattr(trace_info.n, 6, "sorted", sorted);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::k, k);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::largest, largest);
      setattr(trace_info.n, jit::attr::sorted, sorted);
    }
  }
  baseType->topk_out(values_, indices_, self_, k, dim, largest, sorted);
  increment_version(values);
  rebase_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {values, indices} );
  }
  return std::forward_as_tuple(values, indices);
}
std::tuple<Tensor,Tensor> VariableType::topk(const Tensor & self, int64_t k, int64_t dim, bool largest, bool sorted) const {
  profiler::RecordFunction profiler("topk");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TopkBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TopkBackward>(new TopkBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
  }
  Tensor values;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::topk, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "k", k);
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "largest", largest);
      setposattr(trace_info.n, 4, "sorted", sorted);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::k, k);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::largest, largest);
      setattr(trace_info.n, jit::attr::sorted, sorted);
    }
  }
  std::tie(values, indices) = as_variable(baseType->topk(self_, k, dim, largest, sorted));
  set_history(flatten( values ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { values, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(values), std::move(indices));
}
Tensor & VariableType::all_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("all_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("all");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("all");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::all_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->all_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::all(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("all");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for all is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::all, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->all(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::all(const Tensor & self) const {
  profiler::RecordFunction profiler("all");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for all is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::all, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->all(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::any_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("any_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("any");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("any");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::any_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->any_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::any(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("any");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for any is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::any, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->any(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::any(const Tensor & self) const {
  profiler::RecordFunction profiler("any");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for any is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::any, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->any(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
int64_t VariableType::get_device(const Tensor & self) const {
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->get_device(self_);
  return result;
}
Tensor & VariableType::_abs_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_abs_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_abs");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_abs");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_abs_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_abs_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_abs(const Tensor & self) const {
  profiler::RecordFunction profiler("_abs");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _abs is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_abs, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_abs(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sigmoid_(Tensor & self) const {
  profiler::RecordFunction profiler("sigmoid_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SigmoidBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SigmoidBackward>(new SigmoidBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sigmoid, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sigmoid_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::sigmoid_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("sigmoid_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sigmoid");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sigmoid");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sigmoid_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sigmoid_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::sigmoid(const Tensor & self) const {
  profiler::RecordFunction profiler("sigmoid");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SigmoidBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SigmoidBackward>(new SigmoidBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sigmoid, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->sigmoid(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::_log_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_log_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_log");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_log");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_log_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_log(const Tensor & self) const {
  profiler::RecordFunction profiler("_log");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _log is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_log(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_log10_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_log10_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_log10");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_log10");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log10_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_log10_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_log10(const Tensor & self) const {
  profiler::RecordFunction profiler("_log10");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _log10 is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log10, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_log10(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_log1p_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_log1p_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_log1p");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_log1p");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log1p_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_log1p_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_log1p(const Tensor & self) const {
  profiler::RecordFunction profiler("_log1p");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _log1p is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log1p, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_log1p(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_log2_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_log2_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_log2");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_log2");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log2_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_log2_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_log2(const Tensor & self) const {
  profiler::RecordFunction profiler("_log2");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _log2 is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_log2, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_log2(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::lgamma_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("lgamma_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("lgamma");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("lgamma");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lgamma_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->lgamma_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::lgamma(const Tensor & self) const {
  profiler::RecordFunction profiler("lgamma");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LgammaBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LgammaBackward>(new LgammaBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lgamma, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->lgamma(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::lgamma_(Tensor & self) const {
  profiler::RecordFunction profiler("lgamma_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<LgammaBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LgammaBackward>(new LgammaBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lgamma, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->lgamma_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::digamma_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("digamma_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("digamma");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("digamma");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::digamma_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->digamma_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::digamma(const Tensor & self) const {
  profiler::RecordFunction profiler("digamma");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<DigammaBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DigammaBackward>(new DigammaBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::digamma, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->digamma(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::digamma_(Tensor & self) const {
  profiler::RecordFunction profiler("digamma_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<DigammaBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DigammaBackward>(new DigammaBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::digamma, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->digamma_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::polygamma_out(Tensor & result, int64_t n, const Tensor & self) const {
  profiler::RecordFunction profiler("polygamma_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("polygamma");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("polygamma");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::polygamma_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "n", n);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::n, n);
    }
  }
  baseType->polygamma_out(result_, n, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::polygamma(int64_t n, const Tensor & self) const {
  profiler::RecordFunction profiler("polygamma");
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<PolygammaBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PolygammaBackward>(new PolygammaBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->n = n;
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::polygamma, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "n", n);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::n, n);
    }
  }
  auto result = as_variable(baseType->polygamma(n, self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::polygamma_(Tensor & self, int64_t n) const {
  profiler::RecordFunction profiler("polygamma_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for polygamma_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::polygamma, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "n", n);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::n, n);
    }
  }
  baseType->polygamma_(self_, n);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::_exp_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_exp_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_exp");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_exp");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_exp_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_exp_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_exp(const Tensor & self) const {
  profiler::RecordFunction profiler("_exp");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _exp is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_exp, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_exp(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_expm1_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_expm1_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_expm1");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_expm1");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_expm1_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_expm1_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_expm1(const Tensor & self) const {
  profiler::RecordFunction profiler("_expm1");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _expm1 is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_expm1, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_expm1(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_cos_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_cos_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_cos");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_cos");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cos_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_cos_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_cos(const Tensor & self) const {
  profiler::RecordFunction profiler("_cos");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _cos is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cos, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_cos(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_acos_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_acos_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_acos");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_acos");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_acos_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_acos_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_acos(const Tensor & self) const {
  profiler::RecordFunction profiler("_acos");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _acos is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_acos, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_acos(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_cosh_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_cosh_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_cosh");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_cosh");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cosh_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_cosh_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_cosh(const Tensor & self) const {
  profiler::RecordFunction profiler("_cosh");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _cosh is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cosh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_cosh(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_sin_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_sin_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_sin");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_sin");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sin_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_sin_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_sin(const Tensor & self) const {
  profiler::RecordFunction profiler("_sin");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _sin is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_sin(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_asin_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_asin_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_asin");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_asin");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_asin_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_asin_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_asin(const Tensor & self) const {
  profiler::RecordFunction profiler("_asin");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _asin is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_asin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_asin(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_sinh_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_sinh_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_sinh");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_sinh");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sinh_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_sinh_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_sinh(const Tensor & self) const {
  profiler::RecordFunction profiler("_sinh");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _sinh is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sinh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_sinh(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_tan_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_tan_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_tan");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_tan");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tan_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_tan_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_tan(const Tensor & self) const {
  profiler::RecordFunction profiler("_tan");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _tan is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tan, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_tan(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_atan_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_atan_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_atan");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_atan");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_atan_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_atan_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_atan(const Tensor & self) const {
  profiler::RecordFunction profiler("_atan");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _atan is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_atan, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_atan(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_th_tanh_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_th_tanh_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_th_tanh");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_th_tanh");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_th_tanh_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_th_tanh_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_th_tanh(const Tensor & self) const {
  profiler::RecordFunction profiler("_th_tanh");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _th_tanh is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_th_tanh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_th_tanh(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_erf_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_erf_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_erf");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_erf");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_erf_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_erf_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_erf(const Tensor & self) const {
  profiler::RecordFunction profiler("_erf");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _erf is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_erf, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_erf(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::erfinv_(Tensor & self) const {
  profiler::RecordFunction profiler("erfinv_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ErfinvBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ErfinvBackward>(new ErfinvBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::erfinv, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->erfinv_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::erfinv_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("erfinv_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("erfinv");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("erfinv");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::erfinv_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->erfinv_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::erfinv(const Tensor & self) const {
  profiler::RecordFunction profiler("erfinv");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ErfinvBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ErfinvBackward>(new ErfinvBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::erfinv, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->erfinv(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_sqrt_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_sqrt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_sqrt");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_sqrt");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sqrt_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_sqrt_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_sqrt(const Tensor & self) const {
  profiler::RecordFunction profiler("_sqrt");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _sqrt is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sqrt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_sqrt(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_rsqrt_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_rsqrt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_rsqrt");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_rsqrt");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_rsqrt_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_rsqrt_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_rsqrt(const Tensor & self) const {
  profiler::RecordFunction profiler("_rsqrt");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _rsqrt is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_rsqrt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_rsqrt(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_ceil_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_ceil_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_ceil");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_ceil");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_ceil_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_ceil_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_ceil(const Tensor & self) const {
  profiler::RecordFunction profiler("_ceil");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _ceil is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_ceil, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_ceil(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_floor_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_floor_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_floor");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_floor");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_floor_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_floor_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_floor(const Tensor & self) const {
  profiler::RecordFunction profiler("_floor");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _floor is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_floor, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_floor(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_round_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_round_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_round");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_round");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_round_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_round_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_round(const Tensor & self) const {
  profiler::RecordFunction profiler("_round");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _round is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_round, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_round(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_trunc_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("_trunc_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_trunc");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_trunc");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_trunc_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_trunc_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_trunc(const Tensor & self) const {
  profiler::RecordFunction profiler("_trunc");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _trunc is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_trunc, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_trunc(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::frac_(Tensor & self) const {
  profiler::RecordFunction profiler("frac_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<FracBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FracBackward>(new FracBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::frac, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->frac_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::frac_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("frac_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("frac");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("frac");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::frac_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->frac_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::frac(const Tensor & self) const {
  profiler::RecordFunction profiler("frac");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<FracBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FracBackward>(new FracBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::frac, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->frac(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::mean_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("mean_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("mean");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("mean");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mean_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->mean_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::mean(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("mean");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MeanBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MeanBackward0>(new MeanBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mean, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->mean(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::mean(const Tensor & self) const {
  profiler::RecordFunction profiler("mean");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MeanBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MeanBackward1>(new MeanBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->self_numel = self.numel();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mean, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->mean(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::var_out(Tensor & result, const Tensor & self, int64_t dim, bool unbiased, bool keepdim) const {
  profiler::RecordFunction profiler("var_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("var");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("var");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::var_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "unbiased", unbiased);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::unbiased, unbiased);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->var_out(result_, self_, dim, unbiased, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::var(const Tensor & self, int64_t dim, bool unbiased, bool keepdim) const {
  profiler::RecordFunction profiler("var");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<VarBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<VarBackward1>(new VarBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
    grad_fn->unbiased = unbiased;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::var, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "unbiased", unbiased);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::unbiased, unbiased);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->var(self_, dim, unbiased, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::var(const Tensor & self, bool unbiased) const {
  profiler::RecordFunction profiler("var");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<VarBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<VarBackward0>(new VarBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->unbiased = unbiased;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::var, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "unbiased", unbiased);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::unbiased, unbiased);
    }
  }
  auto result = as_variable(baseType->var(self_, unbiased));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::std_out(Tensor & result, const Tensor & self, int64_t dim, bool unbiased, bool keepdim) const {
  profiler::RecordFunction profiler("std_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("std");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("std");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::std_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "unbiased", unbiased);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::unbiased, unbiased);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->std_out(result_, self_, dim, unbiased, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::std(const Tensor & self, int64_t dim, bool unbiased, bool keepdim) const {
  profiler::RecordFunction profiler("std");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<StdBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<StdBackward1>(new StdBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
    grad_fn->unbiased = unbiased;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::std, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "unbiased", unbiased);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::unbiased, unbiased);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->std(self_, dim, unbiased, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::std(const Tensor & self, bool unbiased) const {
  profiler::RecordFunction profiler("std");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<StdBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<StdBackward0>(new StdBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->unbiased = unbiased;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::std, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "unbiased", unbiased);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::unbiased, unbiased);
    }
  }
  auto result = as_variable(baseType->std(self_, unbiased));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::norm_out(Tensor & result, const Tensor & self, Scalar p, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("norm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("norm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("norm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::norm_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "p", p);
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->norm_out(result_, self_, p, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::norm(const Tensor & self, Scalar p, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("norm");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<NormBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NormBackward1>(new NormBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->p = p;
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::norm, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "p", p);
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->norm(self_, p, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::norm(const Tensor & self, Scalar p) const {
  profiler::RecordFunction profiler("norm");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<NormBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NormBackward0>(new NormBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->p = p;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::norm, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "p", p);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
    }
  }
  auto result = as_variable(baseType->norm(self_, p));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::renorm_out(Tensor & result, const Tensor & self, Scalar p, int64_t dim, Scalar maxnorm) const {
  profiler::RecordFunction profiler("renorm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("renorm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("renorm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::renorm_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "p", p);
      setposattr(trace_info.n, 3, "dim", dim);
      setposattr(trace_info.n, 4, "maxnorm", maxnorm);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::maxnorm, maxnorm);
    }
  }
  baseType->renorm_out(result_, self_, p, dim, maxnorm);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::renorm(const Tensor & self, Scalar p, int64_t dim, Scalar maxnorm) const {
  profiler::RecordFunction profiler("renorm");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<RenormBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RenormBackward>(new RenormBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->p = p;
    grad_fn->dim = dim;
    grad_fn->maxnorm = maxnorm;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::renorm, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "p", p);
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "maxnorm", maxnorm);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::maxnorm, maxnorm);
    }
  }
  auto result = as_variable(baseType->renorm(self_, p, dim, maxnorm));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::renorm_(Tensor & self, Scalar p, int64_t dim, Scalar maxnorm) const {
  profiler::RecordFunction profiler("renorm_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RenormBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RenormBackward>(new RenormBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->p = p;
    grad_fn->dim = dim;
    grad_fn->maxnorm = maxnorm;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::renorm, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "p", p);
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "maxnorm", maxnorm);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::maxnorm, maxnorm);
    }
  }
  baseType->renorm_(self_, p, dim, maxnorm);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::s_dist(const Tensor & self, const Tensor & other, Scalar p) const {
  profiler::RecordFunction profiler("dist");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<DistBackward> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<DistBackward>(new DistBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->other_ = SavedVariable(other, false);
    grad_fn->p = p;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::dist, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "p", p);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
    }
  }
  auto result = as_variable(baseType->s_dist(self_, other_, p));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::reciprocal_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("reciprocal_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("reciprocal");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("reciprocal");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reciprocal_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->reciprocal_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::reciprocal(const Tensor & self) const {
  profiler::RecordFunction profiler("reciprocal");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReciprocalBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReciprocalBackward>(new ReciprocalBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reciprocal, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->reciprocal(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::reciprocal_(Tensor & self) const {
  profiler::RecordFunction profiler("reciprocal_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ReciprocalBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReciprocalBackward>(new ReciprocalBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reciprocal, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->reciprocal_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::neg_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("neg_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("neg");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("neg");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::neg_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->neg_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::neg(const Tensor & self) const {
  profiler::RecordFunction profiler("neg");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<NegBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NegBackward>(new NegBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::neg, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->neg(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::neg_(Tensor & self) const {
  profiler::RecordFunction profiler("neg_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<NegBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NegBackward>(new NegBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::neg, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->neg_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_atan2_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("atan2_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("atan2");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("atan2");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::atan2_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_atan2_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_atan2(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("atan2");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<Atan2Backward> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Atan2Backward>(new Atan2Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::atan2, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_atan2(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_atan2_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("atan2_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Atan2Backward> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<Atan2Backward>(new Atan2Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::atan2, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_atan2_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::pow_out(Tensor & result, const Tensor & self, Scalar exponent) const {
  profiler::RecordFunction profiler("pow_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("pow");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("pow");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "exponent", exponent);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::exponent, exponent);
    }
  }
  baseType->pow_out(result_, self_, exponent);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::pow(const Tensor & self, Scalar exponent) const {
  profiler::RecordFunction profiler("pow");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<PowBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PowBackward0>(new PowBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->exponent = exponent;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "exponent", exponent);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::exponent, exponent);
    }
  }
  auto result = as_variable(baseType->pow(self_, exponent));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_pow_out(Tensor & result, const Tensor & self, const Tensor & exponent) const {
  profiler::RecordFunction profiler("pow_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& exponent_ = unpack(exponent, "exponent", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, exponent )) {
    throw_error_out_requires_grad("pow");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("pow");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, exponent )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow_out, { result, self, exponent } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_pow_out(result_, self_, exponent_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_pow(const Tensor & self, const Tensor & exponent) const {
  profiler::RecordFunction profiler("pow");
  auto& self_ = unpack(self, "self", 0);
  auto& exponent_ = unpack(exponent, "exponent", 1);
  std::shared_ptr<PowBackward1> grad_fn;
  if (compute_requires_grad( self, exponent )) {
    grad_fn = std::shared_ptr<PowBackward1>(new PowBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, exponent ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->exponent_ = SavedVariable(exponent, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, exponent )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow, { self, exponent } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_pow(self_, exponent_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::pow_out(Tensor & result, Scalar base, const Tensor & self) const {
  profiler::RecordFunction profiler("pow_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("pow");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("pow");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "base", base);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::base, base);
    }
  }
  baseType->pow_out(result_, base, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::pow(Scalar base, const Tensor & self) const {
  profiler::RecordFunction profiler("pow");
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for pow is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "base", base);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::base, base);
    }
  }
  auto result = as_variable(baseType->pow(base, self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::pow_(Tensor & self, Scalar exponent) const {
  profiler::RecordFunction profiler("pow_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<PowBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PowBackward0>(new PowBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->exponent = exponent;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "exponent", exponent);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::exponent, exponent);
    }
  }
  baseType->pow_(self_, exponent);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_pow_(Tensor & self, const Tensor & exponent) const {
  profiler::RecordFunction profiler("pow_");
  auto& self_ = unpack(self, "self", 0);
  auto& exponent_ = unpack(exponent, "exponent", 1);
  check_inplace(self);
  std::shared_ptr<PowBackward1> grad_fn;
  if (compute_requires_grad( self, exponent )) {
    grad_fn = std::shared_ptr<PowBackward1>(new PowBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, exponent ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->exponent_ = SavedVariable(exponent, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, exponent )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pow, { self, exponent } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_pow_(self_, exponent_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_lerp_out(Tensor & result, const Tensor & self, const Tensor & end, Scalar weight) const {
  profiler::RecordFunction profiler("lerp_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& end_ = unpack(end, "end", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, end )) {
    throw_error_out_requires_grad("lerp");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("lerp");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, end )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lerp_out, { result, self, end } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "weight", weight);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight, weight);
    }
  }
  baseType->s_lerp_out(result_, self_, end_, weight);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_lerp(const Tensor & self, const Tensor & end, Scalar weight) const {
  profiler::RecordFunction profiler("lerp");
  auto& self_ = unpack(self, "self", 0);
  auto& end_ = unpack(end, "end", 1);
  std::shared_ptr<LerpBackward> grad_fn;
  if (compute_requires_grad( self, end )) {
    grad_fn = std::shared_ptr<LerpBackward>(new LerpBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, end ));
    grad_fn->weight = weight;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, end )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lerp, { self, end } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "weight", weight);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight, weight);
    }
  }
  auto result = as_variable(baseType->s_lerp(self_, end_, weight));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_lerp_(Tensor & self, const Tensor & end, Scalar weight) const {
  profiler::RecordFunction profiler("lerp_");
  auto& self_ = unpack(self, "self", 0);
  auto& end_ = unpack(end, "end", 1);
  check_inplace(self);
  std::shared_ptr<LerpBackward> grad_fn;
  if (compute_requires_grad( self, end )) {
    grad_fn = std::shared_ptr<LerpBackward>(new LerpBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, end ));
    grad_fn->weight = weight;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, end )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::lerp, { self, end } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "weight", weight);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight, weight);
    }
  }
  baseType->s_lerp_(self_, end_, weight);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::_linspace_out(Tensor & result, Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("_linspace_out");
  auto& result_ = unpack(result, "result", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_linspace_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "steps", steps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::steps, steps);
    }
  }
  baseType->_linspace_out(result_, start, end, steps);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_linspace(Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("_linspace");
  auto result = as_variable(baseType->_linspace(start, end, steps));
  return result;
}
Tensor & VariableType::_logspace_out(Tensor & result, Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("_logspace_out");
  auto& result_ = unpack(result, "result", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_logspace_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "steps", steps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::steps, steps);
    }
  }
  baseType->_logspace_out(result_, start, end, steps);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_logspace(Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("_logspace");
  auto result = as_variable(baseType->_logspace(start, end, steps));
  return result;
}
Tensor & VariableType::histc_out(Tensor & result, const Tensor & self, int64_t bins, Scalar min, Scalar max) const {
  profiler::RecordFunction profiler("histc_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("histc");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("histc");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::histc_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "bins", bins);
      setposattr(trace_info.n, 3, "min", min);
      setposattr(trace_info.n, 4, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::bins, bins);
      setattr(trace_info.n, jit::attr::min, min);
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  baseType->histc_out(result_, self_, bins, min, max);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::histc(const Tensor & self, int64_t bins, Scalar min, Scalar max) const {
  profiler::RecordFunction profiler("histc");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<HistcBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<HistcBackward>(new HistcBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::histc, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "bins", bins);
      setposattr(trace_info.n, 2, "min", min);
      setposattr(trace_info.n, 3, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::bins, bins);
      setattr(trace_info.n, jit::attr::min, min);
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  auto result = as_variable(baseType->histc(self_, bins, min, max));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::zero_(Tensor & self) const {
  profiler::RecordFunction profiler("zero_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ZeroBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ZeroBackward>(new ZeroBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::zero, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->zero_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::_sumall(const Tensor & self) const {
  profiler::RecordFunction profiler("_sumall");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _sumall is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sumall, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_sumall(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_th_sum_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_th_sum_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_th_sum");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_th_sum");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_th_sum_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->_th_sum_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_th_sum(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_th_sum");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _th_sum is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_th_sum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->_th_sum(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_prodall(const Tensor & self) const {
  profiler::RecordFunction profiler("_prodall");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _prodall is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_prodall, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_prodall(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_th_prod_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_th_prod_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_th_prod");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_th_prod");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_th_prod_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->_th_prod_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_th_prod(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_th_prod");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _th_prod is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_th_prod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->_th_prod(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_cumsum_out(Tensor & result, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("_cumsum_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_cumsum");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_cumsum");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cumsum_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->_cumsum_out(result_, self_, dim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_cumsum(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("_cumsum");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<CumsumBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CumsumBackward>(new CumsumBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cumsum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->_cumsum(self_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_cumprod_out(Tensor & result, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("_cumprod_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_cumprod");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_cumprod");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cumprod_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->_cumprod_out(result_, self_, dim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_cumprod(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("_cumprod");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<CumprodBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CumprodBackward>(new CumprodBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cumprod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->_cumprod(self_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sign_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("sign_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sign");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sign");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sign_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sign_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::sign(const Tensor & self) const {
  profiler::RecordFunction profiler("sign");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SignBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SignBackward>(new SignBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sign, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->sign(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sign_(Tensor & self) const {
  profiler::RecordFunction profiler("sign_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SignBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SignBackward>(new SignBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sign, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sign_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::trace(const Tensor & self) const {
  profiler::RecordFunction profiler("trace");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TraceBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TraceBackward>(new TraceBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::trace, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->trace(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::add_out(Tensor & result, const Tensor & self, Scalar other, Scalar alpha) const {
  profiler::RecordFunction profiler("add_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("add");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("add");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      setposattr(trace_info.n, 3, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->add_out(result_, self_, other, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::add(const Tensor & self, Scalar other, Scalar alpha) const {
  profiler::RecordFunction profiler("add");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AddBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AddBackward0>(new AddBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->add(self_, other, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_add_out(Tensor & result, const Tensor & self, const Tensor & other, Scalar alpha) const {
  profiler::RecordFunction profiler("add_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("add");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("add");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_add_out(result_, self_, other_, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_add(const Tensor & self, const Tensor & other, Scalar alpha) const {
  profiler::RecordFunction profiler("add");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<AddBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<AddBackward1>(new AddBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->alpha = alpha;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s_add(self_, other_, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::add_out(Tensor & result, const Tensor & self, SparseTensor other, Scalar alpha) const {
  profiler::RecordFunction profiler("add_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other.tref )) {
    throw_error_out_requires_grad("add");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("add");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      setposattr(trace_info.n, 3, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->add_out(result_, self_, other_, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::add(const Tensor & self, SparseTensor other, Scalar alpha) const {
  profiler::RecordFunction profiler("add");
  auto& self_ = unpack(self, "self", 0);
  auto other_ = unpack(other, "other", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other.tref )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for add is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other.tref ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->add(self_, other_, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::add_(Tensor & self, Scalar other, Scalar alpha) const {
  profiler::RecordFunction profiler("add_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<AddBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AddBackward0>(new AddBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->add_(self_, other, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_add_(Tensor & self, const Tensor & other, Scalar alpha) const {
  profiler::RecordFunction profiler("add_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<AddBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<AddBackward1>(new AddBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->alpha = alpha;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_add_(self_, other_, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::add_(Tensor & self, SparseTensor other, Scalar alpha) const {
  profiler::RecordFunction profiler("add_");
  auto& self_ = unpack(self, "self", 0);
  auto other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, other.tref )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for add_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other.tref ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::add, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->add_(self_, other_, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::sub_out(Tensor & result, const Tensor & self, Scalar other, Scalar alpha) const {
  profiler::RecordFunction profiler("sub_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sub");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sub");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sub_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      setposattr(trace_info.n, 3, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->sub_out(result_, self_, other, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::sub(const Tensor & self, Scalar other, Scalar alpha) const {
  profiler::RecordFunction profiler("sub");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SubBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SubBackward0>(new SubBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sub, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->sub(self_, other, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_sub_out(Tensor & result, const Tensor & self, const Tensor & other, Scalar alpha) const {
  profiler::RecordFunction profiler("sub_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("sub");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sub");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sub_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_sub_out(result_, self_, other_, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_sub(const Tensor & self, const Tensor & other, Scalar alpha) const {
  profiler::RecordFunction profiler("sub");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<SubBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<SubBackward1>(new SubBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->alpha = alpha;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sub, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s_sub(self_, other_, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sub_(Tensor & self, Scalar other, Scalar alpha) const {
  profiler::RecordFunction profiler("sub_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SubBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SubBackward0>(new SubBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sub, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->sub_(self_, other, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_sub_(Tensor & self, const Tensor & other, Scalar alpha) const {
  profiler::RecordFunction profiler("sub_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<SubBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<SubBackward1>(new SubBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->alpha = alpha;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sub, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_sub_(self_, other_, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::mul_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("mul_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("mul");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("mul");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mul_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->mul_out(result_, self_, other);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::mul(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("mul");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MulBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MulBackward0>(new MulBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->other = other;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mul, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->mul(self_, other));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_mul_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("mul_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("mul");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("mul");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mul_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_mul_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_mul(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("mul");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<MulBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<MulBackward1>(new MulBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mul, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_mul(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::mul_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("mul_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<MulBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MulBackward0>(new MulBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->other = other;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mul, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->mul_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_mul_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("mul_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<MulBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<MulBackward1>(new MulBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mul, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_mul_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::div_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("div_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("div");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("div");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::div_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->div_out(result_, self_, other);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::div(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("div");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<DivBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DivBackward0>(new DivBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->other = other;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::div, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->div(self_, other));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_div_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("div_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("div");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("div");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::div_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_div_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_div(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("div");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<DivBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<DivBackward1>(new DivBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::div, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_div(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::div_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("div_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<DivBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DivBackward0>(new DivBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->other = other;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::div, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->div_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_div_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("div_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<DivBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<DivBackward1>(new DivBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::div, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_div_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::fmod_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("fmod_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("fmod");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("fmod");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fmod_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->fmod_out(result_, self_, other);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::fmod(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("fmod");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<FmodBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FmodBackward0>(new FmodBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fmod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->fmod(self_, other));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_fmod_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("fmod_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("fmod");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("fmod");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fmod_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_fmod_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_fmod(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("fmod");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<FmodBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<FmodBackward1>(new FmodBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fmod, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_fmod(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::fmod_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("fmod_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<FmodBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FmodBackward0>(new FmodBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fmod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->fmod_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_fmod_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("fmod_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  std::shared_ptr<FmodBackward1> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<FmodBackward1>(new FmodBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fmod, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_fmod_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::remainder_out(Tensor & result, const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("remainder_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("remainder");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("remainder");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::remainder_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->remainder_out(result_, self_, other);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::remainder(const Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("remainder");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<RemainderBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RemainderBackward0>(new RemainderBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::remainder, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  auto result = as_variable(baseType->remainder(self_, other));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_remainder_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("remainder_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("remainder");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("remainder");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::remainder_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_remainder_out(result_, self_, other_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_remainder(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("remainder");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_no_requires_grad(other, "other");
  std::shared_ptr<RemainderBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RemainderBackward1>(new RemainderBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::remainder, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->s_remainder(self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::remainder_(Tensor & self, Scalar other) const {
  profiler::RecordFunction profiler("remainder_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RemainderBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RemainderBackward0>(new RemainderBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::remainder, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "other", other);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::other, other);
    }
  }
  baseType->remainder_(self_, other);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_remainder_(Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("remainder_");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  check_inplace(self);
  check_no_requires_grad(other, "other");
  std::shared_ptr<RemainderBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RemainderBackward1>(new RemainderBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::remainder, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->s_remainder_(self_, other_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::clamp_out(Tensor & result, const Tensor & self, Scalar min, Scalar max) const {
  profiler::RecordFunction profiler("clamp_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("clamp");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("clamp");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "min", min);
      setposattr(trace_info.n, 3, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min, min);
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  baseType->clamp_out(result_, self_, min, max);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::clamp(const Tensor & self, Scalar min, Scalar max) const {
  profiler::RecordFunction profiler("clamp");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ClampBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ClampBackward>(new ClampBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->min = min;
    grad_fn->max = max;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min", min);
      setposattr(trace_info.n, 2, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min, min);
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  auto result = as_variable(baseType->clamp(self_, min, max));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::clamp_(Tensor & self, Scalar min, Scalar max) const {
  profiler::RecordFunction profiler("clamp_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ClampBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ClampBackward>(new ClampBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->min = min;
    grad_fn->max = max;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min", min);
      setposattr(trace_info.n, 2, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min, min);
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  baseType->clamp_(self_, min, max);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::clamp_min_out(Tensor & result, const Tensor & self, Scalar min) const {
  profiler::RecordFunction profiler("clamp_min_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("clamp_min");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("clamp_min");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_min_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "min", min);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min, min);
    }
  }
  baseType->clamp_min_out(result_, self_, min);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::clamp_min(const Tensor & self, Scalar min) const {
  profiler::RecordFunction profiler("clamp_min");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ClampMinBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ClampMinBackward>(new ClampMinBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->min = min;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_min, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min", min);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min, min);
    }
  }
  auto result = as_variable(baseType->clamp_min(self_, min));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::clamp_min_(Tensor & self, Scalar min) const {
  profiler::RecordFunction profiler("clamp_min_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ClampMinBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ClampMinBackward>(new ClampMinBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->min = min;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_min, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min", min);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min, min);
    }
  }
  baseType->clamp_min_(self_, min);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::clamp_max_out(Tensor & result, const Tensor & self, Scalar max) const {
  profiler::RecordFunction profiler("clamp_max_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("clamp_max");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("clamp_max");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_max_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  baseType->clamp_max_out(result_, self_, max);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::clamp_max(const Tensor & self, Scalar max) const {
  profiler::RecordFunction profiler("clamp_max");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ClampMaxBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ClampMaxBackward>(new ClampMaxBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->max = max;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_max, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  auto result = as_variable(baseType->clamp_max(self_, max));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::clamp_max_(Tensor & self, Scalar max) const {
  profiler::RecordFunction profiler("clamp_max_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ClampMaxBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ClampMaxBackward>(new ClampMaxBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
    grad_fn->max = max;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::clamp_max, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "max", max);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::max, max);
    }
  }
  baseType->clamp_max_(self_, max);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::_dot(const Tensor & self, const Tensor & tensor) const {
  profiler::RecordFunction profiler("_dot");
  auto& self_ = unpack(self, "self", 0);
  auto& tensor_ = unpack(tensor, "tensor", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, tensor )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _dot is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, tensor ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensor )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_dot, { self, tensor } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_dot(self_, tensor_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::tril_out(Tensor & result, const Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("tril_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("tril");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("tril");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tril_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  baseType->tril_out(result_, self_, diagonal);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::tril(const Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("tril");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TrilBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TrilBackward>(new TrilBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->diagonal = diagonal;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tril, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  auto result = as_variable(baseType->tril(self_, diagonal));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::tril_(Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("tril_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TrilBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TrilBackward>(new TrilBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->diagonal = diagonal;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tril, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  baseType->tril_(self_, diagonal);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::triu_out(Tensor & result, const Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("triu_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("triu");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("triu");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::triu_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  baseType->triu_out(result_, self_, diagonal);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::triu(const Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("triu");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TriuBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TriuBackward>(new TriuBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->diagonal = diagonal;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::triu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  auto result = as_variable(baseType->triu(self_, diagonal));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::triu_(Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("triu_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TriuBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TriuBackward>(new TriuBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->diagonal = diagonal;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::triu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  baseType->triu_(self_, diagonal);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::cross_out(Tensor & result, const Tensor & self, const Tensor & other, int64_t dim) const {
  profiler::RecordFunction profiler("cross_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, other )) {
    throw_error_out_requires_grad("cross");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("cross");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cross_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->cross_out(result_, self_, other_, dim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::cross(const Tensor & self, const Tensor & other, int64_t dim) const {
  profiler::RecordFunction profiler("cross");
  auto& self_ = unpack(self, "self", 0);
  auto& other_ = unpack(other, "other", 1);
  std::shared_ptr<CrossBackward> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<CrossBackward>(new CrossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
    grad_fn->other_ = SavedVariable(other, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cross, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->cross(self_, other_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::diag_out(Tensor & result, const Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("diag_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("diag");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("diag");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::diag_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  baseType->diag_out(result_, self_, diagonal);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::diag(const Tensor & self, int64_t diagonal) const {
  profiler::RecordFunction profiler("diag");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<DiagBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DiagBackward>(new DiagBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->diagonal = diagonal;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::diag, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "diagonal", diagonal);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::diagonal, diagonal);
    }
  }
  auto result = as_variable(baseType->diag(self_, diagonal));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_addmm_out(Tensor & result, const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& mat1_ = unpack(mat1, "mat1", 2);
  auto& mat2_ = unpack(mat2, "mat2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, mat1, mat2 )) {
    throw_error_out_requires_grad("addmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("addmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmm_out, { result, self, mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_addmm_out(result_, self_, mat1_, mat2_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_addmm(const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmm");
  auto& self_ = unpack(self, "self", 0);
  auto& mat1_ = unpack(mat1, "mat1", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  std::shared_ptr<AddmmBackward> grad_fn;
  if (compute_requires_grad( self, mat1, mat2 )) {
    grad_fn = std::shared_ptr<AddmmBackward>(new AddmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat1, mat2 ));
    grad_fn->mat1_sizes = mat1.sizes();
    grad_fn->mat1_ = SavedVariable(mat1, false);
    grad_fn->mat2_ = SavedVariable(mat2, false);
    grad_fn->alpha = alpha;
    grad_fn->mat2_sizes = mat2.sizes();
    grad_fn->beta = beta;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmm, { self, mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s_addmm(self_, mat1_, mat2_, beta, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::addmm_out(Tensor & result, const Tensor & self, SparseTensor mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto mat1_ = unpack(mat1, "mat1", 2);
  auto& mat2_ = unpack(mat2, "mat2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, mat1.tref, mat2 )) {
    throw_error_out_requires_grad("addmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("addmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmm_out, { result, self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "mat1", mat1);
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::mat1, mat1);
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->addmm_out(result_, self_, mat1_, mat2_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::addmm(const Tensor & self, SparseTensor mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmm");
  auto& self_ = unpack(self, "self", 0);
  auto mat1_ = unpack(mat1, "mat1", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, mat1.tref, mat2 )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for addmm is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat1.tref, mat2 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmm, { self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "mat1", mat1);
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::mat1, mat1);
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->addmm(self_, mat1_, mat2_, beta, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::addmm_(Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmm_");
  auto& self_ = unpack(self, "self", 0);
  auto& mat1_ = unpack(mat1, "mat1", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  check_inplace(self);
  std::shared_ptr<AddmmBackward> grad_fn;
  if (compute_requires_grad( self, mat1, mat2 )) {
    grad_fn = std::shared_ptr<AddmmBackward>(new AddmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat1, mat2 ));
    grad_fn->mat1_sizes = mat1.sizes();
    grad_fn->mat1_ = SavedVariable(mat1, false);
    grad_fn->mat2_ = SavedVariable(mat2, false);
    grad_fn->alpha = alpha;
    grad_fn->mat2_sizes = mat2.sizes();
    grad_fn->beta = beta;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmm, { self, mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->addmm_(self_, mat1_, mat2_, beta, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::addmm_(Tensor & self, SparseTensor mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmm_");
  auto& self_ = unpack(self, "self", 0);
  auto mat1_ = unpack(mat1, "mat1", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, mat1.tref, mat2 )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for addmm_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat1.tref, mat2 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmm, { self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "mat1", mat1);
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::mat1, mat1);
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->addmm_(self_, mat1_, mat2_, beta, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s__addmv_out(Tensor & result, const Tensor & self, const Tensor & mat, const Tensor & vec, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("_addmv_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& mat_ = unpack(mat, "mat", 2);
  auto& vec_ = unpack(vec, "vec", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, mat, vec )) {
    throw_error_out_requires_grad("_addmv");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_addmv");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_addmv_out, { result, self, mat, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s__addmv_out(result_, self_, mat_, vec_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s__addmv(const Tensor & self, const Tensor & mat, const Tensor & vec, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("_addmv");
  auto& self_ = unpack(self, "self", 0);
  auto& mat_ = unpack(mat, "mat", 1);
  auto& vec_ = unpack(vec, "vec", 2);
  std::shared_ptr<AddmvBackward> grad_fn;
  if (compute_requires_grad( self, mat, vec )) {
    grad_fn = std::shared_ptr<AddmvBackward>(new AddmvBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat, vec ));
    grad_fn->vec_ = SavedVariable(vec, false);
    grad_fn->alpha = alpha;
    grad_fn->beta = beta;
    grad_fn->mat_ = SavedVariable(mat, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_addmv, { self, mat, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s__addmv(self_, mat_, vec_, beta, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_addmv_(Tensor & self, const Tensor & mat, const Tensor & vec, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("_addmv_");
  auto& self_ = unpack(self, "self", 0);
  auto& mat_ = unpack(mat, "mat", 1);
  auto& vec_ = unpack(vec, "vec", 2);
  check_inplace(self);
  std::shared_ptr<AddmvBackward> grad_fn;
  if (compute_requires_grad( self, mat, vec )) {
    grad_fn = std::shared_ptr<AddmvBackward>(new AddmvBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat, vec ));
    grad_fn->vec_ = SavedVariable(vec, false);
    grad_fn->alpha = alpha;
    grad_fn->beta = beta;
    grad_fn->mat_ = SavedVariable(mat, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_addmv, { self, mat, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->_addmv_(self_, mat_, vec_, beta, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s__addr_out(Tensor & result, const Tensor & self, const Tensor & vec1, const Tensor & vec2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("_addr_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& vec1_ = unpack(vec1, "vec1", 2);
  auto& vec2_ = unpack(vec2, "vec2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, vec1, vec2 )) {
    throw_error_out_requires_grad("_addr");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_addr");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, vec1, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_addr_out, { result, self, vec1, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s__addr_out(result_, self_, vec1_, vec2_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s__addr(const Tensor & self, const Tensor & vec1, const Tensor & vec2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("_addr");
  auto& self_ = unpack(self, "self", 0);
  auto& vec1_ = unpack(vec1, "vec1", 1);
  auto& vec2_ = unpack(vec2, "vec2", 2);
  std::shared_ptr<AddrBackward> grad_fn;
  if (compute_requires_grad( self, vec1, vec2 )) {
    grad_fn = std::shared_ptr<AddrBackward>(new AddrBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, vec1, vec2 ));
    grad_fn->beta = beta;
    grad_fn->vec2_ = SavedVariable(vec2, false);
    grad_fn->alpha = alpha;
    grad_fn->vec1_ = SavedVariable(vec1, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec1, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_addr, { self, vec1, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s__addr(self_, vec1_, vec2_, beta, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_addr_(Tensor & self, const Tensor & vec1, const Tensor & vec2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("_addr_");
  auto& self_ = unpack(self, "self", 0);
  auto& vec1_ = unpack(vec1, "vec1", 1);
  auto& vec2_ = unpack(vec2, "vec2", 2);
  check_inplace(self);
  std::shared_ptr<AddrBackward> grad_fn;
  if (compute_requires_grad( self, vec1, vec2 )) {
    grad_fn = std::shared_ptr<AddrBackward>(new AddrBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, vec1, vec2 ));
    grad_fn->beta = beta;
    grad_fn->vec2_ = SavedVariable(vec2, false);
    grad_fn->alpha = alpha;
    grad_fn->vec1_ = SavedVariable(vec1, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec1, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_addr, { self, vec1, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->_addr_(self_, vec1_, vec2_, beta, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::_ger_out(Tensor & result, const Tensor & self, const Tensor & vec2) const {
  profiler::RecordFunction profiler("_ger_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& vec2_ = unpack(vec2, "vec2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, vec2 )) {
    throw_error_out_requires_grad("_ger");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_ger");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_ger_out, { result, self, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_ger_out(result_, self_, vec2_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_ger(const Tensor & self, const Tensor & vec2) const {
  profiler::RecordFunction profiler("_ger");
  auto& self_ = unpack(self, "self", 0);
  auto& vec2_ = unpack(vec2, "vec2", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, vec2 )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _ger is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, vec2 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_ger, { self, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_ger(self_, vec2_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_mv_out(Tensor & result, const Tensor & self, const Tensor & vec) const {
  profiler::RecordFunction profiler("_mv_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& vec_ = unpack(vec, "vec", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, vec )) {
    throw_error_out_requires_grad("_mv");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_mv");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_mv_out, { result, self, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_mv_out(result_, self_, vec_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_mv(const Tensor & self, const Tensor & vec) const {
  profiler::RecordFunction profiler("_mv");
  auto& self_ = unpack(self, "self", 0);
  auto& vec_ = unpack(vec, "vec", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, vec )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _mv is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, vec ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_mv, { self, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_mv(self_, vec_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_mm_out(Tensor & result, const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("_mm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, mat2 )) {
    throw_error_out_requires_grad("_mm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_mm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_mm_out, { result, self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_mm_out(result_, self_, mat2_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::_mm(const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("_mm");
  auto& self_ = unpack(self, "self", 0);
  auto& mat2_ = unpack(mat2, "mat2", 1);
  std::shared_ptr<MmBackward> grad_fn;
  if (compute_requires_grad( self, mat2 )) {
    grad_fn = std::shared_ptr<MmBackward>(new MmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat2 ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->mat2_sizes = mat2.sizes();
    grad_fn->mat2_ = SavedVariable(mat2, false);
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_mm, { self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_mm(self_, mat2_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::bmm_out(Tensor & result, const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("bmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, mat2 )) {
    throw_error_out_requires_grad("bmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("bmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::bmm_out, { result, self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->bmm_out(result_, self_, mat2_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::bmm(const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("bmm");
  auto& self_ = unpack(self, "self", 0);
  auto& mat2_ = unpack(mat2, "mat2", 1);
  std::shared_ptr<BmmBackward> grad_fn;
  if (compute_requires_grad( self, mat2 )) {
    grad_fn = std::shared_ptr<BmmBackward>(new BmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mat2 ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->mat2_ = SavedVariable(mat2, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::bmm, { self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->bmm(self_, mat2_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_addbmm_out(Tensor & result, const Tensor & self, const Tensor & batch1, const Tensor & batch2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addbmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& batch1_ = unpack(batch1, "batch1", 2);
  auto& batch2_ = unpack(batch2, "batch2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, batch1, batch2 )) {
    throw_error_out_requires_grad("addbmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("addbmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, batch1, batch2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addbmm_out, { result, self, batch1, batch2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_addbmm_out(result_, self_, batch1_, batch2_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_addbmm(const Tensor & self, const Tensor & batch1, const Tensor & batch2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addbmm");
  auto& self_ = unpack(self, "self", 0);
  auto& batch1_ = unpack(batch1, "batch1", 1);
  auto& batch2_ = unpack(batch2, "batch2", 2);
  std::shared_ptr<AddbmmBackward> grad_fn;
  if (compute_requires_grad( self, batch1, batch2 )) {
    grad_fn = std::shared_ptr<AddbmmBackward>(new AddbmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, batch1, batch2 ));
    grad_fn->batch1_argsize_0 = batch1.size(0);
    grad_fn->batch1_argsize_1 = batch1.size(1);
    grad_fn->batch2_argsize_2 = batch2.size(2);
    grad_fn->batch2_ = SavedVariable(batch2, false);
    grad_fn->alpha = alpha;
    grad_fn->batch1_ = SavedVariable(batch1, false);
    grad_fn->beta = beta;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, batch1, batch2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addbmm, { self, batch1, batch2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s_addbmm(self_, batch1_, batch2_, beta, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::addbmm_(Tensor & self, const Tensor & batch1, const Tensor & batch2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addbmm_");
  auto& self_ = unpack(self, "self", 0);
  auto& batch1_ = unpack(batch1, "batch1", 1);
  auto& batch2_ = unpack(batch2, "batch2", 2);
  check_inplace(self);
  std::shared_ptr<AddbmmBackward> grad_fn;
  if (compute_requires_grad( self, batch1, batch2 )) {
    grad_fn = std::shared_ptr<AddbmmBackward>(new AddbmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, batch1, batch2 ));
    grad_fn->batch1_argsize_0 = batch1.size(0);
    grad_fn->batch1_argsize_1 = batch1.size(1);
    grad_fn->batch2_argsize_2 = batch2.size(2);
    grad_fn->batch2_ = SavedVariable(batch2, false);
    grad_fn->alpha = alpha;
    grad_fn->batch1_ = SavedVariable(batch1, false);
    grad_fn->beta = beta;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, batch1, batch2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addbmm, { self, batch1, batch2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->addbmm_(self_, batch1_, batch2_, beta, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_baddbmm_out(Tensor & result, const Tensor & self, const Tensor & batch1, const Tensor & batch2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("baddbmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& batch1_ = unpack(batch1, "batch1", 2);
  auto& batch2_ = unpack(batch2, "batch2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, batch1, batch2 )) {
    throw_error_out_requires_grad("baddbmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("baddbmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, batch1, batch2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::baddbmm_out, { result, self, batch1, batch2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->s_baddbmm_out(result_, self_, batch1_, batch2_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_baddbmm(const Tensor & self, const Tensor & batch1, const Tensor & batch2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("baddbmm");
  auto& self_ = unpack(self, "self", 0);
  auto& batch1_ = unpack(batch1, "batch1", 1);
  auto& batch2_ = unpack(batch2, "batch2", 2);
  std::shared_ptr<BaddbmmBackward> grad_fn;
  if (compute_requires_grad( self, batch1, batch2 )) {
    grad_fn = std::shared_ptr<BaddbmmBackward>(new BaddbmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, batch1, batch2 ));
    grad_fn->batch2_ = SavedVariable(batch2, false);
    grad_fn->alpha = alpha;
    grad_fn->batch1_ = SavedVariable(batch1, false);
    grad_fn->beta = beta;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, batch1, batch2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::baddbmm, { self, batch1, batch2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = as_variable(baseType->s_baddbmm(self_, batch1_, batch2_, beta, alpha));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::baddbmm_(Tensor & self, const Tensor & batch1, const Tensor & batch2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("baddbmm_");
  auto& self_ = unpack(self, "self", 0);
  auto& batch1_ = unpack(batch1, "batch1", 1);
  auto& batch2_ = unpack(batch2, "batch2", 2);
  check_inplace(self);
  std::shared_ptr<BaddbmmBackward> grad_fn;
  if (compute_requires_grad( self, batch1, batch2 )) {
    grad_fn = std::shared_ptr<BaddbmmBackward>(new BaddbmmBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, batch1, batch2 ));
    grad_fn->batch2_ = SavedVariable(batch2, false);
    grad_fn->alpha = alpha;
    grad_fn->batch1_ = SavedVariable(batch1, false);
    grad_fn->beta = beta;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, batch1, batch2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::baddbmm, { self, batch1, batch2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->baddbmm_(self_, batch1_, batch2_, beta, alpha);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_addcmul_out(Tensor & result, const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value) const {
  profiler::RecordFunction profiler("addcmul_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& tensor1_ = unpack(tensor1, "tensor1", 2);
  auto& tensor2_ = unpack(tensor2, "tensor2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, tensor1, tensor2 )) {
    throw_error_out_requires_grad("addcmul");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("addcmul");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, tensor1, tensor2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addcmul_out, { result, self, tensor1, tensor2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->s_addcmul_out(result_, self_, tensor1_, tensor2_, value);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_addcmul(const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value) const {
  profiler::RecordFunction profiler("addcmul");
  auto& self_ = unpack(self, "self", 0);
  auto& tensor1_ = unpack(tensor1, "tensor1", 1);
  auto& tensor2_ = unpack(tensor2, "tensor2", 2);
  std::shared_ptr<AddcmulBackward> grad_fn;
  if (compute_requires_grad( self, tensor1, tensor2 )) {
    grad_fn = std::shared_ptr<AddcmulBackward>(new AddcmulBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, tensor1, tensor2 ));
    grad_fn->tensor2_ = SavedVariable(tensor2, false);
    grad_fn->value = value;
    grad_fn->tensor1_ = SavedVariable(tensor1, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensor1, tensor2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addcmul, { self, tensor1, tensor2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  auto result = as_variable(baseType->s_addcmul(self_, tensor1_, tensor2_, value));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_addcmul_(Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value) const {
  profiler::RecordFunction profiler("addcmul_");
  auto& self_ = unpack(self, "self", 0);
  auto& tensor1_ = unpack(tensor1, "tensor1", 1);
  auto& tensor2_ = unpack(tensor2, "tensor2", 2);
  check_inplace(self);
  std::shared_ptr<AddcmulBackward> grad_fn;
  if (compute_requires_grad( self, tensor1, tensor2 )) {
    grad_fn = std::shared_ptr<AddcmulBackward>(new AddcmulBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, tensor1, tensor2 ));
    grad_fn->tensor2_ = SavedVariable(tensor2, false);
    grad_fn->value = value;
    grad_fn->tensor1_ = SavedVariable(tensor1, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensor1, tensor2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addcmul, { self, tensor1, tensor2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->s_addcmul_(self_, tensor1_, tensor2_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::s_addcdiv_out(Tensor & result, const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value) const {
  profiler::RecordFunction profiler("addcdiv_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& tensor1_ = unpack(tensor1, "tensor1", 2);
  auto& tensor2_ = unpack(tensor2, "tensor2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, tensor1, tensor2 )) {
    throw_error_out_requires_grad("addcdiv");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("addcdiv");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, tensor1, tensor2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addcdiv_out, { result, self, tensor1, tensor2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->s_addcdiv_out(result_, self_, tensor1_, tensor2_, value);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::s_addcdiv(const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value) const {
  profiler::RecordFunction profiler("addcdiv");
  auto& self_ = unpack(self, "self", 0);
  auto& tensor1_ = unpack(tensor1, "tensor1", 1);
  auto& tensor2_ = unpack(tensor2, "tensor2", 2);
  std::shared_ptr<AddcdivBackward> grad_fn;
  if (compute_requires_grad( self, tensor1, tensor2 )) {
    grad_fn = std::shared_ptr<AddcdivBackward>(new AddcdivBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, tensor1, tensor2 ));
    grad_fn->tensor2_ = SavedVariable(tensor2, false);
    grad_fn->value = value;
    grad_fn->tensor1_ = SavedVariable(tensor1, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensor1, tensor2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addcdiv, { self, tensor1, tensor2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  auto result = as_variable(baseType->s_addcdiv(self_, tensor1_, tensor2_, value));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::s_addcdiv_(Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value) const {
  profiler::RecordFunction profiler("addcdiv_");
  auto& self_ = unpack(self, "self", 0);
  auto& tensor1_ = unpack(tensor1, "tensor1", 1);
  auto& tensor2_ = unpack(tensor2, "tensor2", 2);
  check_inplace(self);
  std::shared_ptr<AddcdivBackward> grad_fn;
  if (compute_requires_grad( self, tensor1, tensor2 )) {
    grad_fn = std::shared_ptr<AddcdivBackward>(new AddcdivBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, tensor1, tensor2 ));
    grad_fn->tensor2_ = SavedVariable(tensor2, false);
    grad_fn->value = value;
    grad_fn->tensor1_ = SavedVariable(tensor1, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensor1, tensor2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addcdiv, { self, tensor1, tensor2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->s_addcdiv_(self_, tensor1_, tensor2_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
std::tuple<Tensor &,Tensor &> VariableType::_gesv_single_out(Tensor & solution, Tensor & lu, const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("_gesv_single_out");
  auto& solution_ = unpack(solution, "solution", 0);
  auto& lu_ = unpack(lu, "lu", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& A_ = unpack(A, "A", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, A )) {
    throw_error_out_requires_grad("_gesv_single");
  }
  if (compute_requires_grad( solution )) {
    throw_error_out_requires_grad("_gesv_single");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( solution, lu, self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_gesv_single_out, { solution, lu, self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_gesv_single_out(solution_, lu_, self_, A_);
  increment_version(solution);
  rebase_history(flatten( solution ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {solution, lu} );
  }
  return std::forward_as_tuple(solution, lu);
}
std::tuple<Tensor,Tensor> VariableType::_gesv_single(const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("_gesv_single");
  auto& self_ = unpack(self, "self", 0);
  auto& A_ = unpack(A, "A", 1);
  std::shared_ptr<GesvSingleBackward> grad_fn;
  if (compute_requires_grad( self, A )) {
    grad_fn = std::shared_ptr<GesvSingleBackward>(new GesvSingleBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, A ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->A_ = SavedVariable(A, false);
  }
  Tensor solution;
  Tensor lu;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_gesv_single, { self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(solution, lu) = as_variable(baseType->_gesv_single(self_, A_));
  set_history(flatten( solution ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { solution, lu } );
  }
  if (grad_fn) {
    grad_fn->solution_ = SavedVariable(solution, true);
  }
  return std::make_tuple(std::move(solution), std::move(lu));
}
std::tuple<Tensor &,Tensor &> VariableType::gels_out(Tensor & res1, Tensor & res2, const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("gels_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& A_ = unpack(A, "A", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, A )) {
    throw_error_out_requires_grad("gels");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("gels");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gels_out, { res1, res2, self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->gels_out(res1_, res2_, self_, A_);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::gels(const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("gels");
  auto& self_ = unpack(self, "self", 0);
  auto& A_ = unpack(A, "A", 1);
  std::shared_ptr<GelsBackward> grad_fn;
  if (compute_requires_grad( self, A )) {
    grad_fn = std::shared_ptr<GelsBackward>(new GelsBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, A ));
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gels, { self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(res1, res2) = as_variable(baseType->gels(self_, A_));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
std::tuple<Tensor &,Tensor &> VariableType::trtrs_out(Tensor & res1, Tensor & res2, const Tensor & self, const Tensor & A, bool upper, bool transpose, bool unitriangular) const {
  profiler::RecordFunction profiler("trtrs_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& A_ = unpack(A, "A", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, A )) {
    throw_error_out_requires_grad("trtrs");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("trtrs");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::trtrs_out, { res1, res2, self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "upper", upper);
      setposattr(trace_info.n, 5, "transpose", transpose);
      setposattr(trace_info.n, 6, "unitriangular", unitriangular);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
      setattr(trace_info.n, jit::attr::transpose, transpose);
      setattr(trace_info.n, jit::attr::unitriangular, unitriangular);
    }
  }
  baseType->trtrs_out(res1_, res2_, self_, A_, upper, transpose, unitriangular);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::trtrs(const Tensor & self, const Tensor & A, bool upper, bool transpose, bool unitriangular) const {
  profiler::RecordFunction profiler("trtrs");
  auto& self_ = unpack(self, "self", 0);
  auto& A_ = unpack(A, "A", 1);
  std::shared_ptr<TrtrsBackward> grad_fn;
  if (compute_requires_grad( self, A )) {
    grad_fn = std::shared_ptr<TrtrsBackward>(new TrtrsBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, A ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->A_ = SavedVariable(A, false);
    grad_fn->upper = upper;
    grad_fn->transpose = transpose;
    grad_fn->unitriangular = unitriangular;
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::trtrs, { self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "upper", upper);
      setposattr(trace_info.n, 3, "transpose", transpose);
      setposattr(trace_info.n, 4, "unitriangular", unitriangular);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
      setattr(trace_info.n, jit::attr::transpose, transpose);
      setattr(trace_info.n, jit::attr::unitriangular, unitriangular);
    }
  }
  std::tie(res1, res2) = as_variable(baseType->trtrs(self_, A_, upper, transpose, unitriangular));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  if (grad_fn) {
    grad_fn->res1_ = SavedVariable(res1, true);
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
std::tuple<Tensor &,Tensor &> VariableType::symeig_out(Tensor & res1, Tensor & res2, const Tensor & self, bool eigenvectors, bool upper) const {
  profiler::RecordFunction profiler("symeig_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("symeig");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("symeig");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::symeig_out, { res1, res2, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "eigenvectors", eigenvectors);
      setposattr(trace_info.n, 4, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::eigenvectors, eigenvectors);
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  baseType->symeig_out(res1_, res2_, self_, eigenvectors, upper);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::symeig(const Tensor & self, bool eigenvectors, bool upper) const {
  profiler::RecordFunction profiler("symeig");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SymeigBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SymeigBackward>(new SymeigBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::symeig, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "eigenvectors", eigenvectors);
      setposattr(trace_info.n, 2, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::eigenvectors, eigenvectors);
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  std::tie(res1, res2) = as_variable(baseType->symeig(self_, eigenvectors, upper));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
std::tuple<Tensor &,Tensor &> VariableType::eig_out(Tensor & res1, Tensor & res2, const Tensor & self, bool eigenvectors) const {
  profiler::RecordFunction profiler("eig_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("eig");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("eig");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eig_out, { res1, res2, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "eigenvectors", eigenvectors);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::eigenvectors, eigenvectors);
    }
  }
  baseType->eig_out(res1_, res2_, self_, eigenvectors);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::eig(const Tensor & self, bool eigenvectors) const {
  profiler::RecordFunction profiler("eig");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<EigBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<EigBackward>(new EigBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eig, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "eigenvectors", eigenvectors);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::eigenvectors, eigenvectors);
    }
  }
  std::tie(res1, res2) = as_variable(baseType->eig(self_, eigenvectors));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::svd_out(Tensor & res1, Tensor & res2, Tensor & res3, const Tensor & self, bool some) const {
  profiler::RecordFunction profiler("svd_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& res3_ = unpack(res3, "res3", 2);
  auto& self_ = unpack(self, "self", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("svd");
  }
  if (compute_requires_grad( res1, res2, res3 )) {
    throw_error_out_requires_grad("svd");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, res3, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::svd_out, { res1, res2, res3, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "some", some);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::some, some);
    }
  }
  baseType->svd_out(res1_, res2_, res3_, self_, some);
  increment_version(res1);
  increment_version(res2);
  increment_version(res3);
  rebase_history(flatten( res1, res2, res3 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2, res3} );
  }
  return std::forward_as_tuple(res1, res2, res3);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::svd(const Tensor & self, bool some) const {
  profiler::RecordFunction profiler("svd");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SvdBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SvdBackward>(new SvdBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->some = some;
  }
  Tensor res1;
  Tensor res2;
  Tensor res3;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::svd, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "some", some);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::some, some);
    }
  }
  std::tie(res1, res2, res3) = as_variable(baseType->svd(self_, some));
  set_history(flatten( res1, res2, res3 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2, res3 } );
  }
  if (grad_fn) {
    grad_fn->res1_ = SavedVariable(res1, true);
    grad_fn->res2_ = SavedVariable(res2, true);
    grad_fn->res3_ = SavedVariable(res3, true);
  }
  return std::make_tuple(std::move(res1), std::move(res2), std::move(res3));
}
Tensor & VariableType::inverse_out(Tensor & output, const Tensor & self) const {
  profiler::RecordFunction profiler("inverse_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("inverse");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("inverse");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::inverse_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->inverse_out(output_, self_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::inverse(const Tensor & self) const {
  profiler::RecordFunction profiler("inverse");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<InverseBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<InverseBackward>(new InverseBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::inverse, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = as_variable(baseType->inverse(self_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(output, true);
  }
  return output;
}
Tensor & VariableType::potrf_out(Tensor & output, const Tensor & self, bool upper) const {
  profiler::RecordFunction profiler("potrf_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("potrf");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("potrf");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::potrf_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  baseType->potrf_out(output_, self_, upper);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::potrf(const Tensor & self, bool upper) const {
  profiler::RecordFunction profiler("potrf");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<PotrfBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PotrfBackward>(new PotrfBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->upper = upper;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::potrf, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  auto output = as_variable(baseType->potrf(self_, upper));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(output, true);
  }
  return output;
}
Tensor & VariableType::potrs_out(Tensor & result, const Tensor & self, const Tensor & input2, bool upper) const {
  profiler::RecordFunction profiler("potrs_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& input2_ = unpack(input2, "input2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, input2 )) {
    throw_error_out_requires_grad("potrs");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("potrs");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, input2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::potrs_out, { result, self, input2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  baseType->potrs_out(result_, self_, input2_, upper);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::potrs(const Tensor & self, const Tensor & input2, bool upper) const {
  profiler::RecordFunction profiler("potrs");
  auto& self_ = unpack(self, "self", 0);
  auto& input2_ = unpack(input2, "input2", 1);
  std::shared_ptr<PotrsBackward> grad_fn;
  if (compute_requires_grad( self, input2 )) {
    grad_fn = std::shared_ptr<PotrsBackward>(new PotrsBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, input2 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, input2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::potrs, { self, input2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  auto result = as_variable(baseType->potrs(self_, input2_, upper));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::potri_out(Tensor & output, const Tensor & self, bool upper) const {
  profiler::RecordFunction profiler("potri_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("potri");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("potri");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::potri_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  baseType->potri_out(output_, self_, upper);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::potri(const Tensor & self, bool upper) const {
  profiler::RecordFunction profiler("potri");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<PotriBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PotriBackward>(new PotriBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::potri, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "upper", upper);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
    }
  }
  auto output = as_variable(baseType->potri(self_, upper));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::pstrf_out(Tensor & res1, Tensor & res2, const Tensor & self, bool upper, Scalar tol) const {
  profiler::RecordFunction profiler("pstrf_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("pstrf");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("pstrf");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pstrf_out, { res1, res2, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "upper", upper);
      setposattr(trace_info.n, 4, "tol", tol);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
      setattr(trace_info.n, jit::attr::tol, tol);
    }
  }
  baseType->pstrf_out(res1_, res2_, self_, upper, tol);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::pstrf(const Tensor & self, bool upper, Scalar tol) const {
  profiler::RecordFunction profiler("pstrf");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<PstrfBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PstrfBackward>(new PstrfBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pstrf, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "upper", upper);
      setposattr(trace_info.n, 2, "tol", tol);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::upper, upper);
      setattr(trace_info.n, jit::attr::tol, tol);
    }
  }
  std::tie(res1, res2) = as_variable(baseType->pstrf(self_, upper, tol));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
std::tuple<Tensor &,Tensor &> VariableType::qr_out(Tensor & res1, Tensor & res2, const Tensor & self) const {
  profiler::RecordFunction profiler("qr_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("qr");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("qr");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::qr_out, { res1, res2, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->qr_out(res1_, res2_, self_);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::qr(const Tensor & self) const {
  profiler::RecordFunction profiler("qr");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<QrBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<QrBackward>(new QrBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::qr, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(res1, res2) = as_variable(baseType->qr(self_));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
std::tuple<Tensor &,Tensor &> VariableType::geqrf_out(Tensor & res1, Tensor & res2, const Tensor & self) const {
  profiler::RecordFunction profiler("geqrf_out");
  auto& res1_ = unpack(res1, "res1", 0);
  auto& res2_ = unpack(res2, "res2", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("geqrf");
  }
  if (compute_requires_grad( res1, res2 )) {
    throw_error_out_requires_grad("geqrf");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( res1, res2, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::geqrf_out, { res1, res2, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->geqrf_out(res1_, res2_, self_);
  increment_version(res1);
  increment_version(res2);
  rebase_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {res1, res2} );
  }
  return std::forward_as_tuple(res1, res2);
}
std::tuple<Tensor,Tensor> VariableType::geqrf(const Tensor & self) const {
  profiler::RecordFunction profiler("geqrf");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<GeqrfBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<GeqrfBackward>(new GeqrfBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor res1;
  Tensor res2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::geqrf, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(res1, res2) = as_variable(baseType->geqrf(self_));
  set_history(flatten( res1, res2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { res1, res2 } );
  }
  return std::make_tuple(std::move(res1), std::move(res2));
}
Tensor & VariableType::orgqr_out(Tensor & result, const Tensor & self, const Tensor & input2) const {
  profiler::RecordFunction profiler("orgqr_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& input2_ = unpack(input2, "input2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, input2 )) {
    throw_error_out_requires_grad("orgqr");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("orgqr");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, input2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::orgqr_out, { result, self, input2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->orgqr_out(result_, self_, input2_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::orgqr(const Tensor & self, const Tensor & input2) const {
  profiler::RecordFunction profiler("orgqr");
  auto& self_ = unpack(self, "self", 0);
  auto& input2_ = unpack(input2, "input2", 1);
  std::shared_ptr<OrgqrBackward> grad_fn;
  if (compute_requires_grad( self, input2 )) {
    grad_fn = std::shared_ptr<OrgqrBackward>(new OrgqrBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, input2 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, input2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::orgqr, { self, input2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->orgqr(self_, input2_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::ormqr_out(Tensor & result, const Tensor & self, const Tensor & input2, const Tensor & input3, bool left, bool transpose) const {
  profiler::RecordFunction profiler("ormqr_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& input2_ = unpack(input2, "input2", 2);
  auto& input3_ = unpack(input3, "input3", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, input2, input3 )) {
    throw_error_out_requires_grad("ormqr");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("ormqr");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, input2, input3 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ormqr_out, { result, self, input2, input3 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "left", left);
      setposattr(trace_info.n, 5, "transpose", transpose);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::left, left);
      setattr(trace_info.n, jit::attr::transpose, transpose);
    }
  }
  baseType->ormqr_out(result_, self_, input2_, input3_, left, transpose);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::ormqr(const Tensor & self, const Tensor & input2, const Tensor & input3, bool left, bool transpose) const {
  profiler::RecordFunction profiler("ormqr");
  auto& self_ = unpack(self, "self", 0);
  auto& input2_ = unpack(input2, "input2", 1);
  auto& input3_ = unpack(input3, "input3", 2);
  std::shared_ptr<OrmqrBackward> grad_fn;
  if (compute_requires_grad( self, input2, input3 )) {
    grad_fn = std::shared_ptr<OrmqrBackward>(new OrmqrBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, input2, input3 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, input2, input3 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ormqr, { self, input2, input3 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "left", left);
      setposattr(trace_info.n, 4, "transpose", transpose);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::left, left);
      setattr(trace_info.n, jit::attr::transpose, transpose);
    }
  }
  auto result = as_variable(baseType->ormqr(self_, input2_, input3_, left, transpose));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor &,Tensor &> VariableType::btrifact_out(Tensor & result, Tensor & pivots, const Tensor & self, bool pivot) const {
  profiler::RecordFunction profiler("btrifact_out");
  auto& result_ = unpack(result, "result", 0);
  auto& pivots_ = unpack(pivots, "pivots", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("btrifact");
  }
  if (compute_requires_grad( result, pivots )) {
    throw_error_out_requires_grad("btrifact");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, pivots, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::btrifact_out, { result, pivots, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "pivot", pivot);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pivot, pivot);
    }
  }
  baseType->btrifact_out(result_, pivots_, self_, pivot);
  increment_version(result);
  increment_version(pivots);
  rebase_history(flatten( result, pivots ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result, pivots} );
  }
  return std::forward_as_tuple(result, pivots);
}
std::tuple<Tensor,Tensor> VariableType::btrifact(const Tensor & self, bool pivot) const {
  profiler::RecordFunction profiler("btrifact");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<BtrifactBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<BtrifactBackward>(new BtrifactBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor result;
  Tensor pivots;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::btrifact, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "pivot", pivot);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pivot, pivot);
    }
  }
  std::tie(result, pivots) = as_variable(baseType->btrifact(self_, pivot));
  set_history(flatten( result, pivots ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result, pivots } );
  }
  return std::make_tuple(std::move(result), std::move(pivots));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::btrifact_with_info_out(Tensor & result, Tensor & pivots, Tensor & info, const Tensor & self, bool pivot) const {
  profiler::RecordFunction profiler("btrifact_with_info_out");
  auto& result_ = unpack(result, "result", 0);
  auto& pivots_ = unpack(pivots, "pivots", 1);
  auto& info_ = unpack(info, "info", 2);
  auto& self_ = unpack(self, "self", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("btrifact_with_info");
  }
  if (compute_requires_grad( result, pivots, info )) {
    throw_error_out_requires_grad("btrifact_with_info");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, pivots, info, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::btrifact_with_info_out, { result, pivots, info, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "pivot", pivot);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pivot, pivot);
    }
  }
  baseType->btrifact_with_info_out(result_, pivots_, info_, self_, pivot);
  increment_version(result);
  increment_version(pivots);
  increment_version(info);
  rebase_history(flatten( result, pivots, info ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result, pivots, info} );
  }
  return std::forward_as_tuple(result, pivots, info);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::btrifact_with_info(const Tensor & self, bool pivot) const {
  profiler::RecordFunction profiler("btrifact_with_info");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<BtrifactWithInfoBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<BtrifactWithInfoBackward>(new BtrifactWithInfoBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor result;
  Tensor pivots;
  Tensor info;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::btrifact_with_info, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "pivot", pivot);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pivot, pivot);
    }
  }
  std::tie(result, pivots, info) = as_variable(baseType->btrifact_with_info(self_, pivot));
  set_history(flatten( result, pivots, info ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result, pivots, info } );
  }
  return std::make_tuple(std::move(result), std::move(pivots), std::move(info));
}
Tensor & VariableType::btrisolve_out(Tensor & result, const Tensor & self, const Tensor & LU_data, const Tensor & LU_pivots) const {
  profiler::RecordFunction profiler("btrisolve_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& LU_data_ = unpack(LU_data, "LU_data", 2);
  auto& LU_pivots_ = unpack(LU_pivots, "LU_pivots", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, LU_data, LU_pivots )) {
    throw_error_out_requires_grad("btrisolve");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("btrisolve");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, LU_data, LU_pivots )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::btrisolve_out, { result, self, LU_data, LU_pivots } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->btrisolve_out(result_, self_, LU_data_, LU_pivots_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::btrisolve(const Tensor & self, const Tensor & LU_data, const Tensor & LU_pivots) const {
  profiler::RecordFunction profiler("btrisolve");
  auto& self_ = unpack(self, "self", 0);
  auto& LU_data_ = unpack(LU_data, "LU_data", 1);
  auto& LU_pivots_ = unpack(LU_pivots, "LU_pivots", 2);
  check_no_requires_grad(LU_data, "LU_data");
  check_no_requires_grad(LU_pivots, "LU_pivots");
  std::shared_ptr<BtrisolveBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<BtrisolveBackward>(new BtrisolveBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, LU_data, LU_pivots )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::btrisolve, { self, LU_data, LU_pivots } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->btrisolve(self_, LU_data_, LU_pivots_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::random_(Tensor & self, int64_t from, int64_t to, Generator * generator) const {
  profiler::RecordFunction profiler("random_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RandomBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RandomBackward0>(new RandomBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->random_(self_, from, to, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::random_(Tensor & self, int64_t to, Generator * generator) const {
  profiler::RecordFunction profiler("random_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RandomBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RandomBackward1>(new RandomBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->random_(self_, to, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::random_(Tensor & self, Generator * generator) const {
  profiler::RecordFunction profiler("random_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RandomBackward2> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RandomBackward2>(new RandomBackward2(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->random_(self_, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::multinomial_out(Tensor & result, const Tensor & self, int64_t num_samples, bool replacement, Generator * generator) const {
  profiler::RecordFunction profiler("multinomial_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  baseType->multinomial_out(result_, self_, num_samples, replacement, generator);
  return result;
}
Tensor VariableType::multinomial(const Tensor & self, int64_t num_samples, bool replacement, Generator * generator) const {
  profiler::RecordFunction profiler("multinomial");
  auto& self_ = unpack(self, "self", 0);
  auto result = as_variable(baseType->multinomial(self_, num_samples, replacement, generator));
  return result;
}
Tensor & VariableType::uniform_(Tensor & self, double from, double to, Generator * generator) const {
  profiler::RecordFunction profiler("uniform_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<UniformBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UniformBackward>(new UniformBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->uniform_(self_, from, to, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::normal_out(Tensor & output, const Tensor & mean, double std, Generator * generator) const {
  profiler::RecordFunction profiler("normal_out");
  auto& output_ = unpack(output, "output", 0);
  auto& mean_ = unpack(mean, "mean", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( mean )) {
    throw_error_out_requires_grad("normal");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("normal");
  }
  baseType->normal_out(output_, mean_, std, generator);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  return output;
}
Tensor VariableType::normal(const Tensor & mean, double std, Generator * generator) const {
  profiler::RecordFunction profiler("normal");
  auto& mean_ = unpack(mean, "mean", 0);
  std::shared_ptr<NormalBackward1> grad_fn;
  if (compute_requires_grad( mean )) {
    grad_fn = std::shared_ptr<NormalBackward1>(new NormalBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( mean ));
    grad_fn->mean_sizes = mean.sizes();
  }
  auto output = as_variable(baseType->normal(mean_, std, generator));
  set_history(flatten( output ), grad_fn);
  return output;
}
Tensor & VariableType::normal_out(Tensor & output, double mean, const Tensor & std, Generator * generator) const {
  profiler::RecordFunction profiler("normal_out");
  auto& output_ = unpack(output, "output", 0);
  auto& std_ = unpack(std, "std", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( std )) {
    throw_error_out_requires_grad("normal");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("normal");
  }
  baseType->normal_out(output_, mean, std_, generator);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  return output;
}
Tensor VariableType::normal(double mean, const Tensor & std, Generator * generator) const {
  profiler::RecordFunction profiler("normal");
  auto& std_ = unpack(std, "std", 1);
  std::shared_ptr<NormalBackward2> grad_fn;
  if (compute_requires_grad( std )) {
    grad_fn = std::shared_ptr<NormalBackward2>(new NormalBackward2(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( std ));
    grad_fn->std_sizes = std.sizes();
  }
  auto output = as_variable(baseType->normal(mean, std_, generator));
  set_history(flatten( output ), grad_fn);
  return output;
}
Tensor & VariableType::normal_out(Tensor & output, const Tensor & mean, const Tensor & std, Generator * generator) const {
  profiler::RecordFunction profiler("normal_out");
  auto& output_ = unpack(output, "output", 0);
  auto& mean_ = unpack(mean, "mean", 1);
  auto& std_ = unpack(std, "std", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( mean, std )) {
    throw_error_out_requires_grad("normal");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("normal");
  }
  baseType->normal_out(output_, mean_, std_, generator);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  return output;
}
Tensor VariableType::normal(const Tensor & mean, const Tensor & std, Generator * generator) const {
  profiler::RecordFunction profiler("normal");
  auto& mean_ = unpack(mean, "mean", 0);
  auto& std_ = unpack(std, "std", 1);
  std::shared_ptr<NormalBackward3> grad_fn;
  if (compute_requires_grad( mean, std )) {
    grad_fn = std::shared_ptr<NormalBackward3>(new NormalBackward3(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( mean, std ));
    grad_fn->mean_sizes = mean.sizes();
    grad_fn->std_sizes = std.sizes();
  }
  auto output = as_variable(baseType->normal(mean_, std_, generator));
  set_history(flatten( output ), grad_fn);
  return output;
}
Tensor & VariableType::normal_(Tensor & self, double mean, double std, Generator * generator) const {
  profiler::RecordFunction profiler("normal_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<NormalBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NormalBackward0>(new NormalBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->normal_(self_, mean, std, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::cauchy_(Tensor & self, double median, double sigma, Generator * generator) const {
  profiler::RecordFunction profiler("cauchy_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<CauchyBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CauchyBackward>(new CauchyBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->cauchy_(self_, median, sigma, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::log_normal_(Tensor & self, double mean, double std, Generator * generator) const {
  profiler::RecordFunction profiler("log_normal_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<LogNormalBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogNormalBackward>(new LogNormalBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->log_normal_(self_, mean, std, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::exponential_(Tensor & self, double lambd, Generator * generator) const {
  profiler::RecordFunction profiler("exponential_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ExponentialBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ExponentialBackward>(new ExponentialBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->exponential_(self_, lambd, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::geometric_(Tensor & self, double p, Generator * generator) const {
  profiler::RecordFunction profiler("geometric_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<GeometricBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<GeometricBackward>(new GeometricBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->geometric_(self_, p, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::_th_bernoulli_out(Tensor & output, const Tensor & self, Generator * generator) const {
  profiler::RecordFunction profiler("_th_bernoulli_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_th_bernoulli");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("_th_bernoulli");
  }
  baseType->_th_bernoulli_out(output_, self_, generator);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  return output;
}
Tensor VariableType::_th_bernoulli(const Tensor & self, Generator * generator) const {
  profiler::RecordFunction profiler("_th_bernoulli");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _th_bernoulli is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  auto output = as_variable(baseType->_th_bernoulli(self_, generator));
  set_history(flatten( output ), grad_fn);
  return output;
}
Tensor & VariableType::_dirichlet_grad_out(Tensor & output, const Tensor & x, const Tensor & alpha, const Tensor & total) const {
  profiler::RecordFunction profiler("_dirichlet_grad_out");
  auto& output_ = unpack(output, "output", 0);
  auto& x_ = unpack(x, "x", 1);
  auto& alpha_ = unpack(alpha, "alpha", 2);
  auto& total_ = unpack(total, "total", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( x, alpha, total )) {
    throw_error_out_requires_grad("_dirichlet_grad");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("_dirichlet_grad");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, x, alpha, total )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_dirichlet_grad_out, { output, x, alpha, total } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_dirichlet_grad_out(output_, x_, alpha_, total_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::_dirichlet_grad(const Tensor & x, const Tensor & alpha, const Tensor & total) const {
  profiler::RecordFunction profiler("_dirichlet_grad");
  auto& x_ = unpack(x, "x", 0);
  auto& alpha_ = unpack(alpha, "alpha", 1);
  auto& total_ = unpack(total, "total", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( x, alpha, total )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _dirichlet_grad is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( x, alpha, total ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( x, alpha, total )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_dirichlet_grad, { x, alpha, total } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = as_variable(baseType->_dirichlet_grad(x_, alpha_, total_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor VariableType::tensor(Storage & storage, int64_t storageOffset, IntList size, IntList stride) const {
  profiler::RecordFunction profiler("tensor");
  auto result = as_variable(baseType->tensor(storage, storageOffset, size, stride));
  return result;
}
Tensor VariableType::tensor(IntList size) const {
  profiler::RecordFunction profiler("tensor");
  auto result = as_variable(baseType->tensor(size));
  return result;
}
Tensor VariableType::tensor(IntList size, IntList stride) const {
  profiler::RecordFunction profiler("tensor");
  auto result = as_variable(baseType->tensor(size, stride));
  return result;
}
Tensor VariableType::tensor() const {
  profiler::RecordFunction profiler("tensor");
  auto result = as_variable(baseType->tensor());
  return result;
}
Tensor VariableType::sparse_coo_tensor(const Tensor & indices, const Tensor & values, IntList size) const {
  profiler::RecordFunction profiler("sparse_coo_tensor");
  auto& indices_ = unpack(indices, "indices", 0);
  auto& values_ = unpack(values, "values", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( indices, values )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sparse_coo_tensor, { indices, values } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  auto result = as_variable(baseType->sparse_coo_tensor(indices_, values_, size));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::sparse_coo_tensor(const Tensor & indices, const Tensor & values) const {
  profiler::RecordFunction profiler("sparse_coo_tensor");
  auto& indices_ = unpack(indices, "indices", 0);
  auto& values_ = unpack(values, "values", 1);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( indices, values )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sparse_coo_tensor, { indices, values } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->sparse_coo_tensor(indices_, values_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::alias(const Tensor & self) const {
  profiler::RecordFunction profiler("alias");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AliasBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AliasBackward>(new AliasBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::alias, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_view(self, baseType->alias(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_sparse_coo_tensor_unsafe(const Tensor & indices, const Tensor & values, IntList size) const {
  profiler::RecordFunction profiler("_sparse_coo_tensor_unsafe");
  auto& indices_ = unpack(indices, "indices", 0);
  auto& values_ = unpack(values, "values", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( values )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _sparse_coo_tensor_unsafe is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( values ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( indices, values )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sparse_coo_tensor_unsafe, { indices, values } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  auto result = as_variable(baseType->_sparse_coo_tensor_unsafe(indices_, values_, size));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::_copy_ignoring_overlaps_(Tensor & self, const Tensor & src) const {
  profiler::RecordFunction profiler("_copy_ignoring_overlaps_");
  auto& self_ = unpack(self, "self", 0);
  auto& src_ = unpack(src, "src", 1);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, src )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _copy_ignoring_overlaps_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, src ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, src )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_copy_ignoring_overlaps, { self, src } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_copy_ignoring_overlaps_(self_, src_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::as_strided_out(Tensor & result, const Tensor & self, IntList size, IntList stride, int64_t storage_offset) const {
  profiler::RecordFunction profiler("as_strided_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("as_strided");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("as_strided");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::as_strided_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size", size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "storage_offset", storage_offset);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::storage_offset, storage_offset);
    }
  }
  baseType->as_strided_out(result_, self_, size, stride, storage_offset);
  increment_version(result);
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::as_strided(const Tensor & self, IntList size, IntList stride, int64_t storage_offset) const {
  profiler::RecordFunction profiler("as_strided");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AsStridedBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AsStridedBackward>(new AsStridedBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_geometry = TensorGeometry(self);
    grad_fn->size = size;
    grad_fn->stride = stride;
    grad_fn->storage_offset = storage_offset;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::as_strided, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "storage_offset", storage_offset);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::storage_offset, storage_offset);
    }
  }
  auto result = as_view(self, baseType->as_strided(self_, size, stride, storage_offset));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::as_strided_(Tensor & self, IntList size, IntList stride, int64_t storage_offset) const {
  profiler::RecordFunction profiler("as_strided_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<AsStridedBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AsStridedBackward>(new AsStridedBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_geometry = TensorGeometry(self);
    grad_fn->size = size;
    grad_fn->stride = stride;
    grad_fn->storage_offset = storage_offset;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::as_strided, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "storage_offset", storage_offset);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::storage_offset, storage_offset);
    }
  }
  baseType->as_strided_(self_, size, stride, storage_offset);
  increment_version(self);
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::sparse_raw_resize_(Tensor & self, IntList size, int64_t nDimI, int64_t nDimV) const {
  profiler::RecordFunction profiler("sparse_raw_resize_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for sparse_raw_resize_ is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sparse_raw_resize, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      setposattr(trace_info.n, 2, "nDimI", nDimI);
      setposattr(trace_info.n, 3, "nDimV", nDimV);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::nDimI, nDimI);
      setattr(trace_info.n, jit::attr::nDimV, nDimV);
    }
  }
  baseType->sparse_raw_resize_(self_, size, nDimI, nDimV);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::_cat_out(Tensor & self, TensorList tensors, int64_t dim) const {
  profiler::RecordFunction profiler("_cat_out");
  auto& self_ = unpack(self, "self", 0);
  auto tensors_ = unpack(tensors, "tensors", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( tensors )) {
    throw_error_out_requires_grad("_cat");
  }
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_cat");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cat_out, flatten( self, tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->_cat_out(self_, tensors_, dim);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {self} );
  }
  return self;
}
Tensor VariableType::_cat(TensorList tensors, int64_t dim) const {
  profiler::RecordFunction profiler("_cat");
  auto tensors_ = unpack(tensors, "tensors", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( tensors )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _cat is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( tensors ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cat, flatten( tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto self = as_variable(baseType->_cat(tensors_, dim));
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::_sparse_mask(const Tensor & self, SparseTensor mask) const {
  profiler::RecordFunction profiler("_sparse_mask");
  auto& self_ = unpack(self, "self", 0);
  auto mask_ = unpack(mask, "mask", 1);
  std::shared_ptr<SparseMaskBackward> grad_fn;
  if (compute_requires_grad( self, mask.tref )) {
    grad_fn = std::shared_ptr<SparseMaskBackward>(new SparseMaskBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, mask.tref ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sparse_mask, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "mask", mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::mask, mask);
    }
  }
  auto result = as_variable(baseType->_sparse_mask(self_, mask_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::to_dense(const Tensor & self) const {
  profiler::RecordFunction profiler("to_dense");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for to_dense is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::to_dense, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->to_dense(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
int64_t VariableType::_dimI(const Tensor & self) const {
  profiler::RecordFunction profiler("_dimI");
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->_dimI(self_);
  return result;
}
int64_t VariableType::_dimV(const Tensor & self) const {
  profiler::RecordFunction profiler("_dimV");
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->_dimV(self_);
  return result;
}
int64_t VariableType::_nnz(const Tensor & self) const {
  profiler::RecordFunction profiler("_nnz");
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->_nnz(self_);
  return result;
}
Tensor VariableType::coalesce(const Tensor & self) const {
  profiler::RecordFunction profiler("coalesce");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for coalesce is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::coalesce, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->coalesce(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
bool VariableType::is_coalesced(const Tensor & self) const {
  profiler::RecordFunction profiler("is_coalesced");
  auto& self_ = unpack(self, "self", 0);
  auto result = baseType->is_coalesced(self_);
  return result;
}
Tensor VariableType::_indices(const Tensor & self) const {
  profiler::RecordFunction profiler("_indices");
  auto& self_ = unpack(self, "self", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_indices, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_indices(self_));
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_values(const Tensor & self) const {
  profiler::RecordFunction profiler("_values");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _values is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_values, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_values(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::hspmm_out(Tensor & result, const Tensor & mat1, const Tensor & mat2) const {
  profiler::RecordFunction profiler("hspmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& mat1_ = unpack(mat1, "mat1", 1);
  auto& mat2_ = unpack(mat2, "mat2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( mat1, mat2 )) {
    throw_error_out_requires_grad("hspmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("hspmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hspmm_out, { result, mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->hspmm_out(result_, mat1_, mat2_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::hspmm(const Tensor & mat1, const Tensor & mat2) const {
  profiler::RecordFunction profiler("hspmm");
  auto& mat1_ = unpack(mat1, "mat1", 0);
  auto& mat2_ = unpack(mat2, "mat2", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( mat1, mat2 )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for hspmm is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( mat1, mat2 ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hspmm, { mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->hspmm(mat1_, mat2_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::binary_cross_entropy_out(Tensor & output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("binary_cross_entropy_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::binary_cross_entropy_out, { output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::binary_cross_entropy_out(output, self, target, weight, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::binary_cross_entropy(const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("binary_cross_entropy");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::binary_cross_entropy, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::binary_cross_entropy(self, target, weight, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::binary_cross_entropy_forward_out(Tensor & output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("binary_cross_entropy_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto weight_ = unpack_opt(weight, "weight", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, target, weight )) {
    throw_error_out_requires_grad("binary_cross_entropy_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("binary_cross_entropy_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::binary_cross_entropy_forward_out, { output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->binary_cross_entropy_forward_out(output_, self_, target_, weight_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::binary_cross_entropy_forward(const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("binary_cross_entropy_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  auto weight_ = unpack_opt(weight, "weight", 2);
  check_no_requires_grad(target, "target");
  check_no_requires_grad(weight, "weight");
  std::shared_ptr<BinaryCrossEntropyBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<BinaryCrossEntropyBackward>(new BinaryCrossEntropyBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::binary_cross_entropy_forward, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->binary_cross_entropy_forward(self_, target_, weight_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::binary_cross_entropy_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("binary_cross_entropy_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto weight_ = unpack_opt(weight, "weight", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, target, weight )) {
    throw_error_out_requires_grad("binary_cross_entropy_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("binary_cross_entropy_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::binary_cross_entropy_backward_out, { grad_input, grad_output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->binary_cross_entropy_backward_out(grad_input_, grad_output_, self_, target_, weight_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::binary_cross_entropy_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("binary_cross_entropy_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto weight_ = unpack_opt(weight, "weight", 3);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, self, target, weight )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for binary_cross_entropy_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, target, weight ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::binary_cross_entropy_backward, { grad_output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->binary_cross_entropy_backward(grad_output_, self_, target_, weight_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::kl_div_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("kl_div_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kl_div_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::kl_div_out(output, self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::kl_div(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("kl_div");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kl_div, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::kl_div(self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::kl_div_forward_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("kl_div_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, target )) {
    throw_error_out_requires_grad("kl_div_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("kl_div_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kl_div_forward_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->kl_div_forward_out(output_, self_, target_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::kl_div_forward(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("kl_div_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  check_no_requires_grad(target, "target");
  std::shared_ptr<KlDivBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<KlDivBackward>(new KlDivBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kl_div_forward, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->kl_div_forward(self_, target_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::kl_div_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("kl_div_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, target )) {
    throw_error_out_requires_grad("kl_div_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("kl_div_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kl_div_backward_out, { grad_input, grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->kl_div_backward_out(grad_input_, grad_output_, self_, target_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::kl_div_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("kl_div_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  check_no_requires_grad(target, "target");
  std::shared_ptr<KlDivBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<KlDivBackwardBackward>(new KlDivBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::kl_div_backward, { grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->kl_div_backward(grad_output_, self_, target_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::l1_loss_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("l1_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::l1_loss_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::l1_loss_out(output, self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::l1_loss(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("l1_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::l1_loss, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::l1_loss(self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::l1_loss_forward_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("l1_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, target )) {
    throw_error_out_requires_grad("l1_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("l1_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::l1_loss_forward_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->l1_loss_forward_out(output_, self_, target_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::l1_loss_forward(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("l1_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  check_no_requires_grad(target, "target");
  std::shared_ptr<L1LossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<L1LossBackward>(new L1LossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::l1_loss_forward, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->l1_loss_forward(self_, target_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::l1_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("l1_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, target )) {
    throw_error_out_requires_grad("l1_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("l1_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::l1_loss_backward_out, { grad_input, grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->l1_loss_backward_out(grad_input_, grad_output_, self_, target_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::l1_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("l1_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  check_no_requires_grad(target, "target");
  std::shared_ptr<L1LossBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<L1LossBackwardBackward>(new L1LossBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::l1_loss_backward, { grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->l1_loss_backward(grad_output_, self_, target_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::mse_loss_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("mse_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mse_loss_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::mse_loss_out(output, self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::mse_loss(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("mse_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mse_loss, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::mse_loss(self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::mse_loss_forward_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("mse_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, target )) {
    throw_error_out_requires_grad("mse_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("mse_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mse_loss_forward_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->mse_loss_forward_out(output_, self_, target_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::mse_loss_forward(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("mse_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  check_no_requires_grad(target, "target");
  std::shared_ptr<MseLossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MseLossBackward>(new MseLossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mse_loss_forward, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->mse_loss_forward(self_, target_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::mse_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("mse_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, target )) {
    throw_error_out_requires_grad("mse_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("mse_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mse_loss_backward_out, { grad_input, grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->mse_loss_backward_out(grad_input_, grad_output_, self_, target_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::mse_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("mse_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  check_no_requires_grad(target, "target");
  std::shared_ptr<MseLossBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<MseLossBackwardBackward>(new MseLossBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mse_loss_backward, { grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->mse_loss_backward(grad_output_, self_, target_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::multi_margin_loss_out(Tensor & output, const Tensor & self, const Tensor & target, Scalar p, Scalar margin, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multi_margin_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multi_margin_loss_out, { output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "p", p);
      setposattr(trace_info.n, 4, "margin", margin);
      setposattr(trace_info.n, 6, "size_average", size_average);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::multi_margin_loss_out(output, self, target, p, margin, weight, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::multi_margin_loss(const Tensor & self, const Tensor & target, Scalar p, Scalar margin, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multi_margin_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multi_margin_loss, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "p", p);
      setposattr(trace_info.n, 3, "margin", margin);
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::multi_margin_loss(self, target, p, margin, weight, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::multi_margin_loss_forward_out(Tensor & output, const Tensor & self, const Tensor & target, Scalar p, Scalar margin, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multi_margin_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto weight_ = unpack_opt(weight, "weight", 5);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight )) {
    throw_error_out_requires_grad("multi_margin_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("multi_margin_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multi_margin_loss_forward_out, { output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "p", p);
      setposattr(trace_info.n, 4, "margin", margin);
      setposattr(trace_info.n, 6, "size_average", size_average);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->multi_margin_loss_forward_out(output_, self_, target_, p, margin, weight_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::multi_margin_loss_forward(const Tensor & self, const Tensor & target, Scalar p, Scalar margin, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multi_margin_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  auto weight_ = unpack_opt(weight, "weight", 4);
  check_no_requires_grad(weight, "weight");
  std::shared_ptr<MultiMarginLossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MultiMarginLossBackward>(new MultiMarginLossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->p = p;
    grad_fn->margin = margin;
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multi_margin_loss_forward, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "p", p);
      setposattr(trace_info.n, 3, "margin", margin);
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->multi_margin_loss_forward(self_, target_, p, margin, weight_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::multi_margin_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, Scalar p, Scalar margin, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multi_margin_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto weight_ = unpack_opt(weight, "weight", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    throw_error_out_requires_grad("multi_margin_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("multi_margin_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multi_margin_loss_backward_out, { grad_input, grad_output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "p", p);
      setposattr(trace_info.n, 5, "margin", margin);
      setposattr(trace_info.n, 7, "size_average", size_average);
      setposattr(trace_info.n, 8, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->multi_margin_loss_backward_out(grad_input_, grad_output_, self_, target_, p, margin, weight_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::multi_margin_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, Scalar p, Scalar margin, const Tensor & weight, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multi_margin_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto weight_ = unpack_opt(weight, "weight", 5);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for multi_margin_loss_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multi_margin_loss_backward, { grad_output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "p", p);
      setposattr(trace_info.n, 4, "margin", margin);
      setposattr(trace_info.n, 6, "size_average", size_average);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->multi_margin_loss_backward(grad_output_, self_, target_, p, margin, weight_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::multilabel_margin_loss_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multilabel_margin_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multilabel_margin_loss_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::multilabel_margin_loss_out(output, self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::multilabel_margin_loss(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multilabel_margin_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multilabel_margin_loss, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::multilabel_margin_loss(self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::multilabel_margin_loss_forward_out(Tensor & output, Tensor & is_target, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multilabel_margin_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& is_target_ = unpack(is_target, "is_target", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("multilabel_margin_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("multilabel_margin_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, is_target, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multilabel_margin_loss_forward_out, { output, is_target, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->multilabel_margin_loss_forward_out(output_, is_target_, self_, target_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, is_target} );
  }
  return std::forward_as_tuple(output, is_target);
}
std::tuple<Tensor,Tensor> VariableType::multilabel_margin_loss_forward(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("multilabel_margin_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  std::shared_ptr<MultilabelMarginLossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MultilabelMarginLossBackward>(new MultilabelMarginLossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  Tensor output;
  Tensor is_target;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multilabel_margin_loss_forward, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  std::tie(output, is_target) = as_variable(baseType->multilabel_margin_loss_forward(self_, target_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, is_target } );
  }
  if (grad_fn) {
    grad_fn->is_target_ = SavedVariable(is_target, true);
  }
  return std::make_tuple(std::move(output), std::move(is_target));
}
Tensor & VariableType::multilabel_margin_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce, const Tensor & is_target) const {
  profiler::RecordFunction profiler("multilabel_margin_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto& is_target_ = unpack(is_target, "is_target", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, is_target )) {
    throw_error_out_requires_grad("multilabel_margin_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("multilabel_margin_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target, is_target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multilabel_margin_loss_backward_out, { grad_input, grad_output, self, target, is_target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->multilabel_margin_loss_backward_out(grad_input_, grad_output_, self_, target_, size_average, reduce, is_target_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::multilabel_margin_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce, const Tensor & is_target) const {
  profiler::RecordFunction profiler("multilabel_margin_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto& is_target_ = unpack(is_target, "is_target", 5);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, self, is_target )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for multilabel_margin_loss_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, is_target ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target, is_target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::multilabel_margin_loss_backward, { grad_output, self, target, is_target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->multilabel_margin_loss_backward(grad_output_, self_, target_, size_average, reduce, is_target_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::nll_loss_out(Tensor & output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss_out, { output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "ignore_index", ignore_index);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::nll_loss_out(output, self, target, weight, size_average, ignore_index, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::nll_loss(const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "ignore_index", ignore_index);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::nll_loss(self, target, weight, size_average, ignore_index, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::nll_loss_forward_out(Tensor & output, Tensor & total_weight, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& total_weight_ = unpack(total_weight, "total_weight", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto weight_ = unpack_opt(weight, "weight", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight )) {
    throw_error_out_requires_grad("nll_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("nll_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, total_weight, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss_forward_out, { output, total_weight, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "ignore_index", ignore_index);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->nll_loss_forward_out(output_, total_weight_, self_, target_, weight_, size_average, ignore_index, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, total_weight} );
  }
  return std::forward_as_tuple(output, total_weight);
}
std::tuple<Tensor,Tensor> VariableType::nll_loss_forward(const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  auto weight_ = unpack_opt(weight, "weight", 2);
  check_no_requires_grad(weight, "weight");
  std::shared_ptr<NllLossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NllLossBackward>(new NllLossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->size_average = size_average;
    grad_fn->ignore_index = ignore_index;
    grad_fn->reduce = reduce;
  }
  Tensor output;
  Tensor total_weight;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss_forward, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "ignore_index", ignore_index);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  std::tie(output, total_weight) = as_variable(baseType->nll_loss_forward(self_, target_, weight_, size_average, ignore_index, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, total_weight } );
  }
  if (grad_fn) {
    grad_fn->total_weight_ = SavedVariable(total_weight, true);
  }
  return std::make_tuple(std::move(output), std::move(total_weight));
}
Tensor & VariableType::nll_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce, const Tensor & total_weight) const {
  profiler::RecordFunction profiler("nll_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto weight_ = unpack_opt(weight, "weight", 4);
  auto& total_weight_ = unpack(total_weight, "total_weight", 8);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, total_weight )) {
    throw_error_out_requires_grad("nll_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("nll_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target, weight, total_weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss_backward_out, { grad_input, grad_output, self, target, weight, total_weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "ignore_index", ignore_index);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->nll_loss_backward_out(grad_input_, grad_output_, self_, target_, weight_, size_average, ignore_index, reduce, total_weight_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::nll_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce, const Tensor & total_weight) const {
  profiler::RecordFunction profiler("nll_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto weight_ = unpack_opt(weight, "weight", 3);
  auto& total_weight_ = unpack(total_weight, "total_weight", 7);
  check_no_requires_grad(weight, "weight");
  check_no_requires_grad(total_weight, "total_weight");
  std::shared_ptr<NllLossBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<NllLossBackwardBackward>(new NllLossBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->size_average = size_average;
    grad_fn->ignore_index = ignore_index;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target, weight, total_weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss_backward, { grad_output, self, target, weight, total_weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "ignore_index", ignore_index);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->nll_loss_backward(grad_output_, self_, target_, weight_, size_average, ignore_index, reduce, total_weight_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::nll_loss2d_out(Tensor & output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss2d_out, { output, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "ignore_index", ignore_index);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::nll_loss2d_out(output, self, target, weight, size_average, ignore_index, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::nll_loss2d(const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss2d, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "ignore_index", ignore_index);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::nll_loss2d(self, target, weight, size_average, ignore_index, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::nll_loss2d_forward_out(Tensor & output, Tensor & total_weight, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& total_weight_ = unpack(total_weight, "total_weight", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto weight_ = unpack_opt(weight, "weight", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight )) {
    throw_error_out_requires_grad("nll_loss2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("nll_loss2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, total_weight, self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss2d_forward_out, { output, total_weight, self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "ignore_index", ignore_index);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->nll_loss2d_forward_out(output_, total_weight_, self_, target_, weight_, size_average, ignore_index, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, total_weight} );
  }
  return std::forward_as_tuple(output, total_weight);
}
std::tuple<Tensor,Tensor> VariableType::nll_loss2d_forward(const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce) const {
  profiler::RecordFunction profiler("nll_loss2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  auto weight_ = unpack_opt(weight, "weight", 2);
  check_no_requires_grad(weight, "weight");
  std::shared_ptr<NllLoss2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<NllLoss2DBackward>(new NllLoss2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->size_average = size_average;
    grad_fn->ignore_index = ignore_index;
    grad_fn->reduce = reduce;
  }
  Tensor output;
  Tensor total_weight;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss2d_forward, { self, target, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "ignore_index", ignore_index);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  std::tie(output, total_weight) = as_variable(baseType->nll_loss2d_forward(self_, target_, weight_, size_average, ignore_index, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, total_weight } );
  }
  if (grad_fn) {
    grad_fn->total_weight_ = SavedVariable(total_weight, true);
  }
  return std::make_tuple(std::move(output), std::move(total_weight));
}
Tensor & VariableType::nll_loss2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce, const Tensor & total_weight) const {
  profiler::RecordFunction profiler("nll_loss2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  auto weight_ = unpack_opt(weight, "weight", 4);
  auto& total_weight_ = unpack(total_weight, "total_weight", 8);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, total_weight )) {
    throw_error_out_requires_grad("nll_loss2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("nll_loss2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target, weight, total_weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss2d_backward_out, { grad_input, grad_output, self, target, weight, total_weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "size_average", size_average);
      setposattr(trace_info.n, 6, "ignore_index", ignore_index);
      setposattr(trace_info.n, 7, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->nll_loss2d_backward_out(grad_input_, grad_output_, self_, target_, weight_, size_average, ignore_index, reduce, total_weight_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::nll_loss2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, const Tensor & weight, bool size_average, int64_t ignore_index, bool reduce, const Tensor & total_weight) const {
  profiler::RecordFunction profiler("nll_loss2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  auto weight_ = unpack_opt(weight, "weight", 3);
  auto& total_weight_ = unpack(total_weight, "total_weight", 7);
  check_no_requires_grad(weight, "weight");
  check_no_requires_grad(total_weight, "total_weight");
  std::shared_ptr<NllLoss2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<NllLoss2DBackwardBackward>(new NllLoss2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->size_average = size_average;
    grad_fn->ignore_index = ignore_index;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target, weight, total_weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::nll_loss2d_backward, { grad_output, self, target, weight, total_weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "ignore_index", ignore_index);
      setposattr(trace_info.n, 6, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::ignore_index, ignore_index);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->nll_loss2d_backward(grad_output_, self_, target_, weight_, size_average, ignore_index, reduce, total_weight_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::smooth_l1_loss_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("smooth_l1_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smooth_l1_loss_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::smooth_l1_loss_out(output, self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::smooth_l1_loss(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("smooth_l1_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smooth_l1_loss, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::smooth_l1_loss(self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::smooth_l1_loss_forward_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("smooth_l1_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, target )) {
    throw_error_out_requires_grad("smooth_l1_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("smooth_l1_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smooth_l1_loss_forward_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->smooth_l1_loss_forward_out(output_, self_, target_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::smooth_l1_loss_forward(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("smooth_l1_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  check_no_requires_grad(target, "target");
  std::shared_ptr<SmoothL1LossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SmoothL1LossBackward>(new SmoothL1LossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smooth_l1_loss_forward, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->smooth_l1_loss_forward(self_, target_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::smooth_l1_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("smooth_l1_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, target )) {
    throw_error_out_requires_grad("smooth_l1_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("smooth_l1_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smooth_l1_loss_backward_out, { grad_input, grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->smooth_l1_loss_backward_out(grad_input_, grad_output_, self_, target_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::smooth_l1_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("smooth_l1_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  check_no_requires_grad(target, "target");
  std::shared_ptr<SmoothL1LossBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<SmoothL1LossBackwardBackward>(new SmoothL1LossBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smooth_l1_loss_backward, { grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->smooth_l1_loss_backward(grad_output_, self_, target_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::soft_margin_loss_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("soft_margin_loss_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::soft_margin_loss_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  Type::soft_margin_loss_out(output, self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::soft_margin_loss(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("soft_margin_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::soft_margin_loss, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = Type::soft_margin_loss(self, target, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::soft_margin_loss_forward_out(Tensor & output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("soft_margin_loss_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, target )) {
    throw_error_out_requires_grad("soft_margin_loss_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("soft_margin_loss_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::soft_margin_loss_forward_out, { output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->soft_margin_loss_forward_out(output_, self_, target_, size_average, reduce);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::soft_margin_loss_forward(const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("soft_margin_loss_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& target_ = unpack(target, "target", 1);
  check_no_requires_grad(target, "target");
  std::shared_ptr<SoftMarginLossBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SoftMarginLossBackward>(new SoftMarginLossBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::soft_margin_loss_forward, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "size_average", size_average);
      setposattr(trace_info.n, 3, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto output = as_variable(baseType->soft_margin_loss_forward(self_, target_, size_average, reduce));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::soft_margin_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("soft_margin_loss_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& target_ = unpack(target, "target", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, target )) {
    throw_error_out_requires_grad("soft_margin_loss_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("soft_margin_loss_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::soft_margin_loss_backward_out, { grad_input, grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  baseType->soft_margin_loss_backward_out(grad_input_, grad_output_, self_, target_, size_average, reduce);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::soft_margin_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("soft_margin_loss_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& target_ = unpack(target, "target", 2);
  check_no_requires_grad(target, "target");
  std::shared_ptr<SoftMarginLossBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<SoftMarginLossBackwardBackward>(new SoftMarginLossBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->target_ = SavedVariable(target, false);
    grad_fn->size_average = size_average;
    grad_fn->reduce = reduce;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::soft_margin_loss_backward, { grad_output, self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto grad_input = as_variable(baseType->soft_margin_loss_backward(grad_output_, self_, target_, size_average, reduce));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::elu_out(Tensor & output, const Tensor & self, Scalar alpha, Scalar scale) const {
  profiler::RecordFunction profiler("elu_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      setposattr(trace_info.n, 3, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  Type::elu_out(output, self, alpha, scale);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::elu(const Tensor & self, Scalar alpha, Scalar scale) const {
  profiler::RecordFunction profiler("elu");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "alpha", alpha);
      setposattr(trace_info.n, 2, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  auto output = Type::elu(self, alpha, scale);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::elu_forward_out(Tensor & output, const Tensor & self, Scalar alpha, Scalar scale) const {
  profiler::RecordFunction profiler("elu_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("elu_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("elu_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      setposattr(trace_info.n, 3, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  baseType->elu_forward_out(output_, self_, alpha, scale);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::elu_forward(const Tensor & self, Scalar alpha, Scalar scale) const {
  profiler::RecordFunction profiler("elu_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<EluBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<EluBackward>(new EluBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->alpha = alpha;
    grad_fn->scale = scale;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "alpha", alpha);
      setposattr(trace_info.n, 2, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  auto output = as_variable(baseType->elu_forward(self_, alpha, scale));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(output, true);
  }
  return output;
}
Tensor & VariableType::elu_backward_out(Tensor & grad_input, const Tensor & grad_output, Scalar alpha, Scalar scale, const Tensor & output) const {
  profiler::RecordFunction profiler("elu_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& output_ = unpack(output, "output", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, output )) {
    throw_error_out_requires_grad("elu_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("elu_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu_backward_out, { grad_input, grad_output, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "alpha", alpha);
      setposattr(trace_info.n, 3, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  baseType->elu_backward_out(grad_input_, grad_output_, alpha, scale, output_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::elu_backward(const Tensor & grad_output, Scalar alpha, Scalar scale, const Tensor & output) const {
  profiler::RecordFunction profiler("elu_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& output_ = unpack(output, "output", 3);
  std::shared_ptr<EluBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, output )) {
    grad_fn = std::shared_ptr<EluBackwardBackward>(new EluBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, output ));
    grad_fn->alpha = alpha;
    grad_fn->scale = scale;
    grad_fn->output_ = SavedVariable(output, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu_backward, { grad_output, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "alpha", alpha);
      setposattr(trace_info.n, 2, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  auto grad_input = as_variable(baseType->elu_backward(grad_output_, alpha, scale, output_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::elu_(Tensor & self, Scalar alpha, Scalar scale) const {
  profiler::RecordFunction profiler("elu_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "alpha", alpha);
      setposattr(trace_info.n, 2, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  Type::elu_(self, alpha, scale);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::elu_forward_(Tensor & self, Scalar alpha, Scalar scale) const {
  profiler::RecordFunction profiler("elu_forward_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<EluBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<EluBackward>(new EluBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->alpha = alpha;
    grad_fn->scale = scale;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::elu_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "alpha", alpha);
      setposattr(trace_info.n, 2, "scale", scale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::alpha, alpha);
      setattr(trace_info.n, jit::attr::scale, scale);
    }
  }
  baseType->elu_forward_(self_, alpha, scale);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::glu_out(Tensor & output, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("glu_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::glu_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  Type::glu_out(output, self, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::glu(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("glu");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::glu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto output = Type::glu(self, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::glu_forward_out(Tensor & output, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("glu_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("glu_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("glu_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::glu_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->glu_forward_out(output_, self_, dim);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::glu_forward(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("glu_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<GluBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<GluBackward>(new GluBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::glu_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto output = as_variable(baseType->glu_forward(self_, dim));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::glu_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("glu_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("glu_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("glu_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::glu_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->glu_backward_out(grad_input_, grad_output_, self_, dim);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::glu_backward(const Tensor & grad_output, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("glu_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<GluBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<GluBackwardBackward>(new GluBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::glu_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto grad_input = as_variable(baseType->glu_backward(grad_output_, self_, dim));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::hardshrink_out(Tensor & output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("hardshrink_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardshrink_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  Type::hardshrink_out(output, self, lambd);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::hardshrink(const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("hardshrink");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardshrink, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  auto output = Type::hardshrink(self, lambd);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::hardshrink_forward_out(Tensor & output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("hardshrink_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("hardshrink_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("hardshrink_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardshrink_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  baseType->hardshrink_forward_out(output_, self_, lambd);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::hardshrink_forward(const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("hardshrink_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<HardshrinkBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<HardshrinkBackward>(new HardshrinkBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->lambd = lambd;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardshrink_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  auto output = as_variable(baseType->hardshrink_forward(self_, lambd));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::hardshrink_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("hardshrink_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("hardshrink_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("hardshrink_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardshrink_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  baseType->hardshrink_backward_out(grad_input_, grad_output_, self_, lambd);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::hardshrink_backward(const Tensor & grad_output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("hardshrink_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<HardshrinkBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<HardshrinkBackwardBackward>(new HardshrinkBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->lambd = lambd;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardshrink_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  auto grad_input = as_variable(baseType->hardshrink_backward(grad_output_, self_, lambd));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::hardtanh_out(Tensor & output, const Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "min_val", min_val);
      setposattr(trace_info.n, 3, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  Type::hardtanh_out(output, self, min_val, max_val);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::hardtanh(const Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min_val", min_val);
      setposattr(trace_info.n, 2, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  auto output = Type::hardtanh(self, min_val, max_val);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::hardtanh_forward_out(Tensor & output, const Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("hardtanh_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("hardtanh_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "min_val", min_val);
      setposattr(trace_info.n, 3, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  baseType->hardtanh_forward_out(output_, self_, min_val, max_val);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::hardtanh_forward(const Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<HardtanhBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<HardtanhBackward0>(new HardtanhBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->min_val = min_val;
    grad_fn->max_val = max_val;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min_val", min_val);
      setposattr(trace_info.n, 2, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  auto output = as_variable(baseType->hardtanh_forward(self_, min_val, max_val));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::hardtanh_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("hardtanh_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("hardtanh_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "min_val", min_val);
      setposattr(trace_info.n, 4, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  baseType->hardtanh_backward_out(grad_input_, grad_output_, self_, min_val, max_val);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::hardtanh_backward(const Tensor & grad_output, const Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<HardtanhBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<HardtanhBackwardBackward>(new HardtanhBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->min_val = min_val;
    grad_fn->max_val = max_val;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "min_val", min_val);
      setposattr(trace_info.n, 3, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  auto grad_input = as_variable(baseType->hardtanh_backward(grad_output_, self_, min_val, max_val));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::hardtanh_(Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min_val", min_val);
      setposattr(trace_info.n, 2, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  Type::hardtanh_(self, min_val, max_val);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::hardtanh_forward_(Tensor & self, Scalar min_val, Scalar max_val) const {
  profiler::RecordFunction profiler("hardtanh_forward_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<HardtanhBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<HardtanhBackward1>(new HardtanhBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->min_val = min_val;
    grad_fn->max_val = max_val;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hardtanh_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "min_val", min_val);
      setposattr(trace_info.n, 2, "max_val", max_val);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::min_val, min_val);
      setattr(trace_info.n, jit::attr::max_val, max_val);
    }
  }
  baseType->hardtanh_forward_(self_, min_val, max_val);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::leaky_relu_out(Tensor & output, const Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  Type::leaky_relu_out(output, self, negative_slope);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::leaky_relu(const Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  auto output = Type::leaky_relu(self, negative_slope);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::leaky_relu_forward_out(Tensor & output, const Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("leaky_relu_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("leaky_relu_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  baseType->leaky_relu_forward_out(output_, self_, negative_slope);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::leaky_relu_forward(const Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LeakyReluBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LeakyReluBackward0>(new LeakyReluBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->negative_slope = negative_slope;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  auto output = as_variable(baseType->leaky_relu_forward(self_, negative_slope));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::leaky_relu_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("leaky_relu_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("leaky_relu_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  baseType->leaky_relu_backward_out(grad_input_, grad_output_, self_, negative_slope);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::leaky_relu_backward(const Tensor & grad_output, const Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<LeakyReluBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<LeakyReluBackwardBackward>(new LeakyReluBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->negative_slope = negative_slope;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  auto grad_input = as_variable(baseType->leaky_relu_backward(grad_output_, self_, negative_slope));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::leaky_relu_(Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  Type::leaky_relu_(self, negative_slope);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::leaky_relu_forward_(Tensor & self, Scalar negative_slope) const {
  profiler::RecordFunction profiler("leaky_relu_forward_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<LeakyReluBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LeakyReluBackward1>(new LeakyReluBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->negative_slope = negative_slope;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::leaky_relu_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "negative_slope", negative_slope);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::negative_slope, negative_slope);
    }
  }
  baseType->leaky_relu_forward_(self_, negative_slope);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::log_sigmoid_out(Tensor & output, const Tensor & self) const {
  profiler::RecordFunction profiler("log_sigmoid_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_sigmoid_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::log_sigmoid_out(output, self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::log_sigmoid(const Tensor & self) const {
  profiler::RecordFunction profiler("log_sigmoid");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_sigmoid, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = Type::log_sigmoid(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::log_sigmoid_forward_out(Tensor & output, Tensor & buffer, const Tensor & self) const {
  profiler::RecordFunction profiler("log_sigmoid_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& buffer_ = unpack(buffer, "buffer", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("log_sigmoid_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("log_sigmoid_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, buffer, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_sigmoid_forward_out, { output, buffer, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log_sigmoid_forward_out(output_, buffer_, self_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, buffer} );
  }
  return std::forward_as_tuple(output, buffer);
}
std::tuple<Tensor,Tensor> VariableType::log_sigmoid_forward(const Tensor & self) const {
  profiler::RecordFunction profiler("log_sigmoid_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LogSigmoidBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogSigmoidBackward>(new LogSigmoidBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  Tensor output;
  Tensor buffer;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_sigmoid_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(output, buffer) = as_variable(baseType->log_sigmoid_forward(self_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, buffer } );
  }
  if (grad_fn) {
    grad_fn->buffer_ = SavedVariable(buffer, true);
  }
  return std::make_tuple(std::move(output), std::move(buffer));
}
Tensor & VariableType::log_sigmoid_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & buffer) const {
  profiler::RecordFunction profiler("log_sigmoid_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& buffer_ = unpack(buffer, "buffer", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, buffer )) {
    throw_error_out_requires_grad("log_sigmoid_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("log_sigmoid_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, buffer )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_sigmoid_backward_out, { grad_input, grad_output, self, buffer } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log_sigmoid_backward_out(grad_input_, grad_output_, self_, buffer_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::log_sigmoid_backward(const Tensor & grad_output, const Tensor & self, const Tensor & buffer) const {
  profiler::RecordFunction profiler("log_sigmoid_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& buffer_ = unpack(buffer, "buffer", 2);
  check_no_requires_grad(buffer, "buffer");
  std::shared_ptr<LogSigmoidBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<LogSigmoidBackwardBackward>(new LogSigmoidBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->buffer_ = SavedVariable(buffer, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, buffer )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_sigmoid_backward, { grad_output, self, buffer } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->log_sigmoid_backward(grad_output_, self_, buffer_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::prelu_out(Tensor & output, const Tensor & self, const Tensor & weight) const {
  profiler::RecordFunction profiler("prelu_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prelu_out, { output, self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::prelu_out(output, self, weight);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::prelu(const Tensor & self, const Tensor & weight) const {
  profiler::RecordFunction profiler("prelu");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prelu, { self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = Type::prelu(self, weight);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::prelu_forward_out(Tensor & output, const Tensor & self, const Tensor & weight) const {
  profiler::RecordFunction profiler("prelu_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight )) {
    throw_error_out_requires_grad("prelu_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("prelu_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prelu_forward_out, { output, self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->prelu_forward_out(output_, self_, weight_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::prelu_forward(const Tensor & self, const Tensor & weight) const {
  profiler::RecordFunction profiler("prelu_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  std::shared_ptr<PreluBackward> grad_fn;
  if (compute_requires_grad( self, weight )) {
    grad_fn = std::shared_ptr<PreluBackward>(new PreluBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prelu_forward, { self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = as_variable(baseType->prelu_forward(self_, weight_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::prelu_backward_out(Tensor & grad_input, Tensor & grad_weight, const Tensor & grad_output, const Tensor & self, const Tensor & weight) const {
  profiler::RecordFunction profiler("prelu_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto& grad_output_ = unpack(grad_output, "grad_output", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    throw_error_out_requires_grad("prelu_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight )) {
    throw_error_out_requires_grad("prelu_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_output, self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prelu_backward_out, { grad_input, grad_weight, grad_output, self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->prelu_backward_out(grad_input_, grad_weight_, grad_output_, self_, weight_);
  increment_version(grad_input);
  increment_version(grad_weight);
  rebase_history(flatten( grad_input, grad_weight ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight} );
  }
  return std::forward_as_tuple(grad_input, grad_weight);
}
std::tuple<Tensor,Tensor> VariableType::prelu_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, std::array<bool,2> output_mask) const {
  profiler::RecordFunction profiler("prelu_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  std::shared_ptr<PreluBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<PreluBackwardBackward>(new PreluBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
  }
  Tensor grad_input;
  Tensor grad_weight;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prelu_backward, { grad_output, self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight) = as_variable(baseType->prelu_backward(grad_output_, self_, weight_, output_mask));
  set_history(flatten( grad_input, grad_weight ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight));
}
Tensor & VariableType::rrelu_with_noise_out(Tensor & output, const Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_with_noise_out");
  Type::rrelu_with_noise_out(output, self, noise, lower, upper, training, generator);
  return output;
}
Tensor VariableType::rrelu_with_noise(const Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_with_noise");
  auto output = Type::rrelu_with_noise(self, noise, lower, upper, training, generator);
  return output;
}
Tensor & VariableType::rrelu_with_noise_forward_out(Tensor & output, const Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_with_noise_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& noise_ = unpack(noise, "noise", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, noise )) {
    throw_error_out_requires_grad("rrelu_with_noise_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("rrelu_with_noise_forward");
  }
  baseType->rrelu_with_noise_forward_out(output_, self_, noise_, lower, upper, training, generator);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  return output;
}
Tensor VariableType::rrelu_with_noise_forward(const Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_with_noise_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& noise_ = unpack(noise, "noise", 1);
  check_no_requires_grad(noise, "noise");
  std::shared_ptr<RreluWithNoiseBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RreluWithNoiseBackward0>(new RreluWithNoiseBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->noise_ = SavedVariable(noise, false);
    grad_fn->lower = lower;
    grad_fn->upper = upper;
    grad_fn->training = training;
  }
  auto output = as_variable(baseType->rrelu_with_noise_forward(self_, noise_, lower, upper, training, generator));
  set_history(flatten( output ), grad_fn);
  return output;
}
Tensor & VariableType::rrelu_with_noise_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training) const {
  profiler::RecordFunction profiler("rrelu_with_noise_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& noise_ = unpack(noise, "noise", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, noise )) {
    throw_error_out_requires_grad("rrelu_with_noise_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("rrelu_with_noise_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, noise )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rrelu_with_noise_backward_out, { grad_input, grad_output, self, noise } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "lower", lower);
      setposattr(trace_info.n, 5, "upper", upper);
      setposattr(trace_info.n, 6, "training", training);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lower, lower);
      setattr(trace_info.n, jit::attr::upper, upper);
      setattr(trace_info.n, jit::attr::training, training);
    }
  }
  baseType->rrelu_with_noise_backward_out(grad_input_, grad_output_, self_, noise_, lower, upper, training);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::rrelu_with_noise_backward(const Tensor & grad_output, const Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training) const {
  profiler::RecordFunction profiler("rrelu_with_noise_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& noise_ = unpack(noise, "noise", 2);
  check_no_requires_grad(noise, "noise");
  std::shared_ptr<RreluWithNoiseBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<RreluWithNoiseBackwardBackward>(new RreluWithNoiseBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->noise_ = SavedVariable(noise, false);
    grad_fn->lower = lower;
    grad_fn->upper = upper;
    grad_fn->training = training;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, noise )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rrelu_with_noise_backward, { grad_output, self, noise } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "lower", lower);
      setposattr(trace_info.n, 4, "upper", upper);
      setposattr(trace_info.n, 5, "training", training);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lower, lower);
      setattr(trace_info.n, jit::attr::upper, upper);
      setattr(trace_info.n, jit::attr::training, training);
    }
  }
  auto grad_input = as_variable(baseType->rrelu_with_noise_backward(grad_output_, self_, noise_, lower, upper, training));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::rrelu_with_noise_(Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_with_noise_");
  Type::rrelu_with_noise_(self, noise, lower, upper, training, generator);
  return self;
}
Tensor & VariableType::rrelu_with_noise_forward_(Tensor & self, const Tensor & noise, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_with_noise_forward_");
  auto& self_ = unpack(self, "self", 0);
  auto& noise_ = unpack(noise, "noise", 1);
  check_inplace(self);
  check_no_requires_grad(noise, "noise");
  std::shared_ptr<RreluWithNoiseBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RreluWithNoiseBackward1>(new RreluWithNoiseBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->noise_ = SavedVariable(noise, false);
    grad_fn->lower = lower;
    grad_fn->upper = upper;
    grad_fn->training = training;
  }
  baseType->rrelu_with_noise_forward_(self_, noise_, lower, upper, training, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::softplus_out(Tensor & output, const Tensor & self, Scalar beta, Scalar threshold) const {
  profiler::RecordFunction profiler("softplus_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softplus_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "beta", beta);
      setposattr(trace_info.n, 3, "threshold", threshold);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::threshold, threshold);
    }
  }
  Type::softplus_out(output, self, beta, threshold);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::softplus(const Tensor & self, Scalar beta, Scalar threshold) const {
  profiler::RecordFunction profiler("softplus");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softplus, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "beta", beta);
      setposattr(trace_info.n, 2, "threshold", threshold);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::threshold, threshold);
    }
  }
  auto output = Type::softplus(self, beta, threshold);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::softplus_forward_out(Tensor & output, const Tensor & self, Scalar beta, Scalar threshold) const {
  profiler::RecordFunction profiler("softplus_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("softplus_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("softplus_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softplus_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "beta", beta);
      setposattr(trace_info.n, 3, "threshold", threshold);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::threshold, threshold);
    }
  }
  baseType->softplus_forward_out(output_, self_, beta, threshold);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::softplus_forward(const Tensor & self, Scalar beta, Scalar threshold) const {
  profiler::RecordFunction profiler("softplus_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SoftplusBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SoftplusBackward>(new SoftplusBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->beta = beta;
    grad_fn->threshold = threshold;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softplus_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "beta", beta);
      setposattr(trace_info.n, 2, "threshold", threshold);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::threshold, threshold);
    }
  }
  auto output = as_variable(baseType->softplus_forward(self_, beta, threshold));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(output, true);
  }
  return output;
}
Tensor & VariableType::softplus_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar beta, Scalar threshold, const Tensor & output) const {
  profiler::RecordFunction profiler("softplus_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& output_ = unpack(output, "output", 5);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, output )) {
    throw_error_out_requires_grad("softplus_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("softplus_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softplus_backward_out, { grad_input, grad_output, self, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "threshold", threshold);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::threshold, threshold);
    }
  }
  baseType->softplus_backward_out(grad_input_, grad_output_, self_, beta, threshold, output_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::softplus_backward(const Tensor & grad_output, const Tensor & self, Scalar beta, Scalar threshold, const Tensor & output) const {
  profiler::RecordFunction profiler("softplus_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& output_ = unpack(output, "output", 4);
  std::shared_ptr<SoftplusBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<SoftplusBackwardBackward>(new SoftplusBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->beta = beta;
    grad_fn->threshold = threshold;
    grad_fn->output_ = SavedVariable(output, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softplus_backward, { grad_output, self, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "beta", beta);
      setposattr(trace_info.n, 3, "threshold", threshold);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::threshold, threshold);
    }
  }
  auto grad_input = as_variable(baseType->softplus_backward(grad_output_, self_, beta, threshold, output_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::softshrink_out(Tensor & output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("softshrink_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softshrink_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  Type::softshrink_out(output, self, lambd);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::softshrink(const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("softshrink");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softshrink, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  auto output = Type::softshrink(self, lambd);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::softshrink_forward_out(Tensor & output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("softshrink_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("softshrink_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("softshrink_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softshrink_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  baseType->softshrink_forward_out(output_, self_, lambd);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::softshrink_forward(const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("softshrink_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SoftshrinkBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SoftshrinkBackward>(new SoftshrinkBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->lambd = lambd;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softshrink_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  auto output = as_variable(baseType->softshrink_forward(self_, lambd));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::softshrink_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("softshrink_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("softshrink_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("softshrink_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softshrink_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  baseType->softshrink_backward_out(grad_input_, grad_output_, self_, lambd);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::softshrink_backward(const Tensor & grad_output, const Tensor & self, Scalar lambd) const {
  profiler::RecordFunction profiler("softshrink_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<SoftshrinkBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<SoftshrinkBackwardBackward>(new SoftshrinkBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->lambd = lambd;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softshrink_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "lambd", lambd);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::lambd, lambd);
    }
  }
  auto grad_input = as_variable(baseType->softshrink_backward(grad_output_, self_, lambd));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::threshold_out(Tensor & output, const Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "threshold", threshold);
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  Type::threshold_out(output, self, threshold, value);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::threshold(const Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "threshold", threshold);
      setposattr(trace_info.n, 2, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  auto output = Type::threshold(self, threshold, value);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::threshold_forward_out(Tensor & output, const Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("threshold_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("threshold_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "threshold", threshold);
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->threshold_forward_out(output_, self_, threshold, value);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::threshold_forward(const Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ThresholdBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ThresholdBackward0>(new ThresholdBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->threshold = threshold;
    grad_fn->value = value;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "threshold", threshold);
      setposattr(trace_info.n, 2, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  auto output = as_variable(baseType->threshold_forward(self_, threshold, value));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::threshold_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("threshold_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("threshold_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "threshold", threshold);
      setposattr(trace_info.n, 4, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->threshold_backward_out(grad_input_, grad_output_, self_, threshold, value);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::threshold_backward(const Tensor & grad_output, const Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<ThresholdBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<ThresholdBackwardBackward>(new ThresholdBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->threshold = threshold;
    grad_fn->value = value;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "threshold", threshold);
      setposattr(trace_info.n, 3, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  auto grad_input = as_variable(baseType->threshold_backward(grad_output_, self_, threshold, value));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::threshold_(Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "threshold", threshold);
      setposattr(trace_info.n, 2, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  Type::threshold_(self, threshold, value);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::threshold_forward_(Tensor & self, Scalar threshold, Scalar value) const {
  profiler::RecordFunction profiler("threshold_forward_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ThresholdBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ThresholdBackward1>(new ThresholdBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->threshold = threshold;
    grad_fn->value = value;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::threshold_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "threshold", threshold);
      setposattr(trace_info.n, 2, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::threshold, threshold);
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->threshold_forward_(self_, threshold, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->output_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::adaptive_avg_pool2d_out(Tensor & output, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool2d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  Type::adaptive_avg_pool2d_out(output, self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::adaptive_avg_pool2d(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto output = Type::adaptive_avg_pool2d(self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::adaptive_avg_pool2d_forward_out(Tensor & output, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("adaptive_avg_pool2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("adaptive_avg_pool2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool2d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->adaptive_avg_pool2d_forward_out(output_, self_, output_size);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::adaptive_avg_pool2d_forward(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AdaptiveAvgPool2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AdaptiveAvgPool2DBackward>(new AdaptiveAvgPool2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto output = as_variable(baseType->adaptive_avg_pool2d_forward(self_, output_size));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::adaptive_avg_pool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self) const {
  profiler::RecordFunction profiler("adaptive_avg_pool2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("adaptive_avg_pool2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("adaptive_avg_pool2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool2d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->adaptive_avg_pool2d_backward_out(grad_input_, grad_output_, self_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::adaptive_avg_pool2d_backward(const Tensor & grad_output, const Tensor & self) const {
  profiler::RecordFunction profiler("adaptive_avg_pool2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<AdaptiveAvgPool2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<AdaptiveAvgPool2DBackwardBackward>(new AdaptiveAvgPool2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool2d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->adaptive_avg_pool2d_backward(grad_output_, self_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::adaptive_avg_pool3d_out(Tensor & output, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool3d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  Type::adaptive_avg_pool3d_out(output, self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::adaptive_avg_pool3d(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto output = Type::adaptive_avg_pool3d(self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::adaptive_avg_pool3d_forward_out(Tensor & output, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("adaptive_avg_pool3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("adaptive_avg_pool3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool3d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->adaptive_avg_pool3d_forward_out(output_, self_, output_size);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::adaptive_avg_pool3d_forward(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AdaptiveAvgPool3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AdaptiveAvgPool3DBackward>(new AdaptiveAvgPool3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto output = as_variable(baseType->adaptive_avg_pool3d_forward(self_, output_size));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::adaptive_avg_pool3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self) const {
  profiler::RecordFunction profiler("adaptive_avg_pool3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("adaptive_avg_pool3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("adaptive_avg_pool3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool3d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->adaptive_avg_pool3d_backward_out(grad_input_, grad_output_, self_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::adaptive_avg_pool3d_backward(const Tensor & grad_output, const Tensor & self) const {
  profiler::RecordFunction profiler("adaptive_avg_pool3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<AdaptiveAvgPool3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<AdaptiveAvgPool3DBackwardBackward>(new AdaptiveAvgPool3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool3d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->adaptive_avg_pool3d_backward(grad_output_, self_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
std::tuple<Tensor &,Tensor &> VariableType::adaptive_max_pool2d_out(Tensor & output, Tensor & indices, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool2d_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  Type::adaptive_max_pool2d_out(output, indices, self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::adaptive_max_pool2d(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool2d");
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(output, indices) = Type::adaptive_max_pool2d(self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::adaptive_max_pool2d_forward_out(Tensor & output, Tensor & indices, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("adaptive_max_pool2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("adaptive_max_pool2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool2d_forward_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->adaptive_max_pool2d_forward_out(output_, indices_, self_, output_size);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::adaptive_max_pool2d_forward(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AdaptiveMaxPool2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AdaptiveMaxPool2DBackward>(new AdaptiveMaxPool2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(output, indices) = as_variable(baseType->adaptive_max_pool2d_forward(self_, output_size));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
Tensor & VariableType::adaptive_max_pool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & indices) const {
  profiler::RecordFunction profiler("adaptive_max_pool2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("adaptive_max_pool2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("adaptive_max_pool2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool2d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->adaptive_max_pool2d_backward_out(grad_input_, grad_output_, self_, indices_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::adaptive_max_pool2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & indices) const {
  profiler::RecordFunction profiler("adaptive_max_pool2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 2);
  std::shared_ptr<AdaptiveMaxPool2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<AdaptiveMaxPool2DBackwardBackward>(new AdaptiveMaxPool2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool2d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->adaptive_max_pool2d_backward(grad_output_, self_, indices_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
std::tuple<Tensor &,Tensor &> VariableType::adaptive_max_pool3d_out(Tensor & output, Tensor & indices, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool3d_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  Type::adaptive_max_pool3d_out(output, indices, self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::adaptive_max_pool3d(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool3d");
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(output, indices) = Type::adaptive_max_pool3d(self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::adaptive_max_pool3d_forward_out(Tensor & output, Tensor & indices, const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("adaptive_max_pool3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("adaptive_max_pool3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool3d_forward_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->adaptive_max_pool3d_forward_out(output_, indices_, self_, output_size);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::adaptive_max_pool3d_forward(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AdaptiveMaxPool3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AdaptiveMaxPool3DBackward>(new AdaptiveMaxPool3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(output, indices) = as_variable(baseType->adaptive_max_pool3d_forward(self_, output_size));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
Tensor & VariableType::adaptive_max_pool3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & indices) const {
  profiler::RecordFunction profiler("adaptive_max_pool3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("adaptive_max_pool3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("adaptive_max_pool3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool3d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->adaptive_max_pool3d_backward_out(grad_input_, grad_output_, self_, indices_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::adaptive_max_pool3d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & indices) const {
  profiler::RecordFunction profiler("adaptive_max_pool3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 2);
  std::shared_ptr<AdaptiveMaxPool3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<AdaptiveMaxPool3DBackwardBackward>(new AdaptiveMaxPool3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool3d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->adaptive_max_pool3d_backward(grad_output_, self_, indices_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::avg_pool2d_out(Tensor & output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool2d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 6, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  Type::avg_pool2d_out(output, self, kernel_size, stride, padding, ceil_mode, count_include_pad);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::avg_pool2d(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 5, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  auto output = Type::avg_pool2d(self, kernel_size, stride, padding, ceil_mode, count_include_pad);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::avg_pool2d_forward_out(Tensor & output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("avg_pool2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("avg_pool2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool2d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 6, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  baseType->avg_pool2d_forward_out(output_, self_, kernel_size, stride, padding, ceil_mode, count_include_pad);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::avg_pool2d_forward(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AvgPool2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AvgPool2DBackward>(new AvgPool2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->ceil_mode = ceil_mode;
    grad_fn->count_include_pad = count_include_pad;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 5, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  auto output = as_variable(baseType->avg_pool2d_forward(self_, kernel_size, stride, padding, ceil_mode, count_include_pad));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::avg_pool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("avg_pool2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("avg_pool2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool2d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 7, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  baseType->avg_pool2d_backward_out(grad_input_, grad_output_, self_, kernel_size, stride, padding, ceil_mode, count_include_pad);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::avg_pool2d_backward(const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<AvgPool2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<AvgPool2DBackwardBackward>(new AvgPool2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->ceil_mode = ceil_mode;
    grad_fn->count_include_pad = count_include_pad;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool2d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 6, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  auto grad_input = as_variable(baseType->avg_pool2d_backward(grad_output_, self_, kernel_size, stride, padding, ceil_mode, count_include_pad));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::avg_pool3d_out(Tensor & output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool3d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 6, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  Type::avg_pool3d_out(output, self, kernel_size, stride, padding, ceil_mode, count_include_pad);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::avg_pool3d(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 5, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  auto output = Type::avg_pool3d(self, kernel_size, stride, padding, ceil_mode, count_include_pad);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::avg_pool3d_forward_out(Tensor & output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("avg_pool3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("avg_pool3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool3d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 6, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  baseType->avg_pool3d_forward_out(output_, self_, kernel_size, stride, padding, ceil_mode, count_include_pad);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::avg_pool3d_forward(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AvgPool3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AvgPool3DBackward>(new AvgPool3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->ceil_mode = ceil_mode;
    grad_fn->count_include_pad = count_include_pad;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 5, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  auto output = as_variable(baseType->avg_pool3d_forward(self_, kernel_size, stride, padding, ceil_mode, count_include_pad));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::avg_pool3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("avg_pool3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("avg_pool3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool3d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 7, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  baseType->avg_pool3d_backward_out(grad_input_, grad_output_, self_, kernel_size, stride, padding, ceil_mode, count_include_pad);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::avg_pool3d_backward(const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, bool ceil_mode, bool count_include_pad) const {
  profiler::RecordFunction profiler("avg_pool3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<AvgPool3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<AvgPool3DBackwardBackward>(new AvgPool3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->ceil_mode = ceil_mode;
    grad_fn->count_include_pad = count_include_pad;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::avg_pool3d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      setposattr(trace_info.n, 6, "count_include_pad", count_include_pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
      setattr(trace_info.n, jit::attr::count_include_pad, count_include_pad);
    }
  }
  auto grad_input = as_variable(baseType->avg_pool3d_backward(grad_output_, self_, kernel_size, stride, padding, ceil_mode, count_include_pad));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
std::tuple<Tensor &,Tensor &> VariableType::fractional_max_pool2d_out(Tensor & output, Tensor & indices, const Tensor & self, IntList kernel_size, IntList output_size, const Tensor & random_samples) const {
  profiler::RecordFunction profiler("fractional_max_pool2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self, random_samples )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fractional_max_pool2d_out, { output, indices, self, random_samples } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  Type::fractional_max_pool2d_out(output, indices, self, kernel_size, output_size, random_samples);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::fractional_max_pool2d(const Tensor & self, IntList kernel_size, IntList output_size, const Tensor & random_samples) const {
  profiler::RecordFunction profiler("fractional_max_pool2d");
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, random_samples )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fractional_max_pool2d, { self, random_samples } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(output, indices) = Type::fractional_max_pool2d(self, kernel_size, output_size, random_samples);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::fractional_max_pool2d_forward_out(Tensor & output, Tensor & indices, const Tensor & self, IntList kernel_size, IntList output_size, const Tensor & random_samples) const {
  profiler::RecordFunction profiler("fractional_max_pool2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& random_samples_ = unpack(random_samples, "random_samples", 5);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, random_samples )) {
    throw_error_out_requires_grad("fractional_max_pool2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("fractional_max_pool2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self, random_samples )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fractional_max_pool2d_forward_out, { output, indices, self, random_samples } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->fractional_max_pool2d_forward_out(output_, indices_, self_, kernel_size, output_size, random_samples_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::fractional_max_pool2d_forward(const Tensor & self, IntList kernel_size, IntList output_size, const Tensor & random_samples) const {
  profiler::RecordFunction profiler("fractional_max_pool2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& random_samples_ = unpack(random_samples, "random_samples", 3);
  check_no_requires_grad(random_samples, "random_samples");
  std::shared_ptr<FractionalMaxPool2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FractionalMaxPool2DBackward>(new FractionalMaxPool2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->output_size = output_size;
  }
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, random_samples )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fractional_max_pool2d_forward, { self, random_samples } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(output, indices) = as_variable(baseType->fractional_max_pool2d_forward(self_, kernel_size, output_size, random_samples_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
Tensor & VariableType::fractional_max_pool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList output_size, const Tensor & indices) const {
  profiler::RecordFunction profiler("fractional_max_pool2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 5);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("fractional_max_pool2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("fractional_max_pool2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fractional_max_pool2d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->fractional_max_pool2d_backward_out(grad_input_, grad_output_, self_, kernel_size, output_size, indices_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::fractional_max_pool2d_backward(const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList output_size, const Tensor & indices) const {
  profiler::RecordFunction profiler("fractional_max_pool2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 4);
  std::shared_ptr<FractionalMaxPool2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<FractionalMaxPool2DBackwardBackward>(new FractionalMaxPool2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fractional_max_pool2d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto grad_input = as_variable(baseType->fractional_max_pool2d_backward(grad_output_, self_, kernel_size, output_size, indices_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
std::tuple<Tensor &,Tensor &> VariableType::max_pool2d_out(Tensor & output, Tensor & indices, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool2d_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  Type::max_pool2d_out(output, indices, self, kernel_size, stride, padding, dilation, ceil_mode);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::max_pool2d(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool2d");
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "dilation", dilation);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  std::tie(output, indices) = Type::max_pool2d(self, kernel_size, stride, padding, dilation, ceil_mode);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::max_pool2d_forward_out(Tensor & output, Tensor & indices, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("max_pool2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("max_pool2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool2d_forward_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  baseType->max_pool2d_forward_out(output_, indices_, self_, kernel_size, stride, padding, dilation, ceil_mode);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::max_pool2d_forward(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MaxPool2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaxPool2DBackward>(new MaxPool2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
    grad_fn->ceil_mode = ceil_mode;
  }
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "dilation", dilation);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  std::tie(output, indices) = as_variable(baseType->max_pool2d_forward(self_, kernel_size, stride, padding, dilation, ceil_mode));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
Tensor & VariableType::max_pool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode, const Tensor & indices) const {
  profiler::RecordFunction profiler("max_pool2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 8);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("max_pool2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("max_pool2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool2d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  baseType->max_pool2d_backward_out(grad_input_, grad_output_, self_, kernel_size, stride, padding, dilation, ceil_mode, indices_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::max_pool2d_backward(const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode, const Tensor & indices) const {
  profiler::RecordFunction profiler("max_pool2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 7);
  std::shared_ptr<MaxPool2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<MaxPool2DBackwardBackward>(new MaxPool2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool2d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  auto grad_input = as_variable(baseType->max_pool2d_backward(grad_output_, self_, kernel_size, stride, padding, dilation, ceil_mode, indices_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
std::tuple<Tensor &,Tensor &> VariableType::max_pool3d_out(Tensor & output, Tensor & indices, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool3d_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  Type::max_pool3d_out(output, indices, self, kernel_size, stride, padding, dilation, ceil_mode);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::max_pool3d(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool3d");
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "dilation", dilation);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  std::tie(output, indices) = Type::max_pool3d(self, kernel_size, stride, padding, dilation, ceil_mode);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
std::tuple<Tensor &,Tensor &> VariableType::max_pool3d_forward_out(Tensor & output, Tensor & indices, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("max_pool3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("max_pool3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, indices, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool3d_forward_out, { output, indices, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  baseType->max_pool3d_forward_out(output_, indices_, self_, kernel_size, stride, padding, dilation, ceil_mode);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, indices} );
  }
  return std::forward_as_tuple(output, indices);
}
std::tuple<Tensor,Tensor> VariableType::max_pool3d_forward(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<MaxPool3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaxPool3DBackward>(new MaxPool3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
    grad_fn->ceil_mode = ceil_mode;
  }
  Tensor output;
  Tensor indices;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "dilation", dilation);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  std::tie(output, indices) = as_variable(baseType->max_pool3d_forward(self_, kernel_size, stride, padding, dilation, ceil_mode));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, indices } );
  }
  if (grad_fn) {
    grad_fn->indices_ = SavedVariable(indices, true);
  }
  return std::make_tuple(std::move(output), std::move(indices));
}
Tensor & VariableType::max_pool3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode, const Tensor & indices) const {
  profiler::RecordFunction profiler("max_pool3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 8);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("max_pool3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("max_pool3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool3d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  baseType->max_pool3d_backward_out(grad_input_, grad_output_, self_, kernel_size, stride, padding, dilation, ceil_mode, indices_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::max_pool3d_backward(const Tensor & grad_output, const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode, const Tensor & indices) const {
  profiler::RecordFunction profiler("max_pool3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 7);
  std::shared_ptr<MaxPool3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<MaxPool3DBackwardBackward>(new MaxPool3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool3d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  auto grad_input = as_variable(baseType->max_pool3d_backward(grad_output_, self_, kernel_size, stride, padding, dilation, ceil_mode, indices_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::max_unpool2d_out(Tensor & output, const Tensor & self, const Tensor & indices, IntList output_size) const {
  profiler::RecordFunction profiler("max_unpool2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool2d_out, { output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  Type::max_unpool2d_out(output, self, indices, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::max_unpool2d(const Tensor & self, const Tensor & indices, IntList output_size) const {
  profiler::RecordFunction profiler("max_unpool2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool2d, { self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto output = Type::max_unpool2d(self, indices, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::max_unpool2d_forward_out(Tensor & output, const Tensor & self, const Tensor & indices, IntList output_size) const {
  profiler::RecordFunction profiler("max_unpool2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("max_unpool2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("max_unpool2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool2d_forward_out, { output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->max_unpool2d_forward_out(output_, self_, indices_, output_size);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::max_unpool2d_forward(const Tensor & self, const Tensor & indices, IntList output_size) const {
  profiler::RecordFunction profiler("max_unpool2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  std::shared_ptr<MaxUnpool2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaxUnpool2DBackward>(new MaxUnpool2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->output_size = output_size;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool2d_forward, { self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto output = as_variable(baseType->max_unpool2d_forward(self_, indices_, output_size));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::max_unpool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & indices, IntList output_size) const {
  profiler::RecordFunction profiler("max_unpool2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("max_unpool2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("max_unpool2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool2d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  baseType->max_unpool2d_backward_out(grad_input_, grad_output_, self_, indices_, output_size);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::max_unpool2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & indices, IntList output_size) const {
  profiler::RecordFunction profiler("max_unpool2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 2);
  std::shared_ptr<MaxUnpool2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<MaxUnpool2DBackwardBackward>(new MaxUnpool2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->output_size = output_size;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool2d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto grad_input = as_variable(baseType->max_unpool2d_backward(grad_output_, self_, indices_, output_size));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::max_unpool3d_out(Tensor & output, const Tensor & self, const Tensor & indices, IntList output_size, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("max_unpool3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool3d_out, { output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::max_unpool3d_out(output, self, indices, output_size, stride, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::max_unpool3d(const Tensor & self, const Tensor & indices, IntList output_size, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("max_unpool3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool3d, { self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::max_unpool3d(self, indices, output_size, stride, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::max_unpool3d_forward_out(Tensor & output, const Tensor & self, const Tensor & indices, IntList output_size, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("max_unpool3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("max_unpool3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("max_unpool3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool3d_forward_out, { output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->max_unpool3d_forward_out(output_, self_, indices_, output_size, stride, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::max_unpool3d_forward(const Tensor & self, const Tensor & indices, IntList output_size, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("max_unpool3d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  std::shared_ptr<MaxUnpool3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<MaxUnpool3DBackward>(new MaxUnpool3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->output_size = output_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool3d_forward, { self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = as_variable(baseType->max_unpool3d_forward(self_, indices_, output_size, stride, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::max_unpool3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & indices, IntList output_size, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("max_unpool3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  auto& indices_ = unpack(indices, "indices", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("max_unpool3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("max_unpool3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool3d_backward_out, { grad_input, grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "output_size", output_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->max_unpool3d_backward_out(grad_input_, grad_output_, self_, indices_, output_size, stride, padding);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::max_unpool3d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & indices, IntList output_size, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("max_unpool3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& indices_ = unpack(indices, "indices", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for max_unpool3d_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_unpool3d_backward, { grad_output, self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "output_size", output_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto grad_input = as_variable(baseType->max_unpool3d_backward(grad_output_, self_, indices_, output_size, stride, padding));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::reflection_pad1d_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad1d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad1d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::reflection_pad1d_out(output, self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::reflection_pad1d(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad1d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::reflection_pad1d(self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::reflection_pad1d_forward_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad1d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("reflection_pad1d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("reflection_pad1d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad1d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->reflection_pad1d_forward_out(output_, self_, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::reflection_pad1d_forward(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad1d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReflectionPad1DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReflectionPad1DBackward>(new ReflectionPad1DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->padding = padding;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad1d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = as_variable(baseType->reflection_pad1d_forward(self_, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::reflection_pad1d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad1d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("reflection_pad1d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("reflection_pad1d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad1d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->reflection_pad1d_backward_out(grad_input_, grad_output_, self_, padding);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::reflection_pad1d_backward(const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad1d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<ReflectionPad1DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<ReflectionPad1DBackwardBackward>(new ReflectionPad1DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->padding = padding;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad1d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto grad_input = as_variable(baseType->reflection_pad1d_backward(grad_output_, self_, padding));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::reflection_pad2d_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad2d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::reflection_pad2d_out(output, self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::reflection_pad2d(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::reflection_pad2d(self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::reflection_pad2d_forward_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("reflection_pad2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("reflection_pad2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad2d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->reflection_pad2d_forward_out(output_, self_, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::reflection_pad2d_forward(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReflectionPad2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReflectionPad2DBackward>(new ReflectionPad2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->padding = padding;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = as_variable(baseType->reflection_pad2d_forward(self_, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::reflection_pad2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("reflection_pad2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("reflection_pad2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad2d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->reflection_pad2d_backward_out(grad_input_, grad_output_, self_, padding);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::reflection_pad2d_backward(const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("reflection_pad2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<ReflectionPad2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<ReflectionPad2DBackwardBackward>(new ReflectionPad2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->padding = padding;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reflection_pad2d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto grad_input = as_variable(baseType->reflection_pad2d_backward(grad_output_, self_, padding));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::replication_pad1d_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad1d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad1d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::replication_pad1d_out(output, self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::replication_pad1d(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad1d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::replication_pad1d(self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::replication_pad1d_forward_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad1d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("replication_pad1d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("replication_pad1d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad1d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->replication_pad1d_forward_out(output_, self_, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::replication_pad1d_forward(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad1d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReplicationPad1DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReplicationPad1DBackward>(new ReplicationPad1DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->padding = padding;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad1d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = as_variable(baseType->replication_pad1d_forward(self_, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::replication_pad1d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad1d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("replication_pad1d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("replication_pad1d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad1d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->replication_pad1d_backward_out(grad_input_, grad_output_, self_, padding);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::replication_pad1d_backward(const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad1d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<ReplicationPad1DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<ReplicationPad1DBackwardBackward>(new ReplicationPad1DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->padding = padding;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad1d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto grad_input = as_variable(baseType->replication_pad1d_backward(grad_output_, self_, padding));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::replication_pad2d_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad2d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::replication_pad2d_out(output, self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::replication_pad2d(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::replication_pad2d(self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::replication_pad2d_forward_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("replication_pad2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("replication_pad2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad2d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->replication_pad2d_forward_out(output_, self_, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::replication_pad2d_forward(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReplicationPad2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReplicationPad2DBackward>(new ReplicationPad2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->padding = padding;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = as_variable(baseType->replication_pad2d_forward(self_, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::replication_pad2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("replication_pad2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("replication_pad2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad2d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->replication_pad2d_backward_out(grad_input_, grad_output_, self_, padding);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::replication_pad2d_backward(const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<ReplicationPad2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<ReplicationPad2DBackwardBackward>(new ReplicationPad2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->padding = padding;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad2d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto grad_input = as_variable(baseType->replication_pad2d_backward(grad_output_, self_, padding));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::replication_pad3d_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad3d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::replication_pad3d_out(output, self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::replication_pad3d(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::replication_pad3d(self, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::replication_pad3d_forward_out(Tensor & output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("replication_pad3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("replication_pad3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad3d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->replication_pad3d_forward_out(output_, self_, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::replication_pad3d_forward(const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReplicationPad3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReplicationPad3DBackward>(new ReplicationPad3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->padding = padding;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = as_variable(baseType->replication_pad3d_forward(self_, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::replication_pad3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("replication_pad3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("replication_pad3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad3d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->replication_pad3d_backward_out(grad_input_, grad_output_, self_, padding);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::replication_pad3d_backward(const Tensor & grad_output, const Tensor & self, IntList padding) const {
  profiler::RecordFunction profiler("replication_pad3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<ReplicationPad3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<ReplicationPad3DBackwardBackward>(new ReplicationPad3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->padding = padding;
    grad_fn->self_info = self;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::replication_pad3d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto grad_input = as_variable(baseType->replication_pad3d_backward(grad_output_, self_, padding));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::upsample_linear1d_out(Tensor & output, const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_linear1d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_linear1d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  Type::upsample_linear1d_out(output, self, output_size, align_corners);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_linear1d(const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_linear1d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_linear1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto output = Type::upsample_linear1d(self, output_size, align_corners);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_linear1d_forward_out(Tensor & output, const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_linear1d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("upsample_linear1d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("upsample_linear1d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_linear1d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  baseType->upsample_linear1d_forward_out(output_, self_, output_size, align_corners);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_linear1d_forward(const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_linear1d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UpsampleLinear1DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UpsampleLinear1DBackward>(new UpsampleLinear1DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->output_size = output_size;
    grad_fn->align_corners = align_corners;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_linear1d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto output = as_variable(baseType->upsample_linear1d_forward(self_, output_size, align_corners));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_linear1d_backward_out(Tensor & grad_input, const Tensor & grad_output, IntList output_size, IntList input_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_linear1d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output )) {
    throw_error_out_requires_grad("upsample_linear1d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("upsample_linear1d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_linear1d_backward_out, { grad_input, grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "input_size", input_size);
      setposattr(trace_info.n, 4, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  baseType->upsample_linear1d_backward_out(grad_input_, grad_output_, output_size, input_size, align_corners);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::upsample_linear1d_backward(const Tensor & grad_output, IntList output_size, IntList input_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_linear1d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  std::shared_ptr<UpsampleLinear1DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output )) {
    grad_fn = std::shared_ptr<UpsampleLinear1DBackwardBackward>(new UpsampleLinear1DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output ));
    grad_fn->output_size = output_size;
    grad_fn->align_corners = align_corners;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_linear1d_backward, { grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "input_size", input_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto grad_input = as_variable(baseType->upsample_linear1d_backward(grad_output_, output_size, input_size, align_corners));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::upsample_bilinear2d_out(Tensor & output, const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_bilinear2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_bilinear2d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  Type::upsample_bilinear2d_out(output, self, output_size, align_corners);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_bilinear2d(const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_bilinear2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_bilinear2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto output = Type::upsample_bilinear2d(self, output_size, align_corners);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_bilinear2d_forward_out(Tensor & output, const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_bilinear2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("upsample_bilinear2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("upsample_bilinear2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_bilinear2d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  baseType->upsample_bilinear2d_forward_out(output_, self_, output_size, align_corners);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_bilinear2d_forward(const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_bilinear2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UpsampleBilinear2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UpsampleBilinear2DBackward>(new UpsampleBilinear2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->output_size = output_size;
    grad_fn->align_corners = align_corners;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_bilinear2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto output = as_variable(baseType->upsample_bilinear2d_forward(self_, output_size, align_corners));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_bilinear2d_backward_out(Tensor & grad_input, const Tensor & grad_output, IntList output_size, IntList input_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_bilinear2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output )) {
    throw_error_out_requires_grad("upsample_bilinear2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("upsample_bilinear2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_bilinear2d_backward_out, { grad_input, grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "input_size", input_size);
      setposattr(trace_info.n, 4, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  baseType->upsample_bilinear2d_backward_out(grad_input_, grad_output_, output_size, input_size, align_corners);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::upsample_bilinear2d_backward(const Tensor & grad_output, IntList output_size, IntList input_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_bilinear2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  std::shared_ptr<UpsampleBilinear2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output )) {
    grad_fn = std::shared_ptr<UpsampleBilinear2DBackwardBackward>(new UpsampleBilinear2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output ));
    grad_fn->output_size = output_size;
    grad_fn->align_corners = align_corners;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_bilinear2d_backward, { grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "input_size", input_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto grad_input = as_variable(baseType->upsample_bilinear2d_backward(grad_output_, output_size, input_size, align_corners));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::upsample_trilinear3d_out(Tensor & output, const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_trilinear3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_trilinear3d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  Type::upsample_trilinear3d_out(output, self, output_size, align_corners);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_trilinear3d(const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_trilinear3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_trilinear3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto output = Type::upsample_trilinear3d(self, output_size, align_corners);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_trilinear3d_forward_out(Tensor & output, const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_trilinear3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("upsample_trilinear3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("upsample_trilinear3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_trilinear3d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  baseType->upsample_trilinear3d_forward_out(output_, self_, output_size, align_corners);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_trilinear3d_forward(const Tensor & self, IntList output_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_trilinear3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UpsampleTrilinear3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UpsampleTrilinear3DBackward>(new UpsampleTrilinear3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->output_size = output_size;
    grad_fn->align_corners = align_corners;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_trilinear3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto output = as_variable(baseType->upsample_trilinear3d_forward(self_, output_size, align_corners));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_trilinear3d_backward_out(Tensor & grad_input, const Tensor & grad_output, IntList output_size, IntList input_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_trilinear3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output )) {
    throw_error_out_requires_grad("upsample_trilinear3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("upsample_trilinear3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_trilinear3d_backward_out, { grad_input, grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "output_size", output_size);
      setposattr(trace_info.n, 3, "input_size", input_size);
      setposattr(trace_info.n, 4, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  baseType->upsample_trilinear3d_backward_out(grad_input_, grad_output_, output_size, input_size, align_corners);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::upsample_trilinear3d_backward(const Tensor & grad_output, IntList output_size, IntList input_size, bool align_corners) const {
  profiler::RecordFunction profiler("upsample_trilinear3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  std::shared_ptr<UpsampleTrilinear3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output )) {
    grad_fn = std::shared_ptr<UpsampleTrilinear3DBackwardBackward>(new UpsampleTrilinear3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output ));
    grad_fn->output_size = output_size;
    grad_fn->align_corners = align_corners;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_trilinear3d_backward, { grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      setposattr(trace_info.n, 2, "input_size", input_size);
      setposattr(trace_info.n, 3, "align_corners", align_corners);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::align_corners, align_corners);
    }
  }
  auto grad_input = as_variable(baseType->upsample_trilinear3d_backward(grad_output_, output_size, input_size, align_corners));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::upsample_nearest1d_out(Tensor & output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest1d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest1d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  Type::upsample_nearest1d_out(output, self, scale_factor);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_nearest1d(const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest1d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto output = Type::upsample_nearest1d(self, scale_factor);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_nearest1d_forward_out(Tensor & output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest1d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("upsample_nearest1d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("upsample_nearest1d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest1d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  baseType->upsample_nearest1d_forward_out(output_, self_, scale_factor);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_nearest1d_forward(const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest1d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UpsampleNearest1DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UpsampleNearest1DBackward>(new UpsampleNearest1DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->scale_factor = scale_factor;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest1d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto output = as_variable(baseType->upsample_nearest1d_forward(self_, scale_factor));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_nearest1d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest1d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("upsample_nearest1d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("upsample_nearest1d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest1d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  baseType->upsample_nearest1d_backward_out(grad_input_, grad_output_, self_, scale_factor);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::upsample_nearest1d_backward(const Tensor & grad_output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest1d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<UpsampleNearest1DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<UpsampleNearest1DBackwardBackward>(new UpsampleNearest1DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->scale_factor = scale_factor;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest1d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto grad_input = as_variable(baseType->upsample_nearest1d_backward(grad_output_, self_, scale_factor));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::upsample_nearest2d_out(Tensor & output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest2d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  Type::upsample_nearest2d_out(output, self, scale_factor);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_nearest2d(const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest2d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto output = Type::upsample_nearest2d(self, scale_factor);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_nearest2d_forward_out(Tensor & output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("upsample_nearest2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("upsample_nearest2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest2d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  baseType->upsample_nearest2d_forward_out(output_, self_, scale_factor);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_nearest2d_forward(const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest2d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UpsampleNearest2DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UpsampleNearest2DBackward>(new UpsampleNearest2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->scale_factor = scale_factor;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest2d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto output = as_variable(baseType->upsample_nearest2d_forward(self_, scale_factor));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_nearest2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest2d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("upsample_nearest2d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("upsample_nearest2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest2d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  baseType->upsample_nearest2d_backward_out(grad_input_, grad_output_, self_, scale_factor);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::upsample_nearest2d_backward(const Tensor & grad_output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<UpsampleNearest2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<UpsampleNearest2DBackwardBackward>(new UpsampleNearest2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->scale_factor = scale_factor;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest2d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto grad_input = as_variable(baseType->upsample_nearest2d_backward(grad_output_, self_, scale_factor));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::upsample_nearest3d_out(Tensor & output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest3d_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  Type::upsample_nearest3d_out(output, self, scale_factor);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_nearest3d(const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest3d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto output = Type::upsample_nearest3d(self, scale_factor);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_nearest3d_forward_out(Tensor & output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("upsample_nearest3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("upsample_nearest3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest3d_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  baseType->upsample_nearest3d_forward_out(output_, self_, scale_factor);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::upsample_nearest3d_forward(const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest3d_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UpsampleNearest3DBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UpsampleNearest3DBackward>(new UpsampleNearest3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->scale_factor = scale_factor;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest3d_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto output = as_variable(baseType->upsample_nearest3d_forward(self_, scale_factor));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::upsample_nearest3d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest3d_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    throw_error_out_requires_grad("upsample_nearest3d_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("upsample_nearest3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest3d_backward_out, { grad_input, grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  baseType->upsample_nearest3d_backward_out(grad_input_, grad_output_, self_, scale_factor);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::upsample_nearest3d_backward(const Tensor & grad_output, const Tensor & self, int64_t scale_factor) const {
  profiler::RecordFunction profiler("upsample_nearest3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<UpsampleNearest3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<UpsampleNearest3DBackwardBackward>(new UpsampleNearest3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->scale_factor = scale_factor;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::upsample_nearest3d_backward, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "scale_factor", scale_factor);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_factor, scale_factor);
    }
  }
  auto grad_input = as_variable(baseType->upsample_nearest3d_backward(grad_output_, self_, scale_factor));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::_sigmoid_out(Tensor & output, const Tensor & self) const {
  profiler::RecordFunction profiler("_sigmoid_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sigmoid_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::_sigmoid_out(output, self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::_sigmoid(const Tensor & self) const {
  profiler::RecordFunction profiler("_sigmoid");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sigmoid, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = Type::_sigmoid(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::_sigmoid_forward_out(Tensor & output, const Tensor & self) const {
  profiler::RecordFunction profiler("_sigmoid_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_sigmoid_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("_sigmoid_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sigmoid_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_sigmoid_forward_out(output_, self_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::_sigmoid_forward(const Tensor & self) const {
  profiler::RecordFunction profiler("_sigmoid_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _sigmoid_forward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sigmoid_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = as_variable(baseType->_sigmoid_forward(self_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::_sigmoid_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & output) const {
  profiler::RecordFunction profiler("_sigmoid_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& output_ = unpack(output, "output", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, output )) {
    throw_error_out_requires_grad("_sigmoid_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("_sigmoid_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sigmoid_backward_out, { grad_input, grad_output, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_sigmoid_backward_out(grad_input_, grad_output_, output_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::_sigmoid_backward(const Tensor & grad_output, const Tensor & output) const {
  profiler::RecordFunction profiler("_sigmoid_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& output_ = unpack(output, "output", 1);
  std::shared_ptr<SigmoidBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, output )) {
    grad_fn = std::shared_ptr<SigmoidBackwardBackward>(new SigmoidBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, output ));
    grad_fn->output_ = SavedVariable(output, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sigmoid_backward, { grad_output, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->_sigmoid_backward(grad_output_, output_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::_tanh_out(Tensor & output, const Tensor & self) const {
  profiler::RecordFunction profiler("_tanh_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tanh_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::_tanh_out(output, self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::_tanh(const Tensor & self) const {
  profiler::RecordFunction profiler("_tanh");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tanh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = Type::_tanh(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::_tanh_forward_out(Tensor & output, const Tensor & self) const {
  profiler::RecordFunction profiler("_tanh_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_tanh_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("_tanh_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tanh_forward_out, { output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_tanh_forward_out(output_, self_);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::_tanh_forward(const Tensor & self) const {
  profiler::RecordFunction profiler("_tanh_forward");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _tanh_forward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tanh_forward, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = as_variable(baseType->_tanh_forward(self_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::_tanh_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & output) const {
  profiler::RecordFunction profiler("_tanh_backward_out");
  auto& grad_input_ = unpack(grad_input, "grad_input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& output_ = unpack(output, "output", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, output )) {
    throw_error_out_requires_grad("_tanh_backward");
  }
  if (compute_requires_grad( grad_input )) {
    throw_error_out_requires_grad("_tanh_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_output, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tanh_backward_out, { grad_input, grad_output, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->_tanh_backward_out(grad_input_, grad_output_, output_);
  increment_version(grad_input);
  rebase_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input} );
  }
  return grad_input;
}
Tensor VariableType::_tanh_backward(const Tensor & grad_output, const Tensor & output) const {
  profiler::RecordFunction profiler("_tanh_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& output_ = unpack(output, "output", 1);
  std::shared_ptr<TanhBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, output )) {
    grad_fn = std::shared_ptr<TanhBackwardBackward>(new TanhBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, output ));
    grad_fn->output_ = SavedVariable(output, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_tanh_backward, { grad_output, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto grad_input = as_variable(baseType->_tanh_backward(grad_output_, output_));
  set_history(flatten( grad_input ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input } );
  }
  return grad_input;
}
Tensor & VariableType::thnn_batch_norm_out(Tensor & output, const Tensor & self, const Tensor & weight, const Tensor & bias, const Tensor & running_mean, const Tensor & running_var, bool training, double momentum, double eps) const {
  profiler::RecordFunction profiler("thnn_batch_norm_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias, running_mean, running_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_batch_norm_out, { output, self, weight, bias, running_mean, running_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "training", training);
      setposattr(trace_info.n, 7, "momentum", momentum);
      setposattr(trace_info.n, 8, "eps", eps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::momentum, momentum);
      setattr(trace_info.n, jit::attr::eps, eps);
    }
  }
  Type::thnn_batch_norm_out(output, self, weight, bias, running_mean, running_var, training, momentum, eps);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_batch_norm(const Tensor & self, const Tensor & weight, const Tensor & bias, const Tensor & running_mean, const Tensor & running_var, bool training, double momentum, double eps) const {
  profiler::RecordFunction profiler("thnn_batch_norm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias, running_mean, running_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_batch_norm, { self, weight, bias, running_mean, running_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "training", training);
      setposattr(trace_info.n, 6, "momentum", momentum);
      setposattr(trace_info.n, 7, "eps", eps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::momentum, momentum);
      setattr(trace_info.n, jit::attr::eps, eps);
    }
  }
  auto output = Type::thnn_batch_norm(self, weight, bias, running_mean, running_var, training, momentum, eps);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_batch_norm_forward_out(Tensor & output, Tensor & save_mean, Tensor & save_std, const Tensor & self, const Tensor & weight, const Tensor & bias, const Tensor & running_mean, const Tensor & running_var, bool training, double momentum, double eps) const {
  profiler::RecordFunction profiler("thnn_batch_norm_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& save_mean_ = unpack(save_mean, "save_mean", 1);
  auto& save_std_ = unpack(save_std, "save_std", 2);
  auto& self_ = unpack(self, "self", 3);
  auto weight_ = unpack_opt(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 5);
  auto running_mean_ = unpack_opt(running_mean, "running_mean", 6);
  auto running_var_ = unpack_opt(running_var, "running_var", 7);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias, running_mean, running_var )) {
    throw_error_out_requires_grad("thnn_batch_norm_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_batch_norm_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, save_mean, save_std, self, weight, bias, running_mean, running_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_batch_norm_forward_out, { output, save_mean, save_std, self, weight, bias, running_mean, running_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 8, "training", training);
      setposattr(trace_info.n, 9, "momentum", momentum);
      setposattr(trace_info.n, 10, "eps", eps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::momentum, momentum);
      setattr(trace_info.n, jit::attr::eps, eps);
    }
  }
  baseType->thnn_batch_norm_forward_out(output_, save_mean_, save_std_, self_, weight_, bias_, running_mean_, running_var_, training, momentum, eps);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, save_mean, save_std} );
  }
  return std::forward_as_tuple(output, save_mean, save_std);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_batch_norm_forward(const Tensor & self, const Tensor & weight, const Tensor & bias, const Tensor & running_mean, const Tensor & running_var, bool training, double momentum, double eps) const {
  profiler::RecordFunction profiler("thnn_batch_norm_forward");
  auto& self_ = unpack(self, "self", 0);
  auto weight_ = unpack_opt(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 2);
  auto running_mean_ = unpack_opt(running_mean, "running_mean", 3);
  auto running_var_ = unpack_opt(running_var, "running_var", 4);
  check_no_requires_grad(running_mean, "running_mean");
  check_no_requires_grad(running_var, "running_var");
  std::shared_ptr<ThnnBatchNormBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnBatchNormBackward>(new ThnnBatchNormBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->running_mean_ = SavedVariable(running_mean, false);
    grad_fn->running_var_ = SavedVariable(running_var, false);
    grad_fn->training = training;
    grad_fn->eps = eps;
  }
  Tensor output;
  Tensor save_mean;
  Tensor save_std;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias, running_mean, running_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_batch_norm_forward, { self, weight, bias, running_mean, running_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "training", training);
      setposattr(trace_info.n, 6, "momentum", momentum);
      setposattr(trace_info.n, 7, "eps", eps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::momentum, momentum);
      setattr(trace_info.n, jit::attr::eps, eps);
    }
  }
  std::tie(output, save_mean, save_std) = as_variable(baseType->thnn_batch_norm_forward(self_, weight_, bias_, running_mean_, running_var_, training, momentum, eps));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, save_mean, save_std } );
  }
  if (grad_fn) {
    grad_fn->save_mean_ = SavedVariable(save_mean, true);
    grad_fn->save_std_ = SavedVariable(save_std, true);
  }
  return std::make_tuple(std::move(output), std::move(save_mean), std::move(save_std));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_batch_norm_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, const Tensor & running_mean, const Tensor & running_var, bool training, double eps, const Tensor & save_mean, const Tensor & save_std) const {
  profiler::RecordFunction profiler("thnn_batch_norm_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto weight_ = unpack_opt(weight, "weight", 5);
  auto running_mean_ = unpack_opt(running_mean, "running_mean", 6);
  auto running_var_ = unpack_opt(running_var, "running_var", 7);
  auto save_mean_ = unpack_opt(save_mean, "save_mean", 10);
  auto save_std_ = unpack_opt(save_std, "save_std", 11);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, running_mean, running_var, save_mean, save_std )) {
    throw_error_out_requires_grad("thnn_batch_norm_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_batch_norm_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, running_mean, running_var, save_mean, save_std )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_batch_norm_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, running_mean, running_var, save_mean, save_std } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 8, "training", training);
      setposattr(trace_info.n, 9, "eps", eps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::eps, eps);
    }
  }
  baseType->thnn_batch_norm_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, running_mean_, running_var_, training, eps, save_mean_, save_std_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_batch_norm_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, const Tensor & running_mean, const Tensor & running_var, bool training, double eps, const Tensor & save_mean, const Tensor & save_std, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_batch_norm_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto weight_ = unpack_opt(weight, "weight", 2);
  auto running_mean_ = unpack_opt(running_mean, "running_mean", 3);
  auto running_var_ = unpack_opt(running_var, "running_var", 4);
  auto save_mean_ = unpack_opt(save_mean, "save_mean", 7);
  auto save_std_ = unpack_opt(save_std, "save_std", 8);
  check_no_requires_grad(running_mean, "running_mean");
  check_no_requires_grad(running_var, "running_var");
  std::shared_ptr<ThnnBatchNormBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, save_mean, save_std )) {
    grad_fn = std::shared_ptr<ThnnBatchNormBackwardBackward>(new ThnnBatchNormBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight, save_mean, save_std ));
    grad_fn->save_mean_ = SavedVariable(save_mean, false);
    grad_fn->save_std_ = SavedVariable(save_std, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->running_mean_ = SavedVariable(running_mean, false);
    grad_fn->running_var_ = SavedVariable(running_var, false);
    grad_fn->training = training;
    grad_fn->eps = eps;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, running_mean, running_var, save_mean, save_std )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_batch_norm_backward, { grad_output, self, weight, running_mean, running_var, save_mean, save_std } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "training", training);
      setposattr(trace_info.n, 6, "eps", eps);
      setposattr(trace_info.n, 9, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::eps, eps);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_batch_norm_backward(grad_output_, self_, weight_, running_mean_, running_var_, training, eps, save_mean_, save_std_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor & VariableType::thnn_conv_transpose2d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose2d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      setposattr(trace_info.n, 7, "output_padding", output_padding);
      setposattr(trace_info.n, 8, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  Type::thnn_conv_transpose2d_out(output, self, weight, kernel_size, bias, stride, padding, output_padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv_transpose2d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose2d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "output_padding", output_padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto output = Type::thnn_conv_transpose2d(self, weight, kernel_size, bias, stride, padding, output_padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_transpose2d_forward_out(Tensor & output, Tensor & columns, Tensor & ones, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& columns_ = unpack(columns, "columns", 1);
  auto& ones_ = unpack(ones, "ones", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv_transpose2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv_transpose2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, columns, ones, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose2d_forward_out, { output, columns, ones, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "output_padding", output_padding);
      setposattr(trace_info.n, 10, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_transpose2d_forward_out(output_, columns_, ones_, self_, weight_, kernel_size, bias_, stride, padding, output_padding, dilation);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, columns, ones} );
  }
  return std::forward_as_tuple(output, columns, ones);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_transpose2d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConvTranspose2DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConvTranspose2DBackward>(new ThnnConvTranspose2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->output_padding = output_padding;
    grad_fn->dilation = dilation;
  }
  Tensor output;
  Tensor columns;
  Tensor ones;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose2d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "output_padding", output_padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  std::tie(output, columns, ones) = as_variable(baseType->thnn_conv_transpose2d_forward(self_, weight_, kernel_size, bias_, stride, padding, output_padding, dilation));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, columns, ones } );
  }
  if (grad_fn) {
    grad_fn->columns_ = SavedVariable(columns, true);
    grad_fn->ones_ = SavedVariable(ones, true);
  }
  return std::make_tuple(std::move(output), std::move(columns), std::move(ones));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_transpose2d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList output_padding, IntList dilation, const Tensor & columns, const Tensor & ones) const {
  profiler::RecordFunction profiler("thnn_conv_transpose2d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto& weight_ = unpack(weight, "weight", 5);
  auto& columns_ = unpack(columns, "columns", 11);
  auto& ones_ = unpack(ones, "ones", 12);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, columns, ones )) {
    throw_error_out_requires_grad("thnn_conv_transpose2d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_conv_transpose2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, columns, ones )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose2d_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, columns, ones } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "output_padding", output_padding);
      setposattr(trace_info.n, 10, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_transpose2d_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, kernel_size, stride, padding, output_padding, dilation, columns_, ones_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_transpose2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList output_padding, IntList dilation, const Tensor & columns, const Tensor & ones, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv_transpose2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto& columns_ = unpack(columns, "columns", 8);
  auto& ones_ = unpack(ones, "ones", 9);
  check_no_requires_grad(columns, "columns");
  check_no_requires_grad(ones, "ones");
  std::shared_ptr<ThnnConvTranspose2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConvTranspose2DBackwardBackward>(new ThnnConvTranspose2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->output_padding = output_padding;
    grad_fn->dilation = dilation;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, columns, ones )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose2d_backward, { grad_output, self, weight, columns, ones } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "output_padding", output_padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      setposattr(trace_info.n, 10, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_conv_transpose2d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, output_padding, dilation, columns_, ones_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor & VariableType::thnn_conv_transpose3d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose3d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      setposattr(trace_info.n, 7, "output_padding", output_padding);
      setposattr(trace_info.n, 8, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  Type::thnn_conv_transpose3d_out(output, self, weight, kernel_size, bias, stride, padding, output_padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv_transpose3d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose3d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "output_padding", output_padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto output = Type::thnn_conv_transpose3d(self, weight, kernel_size, bias, stride, padding, output_padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_transpose3d_forward_out(Tensor & output, Tensor & finput, Tensor & fgrad_input, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& finput_ = unpack(finput, "finput", 1);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv_transpose3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv_transpose3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, finput, fgrad_input, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose3d_forward_out, { output, finput, fgrad_input, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "output_padding", output_padding);
      setposattr(trace_info.n, 10, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_transpose3d_forward_out(output_, finput_, fgrad_input_, self_, weight_, kernel_size, bias_, stride, padding, output_padding, dilation);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, finput, fgrad_input} );
  }
  return std::forward_as_tuple(output, finput, fgrad_input);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_transpose3d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_transpose3d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConvTranspose3DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConvTranspose3DBackward>(new ThnnConvTranspose3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->output_padding = output_padding;
    grad_fn->dilation = dilation;
  }
  Tensor output;
  Tensor finput;
  Tensor fgrad_input;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose3d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "output_padding", output_padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  std::tie(output, finput, fgrad_input) = as_variable(baseType->thnn_conv_transpose3d_forward(self_, weight_, kernel_size, bias_, stride, padding, output_padding, dilation));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, finput, fgrad_input } );
  }
  if (grad_fn) {
    grad_fn->finput_ = SavedVariable(finput, true);
    grad_fn->fgrad_input_ = SavedVariable(fgrad_input, true);
  }
  return std::make_tuple(std::move(output), std::move(finput), std::move(fgrad_input));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_transpose3d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList output_padding, IntList dilation, const Tensor & finput, const Tensor & fgrad_input) const {
  profiler::RecordFunction profiler("thnn_conv_transpose3d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto& weight_ = unpack(weight, "weight", 5);
  auto& finput_ = unpack(finput, "finput", 11);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 12);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, finput, fgrad_input )) {
    throw_error_out_requires_grad("thnn_conv_transpose3d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_conv_transpose3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, finput, fgrad_input )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose3d_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, finput, fgrad_input } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "output_padding", output_padding);
      setposattr(trace_info.n, 10, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_transpose3d_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, kernel_size, stride, padding, output_padding, dilation, finput_, fgrad_input_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_transpose3d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList output_padding, IntList dilation, const Tensor & finput, const Tensor & fgrad_input, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv_transpose3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto& finput_ = unpack(finput, "finput", 8);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 9);
  check_no_requires_grad(finput, "finput");
  check_no_requires_grad(fgrad_input, "fgrad_input");
  std::shared_ptr<ThnnConvTranspose3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConvTranspose3DBackwardBackward>(new ThnnConvTranspose3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->output_padding = output_padding;
    grad_fn->dilation = dilation;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, finput, fgrad_input )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_transpose3d_backward, { grad_output, self, weight, finput, fgrad_input } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "output_padding", output_padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      setposattr(trace_info.n, 10, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_conv_transpose3d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, output_padding, dilation, finput_, fgrad_input_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor & VariableType::thnn_conv2d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv2d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::thnn_conv2d_out(output, self, weight, kernel_size, bias, stride, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv2d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv2d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::thnn_conv2d(self, weight, kernel_size, bias, stride, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv2d_forward_out(Tensor & output, Tensor & finput, Tensor & fgrad_input, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& finput_ = unpack(finput, "finput", 1);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, finput, fgrad_input, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv2d_forward_out, { output, finput, fgrad_input, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->thnn_conv2d_forward_out(output_, finput_, fgrad_input_, self_, weight_, kernel_size, bias_, stride, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, finput, fgrad_input} );
  }
  return std::forward_as_tuple(output, finput, fgrad_input);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv2d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConv2DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConv2DBackward>(new ThnnConv2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
  }
  Tensor output;
  Tensor finput;
  Tensor fgrad_input;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv2d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  std::tie(output, finput, fgrad_input) = as_variable(baseType->thnn_conv2d_forward(self_, weight_, kernel_size, bias_, stride, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, finput, fgrad_input } );
  }
  if (grad_fn) {
    grad_fn->finput_ = SavedVariable(finput, true);
    grad_fn->fgrad_input_ = SavedVariable(fgrad_input, true);
  }
  return std::make_tuple(std::move(output), std::move(finput), std::move(fgrad_input));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv2d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, const Tensor & finput, const Tensor & fgrad_input) const {
  profiler::RecordFunction profiler("thnn_conv2d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto& weight_ = unpack(weight, "weight", 5);
  auto& finput_ = unpack(finput, "finput", 9);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 10);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, finput, fgrad_input )) {
    throw_error_out_requires_grad("thnn_conv2d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_conv2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, finput, fgrad_input )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv2d_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, finput, fgrad_input } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->thnn_conv2d_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, kernel_size, stride, padding, finput_, fgrad_input_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, const Tensor & finput, const Tensor & fgrad_input, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto& finput_ = unpack(finput, "finput", 6);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 7);
  check_no_requires_grad(finput, "finput");
  check_no_requires_grad(fgrad_input, "fgrad_input");
  std::shared_ptr<ThnnConv2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConv2DBackwardBackward>(new ThnnConv2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, finput, fgrad_input )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv2d_backward, { grad_output, self, weight, finput, fgrad_input } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 8, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_conv2d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, finput_, fgrad_input_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor & VariableType::thnn_conv_depthwise2d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_depthwise2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_depthwise2d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  Type::thnn_conv_depthwise2d_out(output, self, weight, kernel_size, bias, stride, padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv_depthwise2d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_depthwise2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_depthwise2d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto output = Type::thnn_conv_depthwise2d(self, weight, kernel_size, bias, stride, padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
Tensor & VariableType::thnn_conv_depthwise2d_forward_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_depthwise2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto bias_ = unpack_opt(bias, "bias", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv_depthwise2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv_depthwise2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_depthwise2d_forward_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_depthwise2d_forward_out(output_, self_, weight_, kernel_size, bias_, stride, padding, dilation);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv_depthwise2d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_depthwise2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConvDepthwise2DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConvDepthwise2DBackward>(new ThnnConvDepthwise2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_depthwise2d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto output = as_variable(baseType->thnn_conv_depthwise2d_forward(self_, weight_, kernel_size, bias_, stride, padding, dilation));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &> VariableType::thnn_conv_depthwise2d_backward_out(Tensor & grad_input, Tensor & grad_weight, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_depthwise2d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto& grad_output_ = unpack(grad_output, "grad_output", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    throw_error_out_requires_grad("thnn_conv_depthwise2d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight )) {
    throw_error_out_requires_grad("thnn_conv_depthwise2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_output, self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_depthwise2d_backward_out, { grad_input, grad_weight, grad_output, self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 6, "stride", stride);
      setposattr(trace_info.n, 7, "padding", padding);
      setposattr(trace_info.n, 8, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_depthwise2d_backward_out(grad_input_, grad_weight_, grad_output_, self_, weight_, kernel_size, stride, padding, dilation);
  increment_version(grad_input);
  increment_version(grad_weight);
  rebase_history(flatten( grad_input, grad_weight ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight} );
  }
  return std::forward_as_tuple(grad_input, grad_weight);
}
std::tuple<Tensor,Tensor> VariableType::thnn_conv_depthwise2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList dilation, std::array<bool,2> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv_depthwise2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  std::shared_ptr<ThnnConvDepthwise2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConvDepthwise2DBackwardBackward>(new ThnnConvDepthwise2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_argsize_1 = self.size(1);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
  }
  Tensor grad_input;
  Tensor grad_weight;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_depthwise2d_backward, { grad_output, self, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight) = as_variable(baseType->thnn_conv_depthwise2d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, dilation, output_mask));
  set_history(flatten( grad_input, grad_weight ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight));
}
Tensor & VariableType::thnn_conv3d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv3d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  Type::thnn_conv3d_out(output, self, weight, kernel_size, bias, stride, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv3d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv3d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  auto output = Type::thnn_conv3d(self, weight, kernel_size, bias, stride, padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv3d_forward_out(Tensor & output, Tensor & finput, Tensor & fgrad_input, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& finput_ = unpack(finput, "finput", 1);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, finput, fgrad_input, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv3d_forward_out, { output, finput, fgrad_input, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->thnn_conv3d_forward_out(output_, finput_, fgrad_input_, self_, weight_, kernel_size, bias_, stride, padding);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, finput, fgrad_input} );
  }
  return std::forward_as_tuple(output, finput, fgrad_input);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv3d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding) const {
  profiler::RecordFunction profiler("thnn_conv3d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConv3DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConv3DBackward>(new ThnnConv3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
  }
  Tensor output;
  Tensor finput;
  Tensor fgrad_input;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv3d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  std::tie(output, finput, fgrad_input) = as_variable(baseType->thnn_conv3d_forward(self_, weight_, kernel_size, bias_, stride, padding));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, finput, fgrad_input } );
  }
  if (grad_fn) {
    grad_fn->finput_ = SavedVariable(finput, true);
    grad_fn->fgrad_input_ = SavedVariable(fgrad_input, true);
  }
  return std::make_tuple(std::move(output), std::move(finput), std::move(fgrad_input));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv3d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, const Tensor & finput, const Tensor & fgrad_input) const {
  profiler::RecordFunction profiler("thnn_conv3d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto& weight_ = unpack(weight, "weight", 5);
  auto& finput_ = unpack(finput, "finput", 9);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 10);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, finput, fgrad_input )) {
    throw_error_out_requires_grad("thnn_conv3d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_conv3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, finput, fgrad_input )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv3d_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, finput, fgrad_input } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
    }
  }
  baseType->thnn_conv3d_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, kernel_size, stride, padding, finput_, fgrad_input_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv3d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, const Tensor & finput, const Tensor & fgrad_input, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto& finput_ = unpack(finput, "finput", 6);
  auto& fgrad_input_ = unpack(fgrad_input, "fgrad_input", 7);
  check_no_requires_grad(finput, "finput");
  check_no_requires_grad(fgrad_input, "fgrad_input");
  std::shared_ptr<ThnnConv3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConv3DBackwardBackward>(new ThnnConv3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, finput, fgrad_input )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv3d_backward, { grad_output, self, weight, finput, fgrad_input } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 8, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_conv3d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, finput_, fgrad_input_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor & VariableType::thnn_conv_dilated2d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated2d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated2d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  Type::thnn_conv_dilated2d_out(output, self, weight, kernel_size, bias, stride, padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv_dilated2d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated2d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated2d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto output = Type::thnn_conv_dilated2d(self, weight, kernel_size, bias, stride, padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_dilated2d_forward_out(Tensor & output, Tensor & columns, Tensor & ones, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated2d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& columns_ = unpack(columns, "columns", 1);
  auto& ones_ = unpack(ones, "ones", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv_dilated2d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv_dilated2d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, columns, ones, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated2d_forward_out, { output, columns, ones, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_dilated2d_forward_out(output_, columns_, ones_, self_, weight_, kernel_size, bias_, stride, padding, dilation);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, columns, ones} );
  }
  return std::forward_as_tuple(output, columns, ones);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_dilated2d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated2d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConvDilated2DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConvDilated2DBackward>(new ThnnConvDilated2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
  }
  Tensor output;
  Tensor columns;
  Tensor ones;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated2d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  std::tie(output, columns, ones) = as_variable(baseType->thnn_conv_dilated2d_forward(self_, weight_, kernel_size, bias_, stride, padding, dilation));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, columns, ones } );
  }
  if (grad_fn) {
    grad_fn->columns_ = SavedVariable(columns, true);
    grad_fn->ones_ = SavedVariable(ones, true);
  }
  return std::make_tuple(std::move(output), std::move(columns), std::move(ones));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_dilated2d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList dilation, const Tensor & columns, const Tensor & ones) const {
  profiler::RecordFunction profiler("thnn_conv_dilated2d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto& weight_ = unpack(weight, "weight", 5);
  auto& columns_ = unpack(columns, "columns", 10);
  auto& ones_ = unpack(ones, "ones", 11);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, columns, ones )) {
    throw_error_out_requires_grad("thnn_conv_dilated2d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_conv_dilated2d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, columns, ones )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated2d_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, columns, ones } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_dilated2d_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, kernel_size, stride, padding, dilation, columns_, ones_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_dilated2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList dilation, const Tensor & columns, const Tensor & ones, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv_dilated2d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto& columns_ = unpack(columns, "columns", 7);
  auto& ones_ = unpack(ones, "ones", 8);
  check_no_requires_grad(columns, "columns");
  check_no_requires_grad(ones, "ones");
  std::shared_ptr<ThnnConvDilated2DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConvDilated2DBackwardBackward>(new ThnnConvDilated2DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, columns, ones )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated2d_backward, { grad_output, self, weight, columns, ones } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 9, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_conv_dilated2d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, dilation, columns_, ones_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor & VariableType::thnn_conv_dilated3d_out(Tensor & output, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated3d_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated3d_out, { output, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "padding", padding);
      setposattr(trace_info.n, 7, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  Type::thnn_conv_dilated3d_out(output, self, weight, kernel_size, bias, stride, padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output} );
  }
  return output;
}
Tensor VariableType::thnn_conv_dilated3d(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated3d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated3d, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto output = Type::thnn_conv_dilated3d(self, weight, kernel_size, bias, stride, padding, dilation);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_dilated3d_forward_out(Tensor & output, Tensor & columns, Tensor & ones, const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated3d_forward_out");
  auto& output_ = unpack(output, "output", 0);
  auto& columns_ = unpack(columns, "columns", 1);
  auto& ones_ = unpack(ones, "ones", 2);
  auto& self_ = unpack(self, "self", 3);
  auto& weight_ = unpack(weight, "weight", 4);
  auto bias_ = unpack_opt(bias, "bias", 6);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    throw_error_out_requires_grad("thnn_conv_dilated3d_forward");
  }
  if (compute_requires_grad( output )) {
    throw_error_out_requires_grad("thnn_conv_dilated3d_forward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( output, columns, ones, self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated3d_forward_out, { output, columns, ones, self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_dilated3d_forward_out(output_, columns_, ones_, self_, weight_, kernel_size, bias_, stride, padding, dilation);
  increment_version(output);
  rebase_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {output, columns, ones} );
  }
  return std::forward_as_tuple(output, columns, ones);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_dilated3d_forward(const Tensor & self, const Tensor & weight, IntList kernel_size, const Tensor & bias, IntList stride, IntList padding, IntList dilation) const {
  profiler::RecordFunction profiler("thnn_conv_dilated3d_forward");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 3);
  std::shared_ptr<ThnnConvDilated3DBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ThnnConvDilated3DBackward>(new ThnnConvDilated3DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->kernel_size = kernel_size;
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
  }
  Tensor output;
  Tensor columns;
  Tensor ones;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated3d_forward, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  std::tie(output, columns, ones) = as_variable(baseType->thnn_conv_dilated3d_forward(self_, weight_, kernel_size, bias_, stride, padding, dilation));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output, columns, ones } );
  }
  if (grad_fn) {
    grad_fn->columns_ = SavedVariable(columns, true);
    grad_fn->ones_ = SavedVariable(ones, true);
  }
  return std::make_tuple(std::move(output), std::move(columns), std::move(ones));
}
std::tuple<Tensor &,Tensor &,Tensor &> VariableType::thnn_conv_dilated3d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList dilation, const Tensor & columns, const Tensor & ones) const {
  profiler::RecordFunction profiler("thnn_conv_dilated3d_backward_out");
  auto grad_input_ = unpack_opt(grad_input, "grad_input", 0);
  auto grad_weight_ = unpack_opt(grad_weight, "grad_weight", 1);
  auto grad_bias_ = unpack_opt(grad_bias, "grad_bias", 2);
  auto& grad_output_ = unpack(grad_output, "grad_output", 3);
  auto& self_ = unpack(self, "self", 4);
  auto& weight_ = unpack(weight, "weight", 5);
  auto& columns_ = unpack(columns, "columns", 10);
  auto& ones_ = unpack(ones, "ones", 11);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( grad_output, self, weight, columns, ones )) {
    throw_error_out_requires_grad("thnn_conv_dilated3d_backward");
  }
  if (compute_requires_grad( grad_input, grad_weight, grad_bias )) {
    throw_error_out_requires_grad("thnn_conv_dilated3d_backward");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_input, grad_weight, grad_bias, grad_output, self, weight, columns, ones )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated3d_backward_out, { grad_input, grad_weight, grad_bias, grad_output, self, weight, columns, ones } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "kernel_size", kernel_size);
      setposattr(trace_info.n, 7, "stride", stride);
      setposattr(trace_info.n, 8, "padding", padding);
      setposattr(trace_info.n, 9, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  baseType->thnn_conv_dilated3d_backward_out(grad_input_, grad_weight_, grad_bias_, grad_output_, self_, weight_, kernel_size, stride, padding, dilation, columns_, ones_);
  increment_version(grad_input);
  increment_version(grad_weight);
  increment_version(grad_bias);
  rebase_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {grad_input, grad_weight, grad_bias} );
  }
  return std::forward_as_tuple(grad_input, grad_weight, grad_bias);
}
std::tuple<Tensor,Tensor,Tensor> VariableType::thnn_conv_dilated3d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntList kernel_size, IntList stride, IntList padding, IntList dilation, const Tensor & columns, const Tensor & ones, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("thnn_conv_dilated3d_backward");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto& columns_ = unpack(columns, "columns", 7);
  auto& ones_ = unpack(ones, "ones", 8);
  check_no_requires_grad(columns, "columns");
  check_no_requires_grad(ones, "ones");
  std::shared_ptr<ThnnConvDilated3DBackwardBackward> grad_fn;
  if (compute_requires_grad( grad_output, self, weight )) {
    grad_fn = std::shared_ptr<ThnnConvDilated3DBackwardBackward>(new ThnnConvDilated3DBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self, weight ));
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->stride = stride;
    grad_fn->padding = padding;
    grad_fn->dilation = dilation;
  }
  Tensor grad_input;
  Tensor grad_weight;
  Tensor grad_bias;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self, weight, columns, ones )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::thnn_conv_dilated3d_backward, { grad_output, self, weight, columns, ones } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "kernel_size", kernel_size);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "padding", padding);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 9, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(grad_input, grad_weight, grad_bias) = as_variable(baseType->thnn_conv_dilated3d_backward(grad_output_, self_, weight_, kernel_size, stride, padding, dilation, columns_, ones_, output_mask));
  set_history(flatten( grad_input, grad_weight, grad_bias ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_input, grad_weight, grad_bias } );
  }
  return std::make_tuple(std::move(grad_input), std::move(grad_weight), std::move(grad_bias));
}
Tensor VariableType::_cast_uint8_t(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_uint8_t");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_uint8_t, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_uint8_t(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_int8_t(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_int8_t");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_int8_t, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_int8_t(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_double(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_double");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_double, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_double(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_float(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_float");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_float, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_float(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_int(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_int");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_int, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_int(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_int64_t(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_int64_t");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_int64_t, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_int64_t(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_int16_t(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_int16_t");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_int16_t, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_int16_t(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cast_Half(const Tensor & self, bool non_blocking) const {
  profiler::RecordFunction profiler("_cast_Half");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cast_Half, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "non_blocking", non_blocking);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::non_blocking, non_blocking);
    }
  }
  auto result = Type::_cast_Half(self, non_blocking);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_cudnn_rnn_flatten_weight(TensorList weight_arr, int64_t weight_stride0, int64_t input_size, int64_t mode, int64_t hidden_size, int64_t num_layers, bool batch_first, bool bidirectional) const {
  profiler::RecordFunction profiler("_cudnn_rnn_flatten_weight");
  auto weight_arr_ = unpack(weight_arr, "weight_arr", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( weight_arr )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _cudnn_rnn_flatten_weight is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( weight_arr ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( weight_arr )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cudnn_rnn_flatten_weight, flatten( weight_arr ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight_stride0, weight_stride0);
      setattr(trace_info.n, jit::attr::input_size, input_size);
      setattr(trace_info.n, jit::attr::mode, mode);
      setattr(trace_info.n, jit::attr::hidden_size, hidden_size);
      setattr(trace_info.n, jit::attr::num_layers, num_layers);
      setattr(trace_info.n, jit::attr::batch_first, batch_first);
      setattr(trace_info.n, jit::attr::bidirectional, bidirectional);
    }
  }
  auto result = as_variable(baseType->_cudnn_rnn_flatten_weight(weight_arr_, weight_stride0, input_size, mode, hidden_size, num_layers, batch_first, bidirectional));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor,Tensor,Tensor,Tensor> VariableType::_cudnn_rnn(const Tensor & input, TensorList weight, int64_t weight_stride0, const Tensor & weight_buf, const Tensor & hx, const Tensor & cx, int64_t mode, int64_t hidden_size, int64_t num_layers, bool batch_first, double dropout, bool train, bool bidirectional, IntList batch_sizes, const Tensor & dropout_state) const {
  profiler::RecordFunction profiler("_cudnn_rnn");
  auto& input_ = unpack(input, "input", 0);
  auto weight_ = unpack(weight, "weight", 1);
  auto weight_buf_ = unpack_opt(weight_buf, "weight_buf", 3);
  auto& hx_ = unpack(hx, "hx", 4);
  auto cx_ = unpack_opt(cx, "cx", 5);
  auto dropout_state_ = unpack_opt(dropout_state, "dropout_state", 14);
  check_no_requires_grad(weight_buf, "weight_buf");
  std::shared_ptr<CudnnRnnBackward> grad_fn;
  if (compute_requires_grad( input, weight, hx, cx )) {
    grad_fn = std::shared_ptr<CudnnRnnBackward>(new CudnnRnnBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( input, weight, hx, cx ));
    grad_fn->input_ = SavedVariable(input, false);
    grad_fn->weight_ = make_saved_variable_list(weight);
    grad_fn->weight_stride0 = weight_stride0;
    grad_fn->hx_ = SavedVariable(hx, false);
    grad_fn->cx_ = SavedVariable(cx, false);
    grad_fn->mode = mode;
    grad_fn->hidden_size = hidden_size;
    grad_fn->num_layers = num_layers;
    grad_fn->batch_first = batch_first;
    grad_fn->dropout = dropout;
    grad_fn->train = train;
    grad_fn->bidirectional = bidirectional;
    grad_fn->batch_sizes = batch_sizes;
    grad_fn->dropout_state_ = SavedVariable(dropout_state, false);
    grad_fn->weight_size_ = weight.size();
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  Tensor result3;
  Tensor result4;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, weight_buf, hx, cx, dropout_state )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cudnn_rnn, flatten( input, weight, weight_buf, hx, cx, dropout_state ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight_stride0, weight_stride0);
      setattr(trace_info.n, jit::attr::mode, mode);
      setattr(trace_info.n, jit::attr::hidden_size, hidden_size);
      setattr(trace_info.n, jit::attr::num_layers, num_layers);
      setattr(trace_info.n, jit::attr::batch_first, batch_first);
      setattr(trace_info.n, jit::attr::dropout, dropout);
      setattr(trace_info.n, jit::attr::train, train);
      setattr(trace_info.n, jit::attr::bidirectional, bidirectional);
      setattr(trace_info.n, jit::attr::batch_sizes, batch_sizes);
    }
  }
  std::tie(result0, result1, result2, result3, result4) = as_variable(baseType->_cudnn_rnn(input_, weight_, weight_stride0, weight_buf_, hx_, cx_, mode, hidden_size, num_layers, batch_first, dropout, train, bidirectional, batch_sizes, dropout_state_));
  set_history(flatten( result0, result1, result2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2, result3, result4 } );
  }
  if (grad_fn) {
    grad_fn->result0_ = SavedVariable(result0, true);
    grad_fn->result3_ = SavedVariable(result3, true);
    grad_fn->result4_ = SavedVariable(result4, true);
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2), std::move(result3), std::move(result4));
}
std::tuple<Tensor,Tensor,Tensor,std::vector<Tensor>> VariableType::_cudnn_rnn_backward(const Tensor & input, TensorList weight, int64_t weight_stride0, const Tensor & weight_buf, const Tensor & hx, const Tensor & cx, const Tensor & output, const Tensor & grad_output, const Tensor & grad_hy, const Tensor & grad_cy, int64_t mode, int64_t hidden_size, int64_t num_layers, bool batch_first, double dropout, bool train, bool bidirectional, IntList batch_sizes, const Tensor & dropout_state, const Tensor & reserve, std::array<bool,4> output_mask) const {
  profiler::RecordFunction profiler("_cudnn_rnn_backward");
  auto& input_ = unpack(input, "input", 0);
  auto weight_ = unpack(weight, "weight", 1);
  auto& weight_buf_ = unpack(weight_buf, "weight_buf", 3);
  auto& hx_ = unpack(hx, "hx", 4);
  auto cx_ = unpack_opt(cx, "cx", 5);
  auto& output_ = unpack(output, "output", 6);
  auto grad_output_ = unpack_opt(grad_output, "grad_output", 7);
  auto grad_hy_ = unpack_opt(grad_hy, "grad_hy", 8);
  auto grad_cy_ = unpack_opt(grad_cy, "grad_cy", 9);
  auto dropout_state_ = unpack_opt(dropout_state, "dropout_state", 18);
  auto& reserve_ = unpack(reserve, "reserve", 19);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( input, weight, weight_buf, hx, cx, output, grad_output, grad_hy, grad_cy, reserve )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for _cudnn_rnn_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( input, weight, weight_buf, hx, cx, output, grad_output, grad_hy, grad_cy, reserve ));
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  std::vector<Tensor> result3;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, weight_buf, hx, cx, output, grad_output, grad_hy, grad_cy, dropout_state, reserve )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_cudnn_rnn_backward, flatten( input, weight, weight_buf, hx, cx, output, grad_output, grad_hy, grad_cy, dropout_state, reserve ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight_stride0, weight_stride0);
      setattr(trace_info.n, jit::attr::mode, mode);
      setattr(trace_info.n, jit::attr::hidden_size, hidden_size);
      setattr(trace_info.n, jit::attr::num_layers, num_layers);
      setattr(trace_info.n, jit::attr::batch_first, batch_first);
      setattr(trace_info.n, jit::attr::dropout, dropout);
      setattr(trace_info.n, jit::attr::train, train);
      setattr(trace_info.n, jit::attr::bidirectional, bidirectional);
      setattr(trace_info.n, jit::attr::batch_sizes, batch_sizes);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(result0, result1, result2, result3) = as_variable(baseType->_cudnn_rnn_backward(input_, weight_, weight_stride0, weight_buf_, hx_, cx_, output_, grad_output_, grad_hy_, grad_cy_, mode, hidden_size, num_layers, batch_first, dropout, train, bidirectional, batch_sizes, dropout_state_, reserve_, output_mask));
  set_history(flatten( result0, result1, result2, result3 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  flatten( result0, result1, result2, result3 ) );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2), std::move(result3));
}
Tensor VariableType::_cudnn_init_dropout_state(double dropout, bool train, int64_t dropout_seed) const {
  profiler::RecordFunction profiler("_cudnn_init_dropout_state");
  auto result = as_variable(baseType->_cudnn_init_dropout_state(dropout, train, dropout_seed));
  return result;
}
Tensor VariableType::abs(const Tensor & self) const {
  profiler::RecordFunction profiler("abs");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AbsBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AbsBackward>(new AbsBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::abs, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->abs(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::abs_(Tensor & self) const {
  profiler::RecordFunction profiler("abs_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<AbsBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AbsBackward>(new AbsBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::abs, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->abs_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::abs_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("abs_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("abs");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("abs");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::abs_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->abs_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::acos(const Tensor & self) const {
  profiler::RecordFunction profiler("acos");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AcosBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AcosBackward>(new AcosBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::acos, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->acos(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::acos_(Tensor & self) const {
  profiler::RecordFunction profiler("acos_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<AcosBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AcosBackward>(new AcosBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::acos, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->acos_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::acos_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("acos_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("acos");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("acos");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::acos_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->acos_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::adaptive_avg_pool1d(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_avg_pool1d");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_avg_pool1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  auto result = Type::adaptive_avg_pool1d(self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::adaptive_max_pool1d(const Tensor & self, IntList output_size) const {
  profiler::RecordFunction profiler("adaptive_max_pool1d");
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::adaptive_max_pool1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "output_size", output_size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::output_size, output_size);
    }
  }
  std::tie(result0, result1) = Type::adaptive_max_pool1d(self, output_size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
bool VariableType::allclose(const Tensor & self, const Tensor & other, double rtol, double atol, bool equal_nan) const {
  profiler::RecordFunction profiler("allclose");
  auto result = Type::allclose(self, other, rtol, atol, equal_nan);
  return result;
}
Tensor VariableType::addmv(const Tensor & self, const Tensor & mat, const Tensor & vec, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmv");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmv, { self, mat, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = Type::addmv(self, mat, vec, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::addmv_(Tensor & self, const Tensor & mat, const Tensor & vec, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmv_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmv, { self, mat, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  Type::addmv_(self, mat, vec, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::addmv_out(Tensor & result, const Tensor & self, const Tensor & mat, const Tensor & vec, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addmv_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addmv_out, { result, self, mat, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  Type::addmv_out(result, self, mat, vec, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::addr(const Tensor & self, const Tensor & vec1, const Tensor & vec2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addr");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec1, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addr, { self, vec1, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = Type::addr(self, vec1, vec2, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::addr_(Tensor & self, const Tensor & vec1, const Tensor & vec2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addr_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec1, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addr, { self, vec1, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  Type::addr_(self, vec1, vec2, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::addr_out(Tensor & result, const Tensor & self, const Tensor & vec1, const Tensor & vec2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("addr_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, vec1, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::addr_out, { result, self, vec1, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  Type::addr_out(result, self, vec1, vec2, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::arange(Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("arange");
  auto result = as_variable(baseType->arange(start, end, step));
  return result;
}
Tensor & VariableType::arange_out(Tensor & result, Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("arange_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::arange_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "step", step);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::step, step);
    }
  }
  Type::arange_out(result, start, end, step);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::arange(Scalar end) const {
  profiler::RecordFunction profiler("arange");
  auto result = as_variable(baseType->arange(end));
  return result;
}
Tensor & VariableType::arange_out(Tensor & result, Scalar end) const {
  profiler::RecordFunction profiler("arange_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::arange_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "end", end);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::end, end);
    }
  }
  Type::arange_out(result, end);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::argmax(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("argmax");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::argmax, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::argmax(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::argmax(const Tensor & self) const {
  profiler::RecordFunction profiler("argmax");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::argmax, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::argmax(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_argmax(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_argmax");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_argmax, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::_argmax(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::argmin(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("argmin");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::argmin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::argmin(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::argmin(const Tensor & self) const {
  profiler::RecordFunction profiler("argmin");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::argmin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::argmin(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_argmin(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_argmin");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_argmin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::_argmin(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::asin(const Tensor & self) const {
  profiler::RecordFunction profiler("asin");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AsinBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AsinBackward>(new AsinBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::asin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->asin(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::asin_(Tensor & self) const {
  profiler::RecordFunction profiler("asin_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<AsinBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AsinBackward>(new AsinBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::asin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->asin_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::asin_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("asin_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("asin");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("asin");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::asin_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->asin_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::atan(const Tensor & self) const {
  profiler::RecordFunction profiler("atan");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<AtanBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AtanBackward>(new AtanBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::atan, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->atan(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::atan_(Tensor & self) const {
  profiler::RecordFunction profiler("atan_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<AtanBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<AtanBackward>(new AtanBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::atan, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->atan_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::atan_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("atan_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("atan");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("atan");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::atan_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->atan_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::batch_norm(const Tensor & input, const Tensor & weight, const Tensor & bias, const Tensor & running_mean, const Tensor & running_var, bool training, double momentum, double eps, bool cudnn_enabled) const {
  profiler::RecordFunction profiler("batch_norm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, bias, running_mean, running_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::batch_norm, { input, weight, bias, running_mean, running_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "training", training);
      setposattr(trace_info.n, 6, "momentum", momentum);
      setposattr(trace_info.n, 7, "eps", eps);
      setposattr(trace_info.n, 8, "cudnn_enabled", cudnn_enabled);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::momentum, momentum);
      setattr(trace_info.n, jit::attr::eps, eps);
      setattr(trace_info.n, jit::attr::cudnn_enabled, cudnn_enabled);
    }
  }
  auto result = Type::batch_norm(input, weight, bias, running_mean, running_var, training, momentum, eps, cudnn_enabled);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::bernoulli(const Tensor & self, const Tensor & p, Generator * generator) const {
  profiler::RecordFunction profiler("bernoulli");
  auto result = Type::bernoulli(self, p, generator);
  return result;
}
Tensor VariableType::bernoulli(const Tensor & self, double p, Generator * generator) const {
  profiler::RecordFunction profiler("bernoulli");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<BernoulliBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<BernoulliBackward>(new BernoulliBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  auto result = as_variable(baseType->bernoulli(self_, p, generator));
  set_history(flatten( result ), grad_fn);
  return result;
}
Tensor VariableType::bernoulli(const Tensor & self) const {
  profiler::RecordFunction profiler("bernoulli");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::bernoulli, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::bernoulli(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::bernoulli_(Tensor & self, const Tensor & p, Generator * generator) const {
  profiler::RecordFunction profiler("bernoulli_");
  Type::bernoulli_(self, p, generator);
  return self;
}
Tensor & VariableType::bernoulli_(Tensor & self, double p, Generator * generator) const {
  profiler::RecordFunction profiler("bernoulli_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<BernoulliBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<BernoulliBackward>(new BernoulliBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  baseType->bernoulli_(self_, p, generator);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  return self;
}
Tensor & VariableType::bernoulli_(Tensor & self) const {
  profiler::RecordFunction profiler("bernoulli_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::bernoulli, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::bernoulli_(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::bilinear(const Tensor & input1, const Tensor & input2, const Tensor & weight, const Tensor & bias) const {
  profiler::RecordFunction profiler("bilinear");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input1, input2, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::bilinear, { input1, input2, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::bilinear(input1, input2, weight, bias);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cat(TensorList tensors, int64_t dim) const {
  profiler::RecordFunction profiler("cat");
  auto tensors_ = unpack(tensors, "tensors", 0);
  std::shared_ptr<CatBackward> grad_fn;
  if (compute_requires_grad( tensors )) {
    grad_fn = std::shared_ptr<CatBackward>(new CatBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( tensors ));
    grad_fn->tensors_args_sizes = to_args_sizes(tensors);
    grad_fn->dim = dim;
    grad_fn->tensors_size_ = tensors.size();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cat, flatten( tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->cat(tensors_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::cat_out(Tensor & result, TensorList tensors, int64_t dim) const {
  profiler::RecordFunction profiler("cat_out");
  auto& result_ = unpack(result, "result", 0);
  auto tensors_ = unpack(tensors, "tensors", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( tensors )) {
    throw_error_out_requires_grad("cat");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("cat");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cat_out, flatten( result, tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->cat_out(result_, tensors_, dim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::ceil(const Tensor & self) const {
  profiler::RecordFunction profiler("ceil");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<CeilBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CeilBackward>(new CeilBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ceil, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->ceil(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::ceil_(Tensor & self) const {
  profiler::RecordFunction profiler("ceil_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<CeilBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CeilBackward>(new CeilBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ceil, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->ceil_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::ceil_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("ceil_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("ceil");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("ceil");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ceil_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->ceil_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
std::vector<Tensor> VariableType::chunk(const Tensor & self, int64_t chunks, int64_t dim) const {
  profiler::RecordFunction profiler("chunk");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::chunk, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "chunks", chunks);
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::chunks, chunks);
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = Type::chunk(self, chunks, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  flatten(result) );
  }
  return result;
}
bool VariableType::cudnn_is_acceptable(const Tensor & self) const {
  profiler::RecordFunction profiler("cudnn_is_acceptable");
  auto result = Type::cudnn_is_acceptable(self);
  return result;
}
Tensor VariableType::convolution(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding, int64_t groups) const {
  profiler::RecordFunction profiler("convolution");
  auto result = Type::convolution(input, weight, bias, stride, padding, dilation, transposed, output_padding, groups);
  return result;
}
Tensor VariableType::_convolution(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding, int64_t groups, bool benchmark, bool deterministic, bool cudnn_enabled) const {
  profiler::RecordFunction profiler("_convolution");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_convolution, { input, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "transposed", transposed);
      setposattr(trace_info.n, 7, "output_padding", output_padding);
      setposattr(trace_info.n, 8, "groups", groups);
      setposattr(trace_info.n, 9, "benchmark", benchmark);
      setposattr(trace_info.n, 10, "deterministic", deterministic);
      setposattr(trace_info.n, 11, "cudnn_enabled", cudnn_enabled);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::transposed, transposed);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
      setattr(trace_info.n, jit::attr::cudnn_enabled, cudnn_enabled);
    }
  }
  auto result = Type::_convolution(input, weight, bias, stride, padding, dilation, transposed, output_padding, groups, benchmark, deterministic, cudnn_enabled);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_convolution_nogroup(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding) const {
  profiler::RecordFunction profiler("_convolution_nogroup");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_convolution_nogroup, { input, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "padding", padding);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "transposed", transposed);
      setposattr(trace_info.n, 7, "output_padding", output_padding);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::transposed, transposed);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
    }
  }
  auto result = Type::_convolution_nogroup(input, weight, bias, stride, padding, dilation, transposed, output_padding);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor,Tensor> VariableType::_convolution_double_backward(const Tensor & ggI, const Tensor & ggW, const Tensor & ggb, const Tensor & gO, const Tensor & weight, const Tensor & self, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding, int64_t groups, bool benchmark, bool deterministic, bool cudnn_enabled, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("_convolution_double_backward");
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( ggI, ggW, ggb, gO, weight, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_convolution_double_backward, { ggI, ggW, ggb, gO, weight, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "stride", stride);
      setposattr(trace_info.n, 7, "padding", padding);
      setposattr(trace_info.n, 8, "dilation", dilation);
      setposattr(trace_info.n, 9, "transposed", transposed);
      setposattr(trace_info.n, 10, "output_padding", output_padding);
      setposattr(trace_info.n, 11, "groups", groups);
      setposattr(trace_info.n, 12, "benchmark", benchmark);
      setposattr(trace_info.n, 13, "deterministic", deterministic);
      setposattr(trace_info.n, 14, "cudnn_enabled", cudnn_enabled);
      setposattr(trace_info.n, 15, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::transposed, transposed);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
      setattr(trace_info.n, jit::attr::cudnn_enabled, cudnn_enabled);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(result0, result1, result2) = Type::_convolution_double_backward(ggI, ggW, ggb, gO, weight, self, stride, padding, dilation, transposed, output_padding, groups, benchmark, deterministic, cudnn_enabled, output_mask);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
Tensor VariableType::conv1d(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList dilation, int64_t groups) const {
  profiler::RecordFunction profiler("conv1d");
  auto result = Type::conv1d(input, weight, bias, stride, padding, dilation, groups);
  return result;
}
Tensor VariableType::conv2d(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList dilation, int64_t groups) const {
  profiler::RecordFunction profiler("conv2d");
  auto result = Type::conv2d(input, weight, bias, stride, padding, dilation, groups);
  return result;
}
Tensor VariableType::conv3d(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList dilation, int64_t groups) const {
  profiler::RecordFunction profiler("conv3d");
  auto result = Type::conv3d(input, weight, bias, stride, padding, dilation, groups);
  return result;
}
Tensor VariableType::conv_tbc(const Tensor & self, const Tensor & weight, const Tensor & bias, int64_t pad) const {
  profiler::RecordFunction profiler("conv_tbc");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto& bias_ = unpack(bias, "bias", 2);
  std::shared_ptr<ConvTbcBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<ConvTbcBackward>(new ConvTbcBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->bias_ = SavedVariable(bias, false);
    grad_fn->pad = pad;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::conv_tbc, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "pad", pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pad, pad);
    }
  }
  auto result = as_variable(baseType->conv_tbc(self_, weight_, bias_, pad));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor,Tensor> VariableType::conv_tbc_backward(const Tensor & self, const Tensor & input, const Tensor & weight, const Tensor & bias, int64_t pad) const {
  profiler::RecordFunction profiler("conv_tbc_backward");
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, input, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::conv_tbc_backward, { self, input, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "pad", pad);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pad, pad);
    }
  }
  std::tie(result0, result1, result2) = Type::conv_tbc_backward(self, input, weight, bias, pad);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
Tensor VariableType::conv_transpose1d(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, int64_t groups, IntList dilation) const {
  profiler::RecordFunction profiler("conv_transpose1d");
  auto result = Type::conv_transpose1d(input, weight, bias, stride, padding, output_padding, groups, dilation);
  return result;
}
Tensor VariableType::conv_transpose2d(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, int64_t groups, IntList dilation) const {
  profiler::RecordFunction profiler("conv_transpose2d");
  auto result = Type::conv_transpose2d(input, weight, bias, stride, padding, output_padding, groups, dilation);
  return result;
}
Tensor VariableType::conv_transpose3d(const Tensor & input, const Tensor & weight, const Tensor & bias, IntList stride, IntList padding, IntList output_padding, int64_t groups, IntList dilation) const {
  profiler::RecordFunction profiler("conv_transpose3d");
  auto result = Type::conv_transpose3d(input, weight, bias, stride, padding, output_padding, groups, dilation);
  return result;
}
Tensor VariableType::cos(const Tensor & self) const {
  profiler::RecordFunction profiler("cos");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<CosBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CosBackward>(new CosBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cos, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->cos(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::cos_(Tensor & self) const {
  profiler::RecordFunction profiler("cos_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<CosBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CosBackward>(new CosBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cos, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->cos_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::cos_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("cos_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("cos");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("cos");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cos_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->cos_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::cosh(const Tensor & self) const {
  profiler::RecordFunction profiler("cosh");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<CoshBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CoshBackward>(new CoshBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cosh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->cosh(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::cosh_(Tensor & self) const {
  profiler::RecordFunction profiler("cosh_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<CoshBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<CoshBackward>(new CoshBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cosh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->cosh_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::cosh_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("cosh_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("cosh");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("cosh");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cosh_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->cosh_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::cosine_embedding_loss(const Tensor & input1, const Tensor & input2, const Tensor & target, double margin, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("cosine_embedding_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input1, input2, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cosine_embedding_loss, { input1, input2, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "margin", margin);
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto result = Type::cosine_embedding_loss(input1, input2, target, margin, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_affine_grid_generator(const Tensor & theta, int64_t N, int64_t C, int64_t H, int64_t W) const {
  profiler::RecordFunction profiler("cudnn_affine_grid_generator");
  auto& theta_ = unpack(theta, "theta", 0);
  std::shared_ptr<CudnnAffineGridGeneratorBackward> grad_fn;
  if (compute_requires_grad( theta )) {
    grad_fn = std::shared_ptr<CudnnAffineGridGeneratorBackward>(new CudnnAffineGridGeneratorBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( theta ));
    grad_fn->N = N;
    grad_fn->C = C;
    grad_fn->H = H;
    grad_fn->W = W;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( theta )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_affine_grid_generator, { theta } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "N", N);
      setposattr(trace_info.n, 2, "C", C);
      setposattr(trace_info.n, 3, "H", H);
      setposattr(trace_info.n, 4, "W", W);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::N, N);
      setattr(trace_info.n, jit::attr::C, C);
      setattr(trace_info.n, jit::attr::H, H);
      setattr(trace_info.n, jit::attr::W, W);
    }
  }
  auto grid = as_variable(baseType->cudnn_affine_grid_generator(theta_, N, C, H, W));
  set_history(flatten( grid ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grid } );
  }
  return grid;
}
Tensor VariableType::cudnn_affine_grid_generator_backward(const Tensor & grad, int64_t N, int64_t C, int64_t H, int64_t W) const {
  profiler::RecordFunction profiler("cudnn_affine_grid_generator_backward");
  auto& grad_ = unpack(grad, "grad", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_affine_grid_generator_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_affine_grid_generator_backward, { grad } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "N", N);
      setposattr(trace_info.n, 2, "C", C);
      setposattr(trace_info.n, 3, "H", H);
      setposattr(trace_info.n, 4, "W", W);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::N, N);
      setattr(trace_info.n, jit::attr::C, C);
      setattr(trace_info.n, jit::attr::H, H);
      setattr(trace_info.n, jit::attr::W, W);
    }
  }
  auto grad_theta = as_variable(baseType->cudnn_affine_grid_generator_backward(grad_, N, C, H, W));
  set_history(flatten( grad_theta ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_theta } );
  }
  return grad_theta;
}
std::tuple<Tensor,Tensor,Tensor> VariableType::cudnn_batch_norm(const Tensor & input, const Tensor & weight, const Tensor & bias, const Tensor & running_mean, const Tensor & running_var, bool training, double exponential_average_factor, double epsilon) const {
  profiler::RecordFunction profiler("cudnn_batch_norm");
  auto& input_ = unpack(input, "input", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 2);
  auto running_mean_ = unpack_opt(running_mean, "running_mean", 3);
  auto running_var_ = unpack_opt(running_var, "running_var", 4);
  check_no_requires_grad(running_mean, "running_mean");
  check_no_requires_grad(running_var, "running_var");
  std::shared_ptr<CudnnBatchNormBackward> grad_fn;
  if (compute_requires_grad( input, weight, bias )) {
    grad_fn = std::shared_ptr<CudnnBatchNormBackward>(new CudnnBatchNormBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( input, weight, bias ));
    grad_fn->input_ = SavedVariable(input, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->running_mean_ = SavedVariable(running_mean, false);
    grad_fn->running_var_ = SavedVariable(running_var, false);
    grad_fn->training = training;
    grad_fn->epsilon = epsilon;
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, bias, running_mean, running_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_batch_norm, { input, weight, bias, running_mean, running_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "training", training);
      setposattr(trace_info.n, 6, "exponential_average_factor", exponential_average_factor);
      setposattr(trace_info.n, 7, "epsilon", epsilon);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::training, training);
      setattr(trace_info.n, jit::attr::exponential_average_factor, exponential_average_factor);
      setattr(trace_info.n, jit::attr::epsilon, epsilon);
    }
  }
  std::tie(result0, result1, result2) = as_variable(baseType->cudnn_batch_norm(input_, weight_, bias_, running_mean_, running_var_, training, exponential_average_factor, epsilon));
  set_history(flatten( result0 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  if (grad_fn) {
    grad_fn->result1_ = SavedVariable(result1, true);
    grad_fn->result2_ = SavedVariable(result2, true);
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
std::tuple<Tensor,Tensor,Tensor> VariableType::cudnn_batch_norm_backward(const Tensor & input, const Tensor & grad_output, const Tensor & weight, const Tensor & running_mean, const Tensor & running_var, const Tensor & save_mean, const Tensor & save_var, double epsilon) const {
  profiler::RecordFunction profiler("cudnn_batch_norm_backward");
  auto& input_ = unpack(input, "input", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  auto running_mean_ = unpack_opt(running_mean, "running_mean", 3);
  auto running_var_ = unpack_opt(running_var, "running_var", 4);
  auto save_mean_ = unpack_opt(save_mean, "save_mean", 5);
  auto save_var_ = unpack_opt(save_var, "save_var", 6);
  check_no_requires_grad(running_mean, "running_mean");
  check_no_requires_grad(running_var, "running_var");
  std::shared_ptr<CudnnBatchNormBackwardBackward> grad_fn;
  if (compute_requires_grad( input, grad_output, weight, save_mean, save_var )) {
    grad_fn = std::shared_ptr<CudnnBatchNormBackwardBackward>(new CudnnBatchNormBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( input, grad_output, weight, save_mean, save_var ));
    grad_fn->input_ = SavedVariable(input, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->running_mean_ = SavedVariable(running_mean, false);
    grad_fn->running_var_ = SavedVariable(running_var, false);
    grad_fn->save_mean_ = SavedVariable(save_mean, false);
    grad_fn->save_var_ = SavedVariable(save_var, false);
    grad_fn->epsilon = epsilon;
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, grad_output, weight, running_mean, running_var, save_mean, save_var )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_batch_norm_backward, { input, grad_output, weight, running_mean, running_var, save_mean, save_var } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 7, "epsilon", epsilon);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::epsilon, epsilon);
    }
  }
  std::tie(result0, result1, result2) = as_variable(baseType->cudnn_batch_norm_backward(input_, grad_output_, weight_, running_mean_, running_var_, save_mean_, save_var_, epsilon));
  set_history(flatten( result0, result1, result2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
Tensor VariableType::cudnn_convolution(const Tensor & self, const Tensor & weight, const Tensor & bias, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) const {
  profiler::RecordFunction profiler("cudnn_convolution");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 2);
  std::shared_ptr<CudnnConvolutionBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<CudnnConvolutionBackward>(new CudnnConvolutionBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->padding = padding;
    grad_fn->stride = stride;
    grad_fn->dilation = dilation;
    grad_fn->groups = groups;
    grad_fn->benchmark = benchmark;
    grad_fn->deterministic = deterministic;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "groups", groups);
      setposattr(trace_info.n, 7, "benchmark", benchmark);
      setposattr(trace_info.n, 8, "deterministic", deterministic);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
    }
  }
  auto result = as_variable(baseType->cudnn_convolution(self_, weight_, bias_, padding, stride, dilation, groups, benchmark, deterministic));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_convolution_backward_input(IntList self_size, const Tensor & grad_output, const Tensor & weight, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) const {
  profiler::RecordFunction profiler("cudnn_convolution_backward_input");
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, weight )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_convolution_backward_input is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, weight ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_backward_input, { grad_output, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "self_size", self_size);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "groups", groups);
      setposattr(trace_info.n, 7, "benchmark", benchmark);
      setposattr(trace_info.n, 8, "deterministic", deterministic);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::self_size, self_size);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_backward_input(self_size, grad_output_, weight_, padding, stride, dilation, groups, benchmark, deterministic));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor,Tensor> VariableType::cudnn_convolution_backward(const Tensor & self, const Tensor & grad_output, const Tensor & weight, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("cudnn_convolution_backward");
  auto& self_ = unpack(self, "self", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  std::shared_ptr<CudnnConvolutionBackwardBackward> grad_fn;
  if (compute_requires_grad( self, grad_output, weight )) {
    grad_fn = std::shared_ptr<CudnnConvolutionBackwardBackward>(new CudnnConvolutionBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, grad_output, weight ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->padding = padding;
    grad_fn->stride = stride;
    grad_fn->dilation = dilation;
    grad_fn->groups = groups;
    grad_fn->benchmark = benchmark;
    grad_fn->deterministic = deterministic;
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, grad_output, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_backward, { self, grad_output, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "groups", groups);
      setposattr(trace_info.n, 7, "benchmark", benchmark);
      setposattr(trace_info.n, 8, "deterministic", deterministic);
      setposattr(trace_info.n, 9, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(result0, result1, result2) = as_variable(baseType->cudnn_convolution_backward(self_, grad_output_, weight_, padding, stride, dilation, groups, benchmark, deterministic, output_mask));
  set_history(flatten( result0, result1, result2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
Tensor VariableType::cudnn_convolution_backward_bias(const Tensor & grad_output) const {
  profiler::RecordFunction profiler("cudnn_convolution_backward_bias");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_convolution_backward_bias is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_backward_bias, { grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_backward_bias(grad_output_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_convolution_backward_weight(IntList weight_size, const Tensor & grad_output, const Tensor & self, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) const {
  profiler::RecordFunction profiler("cudnn_convolution_backward_weight");
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_convolution_backward_weight is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_backward_weight, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "weight_size", weight_size);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "groups", groups);
      setposattr(trace_info.n, 7, "benchmark", benchmark);
      setposattr(trace_info.n, 8, "deterministic", deterministic);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight_size, weight_size);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_backward_weight(weight_size, grad_output_, self_, padding, stride, dilation, groups, benchmark, deterministic));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_convolution_transpose(const Tensor & self, const Tensor & weight, const Tensor & bias, IntList padding, IntList output_padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) const {
  profiler::RecordFunction profiler("cudnn_convolution_transpose");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 2);
  std::shared_ptr<CudnnConvolutionTransposeBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<CudnnConvolutionTransposeBackward>(new CudnnConvolutionTransposeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->padding = padding;
    grad_fn->output_padding = output_padding;
    grad_fn->stride = stride;
    grad_fn->dilation = dilation;
    grad_fn->groups = groups;
    grad_fn->benchmark = benchmark;
    grad_fn->deterministic = deterministic;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_transpose, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "output_padding", output_padding);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "groups", groups);
      setposattr(trace_info.n, 8, "benchmark", benchmark);
      setposattr(trace_info.n, 9, "deterministic", deterministic);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_transpose(self_, weight_, bias_, padding, output_padding, stride, dilation, groups, benchmark, deterministic));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor,Tensor> VariableType::cudnn_convolution_transpose_backward(const Tensor & self, const Tensor & grad_output, const Tensor & weight, IntList padding, IntList output_padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("cudnn_convolution_transpose_backward");
  auto& self_ = unpack(self, "self", 0);
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& weight_ = unpack(weight, "weight", 2);
  std::shared_ptr<CudnnConvolutionTransposeBackwardBackward> grad_fn;
  if (compute_requires_grad( self, grad_output, weight )) {
    grad_fn = std::shared_ptr<CudnnConvolutionTransposeBackwardBackward>(new CudnnConvolutionTransposeBackwardBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, grad_output, weight ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->padding = padding;
    grad_fn->output_padding = output_padding;
    grad_fn->stride = stride;
    grad_fn->dilation = dilation;
    grad_fn->groups = groups;
    grad_fn->benchmark = benchmark;
    grad_fn->deterministic = deterministic;
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, grad_output, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_transpose_backward, { self, grad_output, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "output_padding", output_padding);
      setposattr(trace_info.n, 5, "stride", stride);
      setposattr(trace_info.n, 6, "dilation", dilation);
      setposattr(trace_info.n, 7, "groups", groups);
      setposattr(trace_info.n, 8, "benchmark", benchmark);
      setposattr(trace_info.n, 9, "deterministic", deterministic);
      setposattr(trace_info.n, 10, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::output_padding, output_padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(result0, result1, result2) = as_variable(baseType->cudnn_convolution_transpose_backward(self_, grad_output_, weight_, padding, output_padding, stride, dilation, groups, benchmark, deterministic, output_mask));
  set_history(flatten( result0, result1, result2 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
Tensor VariableType::cudnn_convolution_transpose_backward_bias(const Tensor & grad_output) const {
  profiler::RecordFunction profiler("cudnn_convolution_transpose_backward_bias");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_convolution_transpose_backward_bias is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_transpose_backward_bias, { grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_transpose_backward_bias(grad_output_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_convolution_transpose_backward_input(const Tensor & grad_output, const Tensor & weight, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) const {
  profiler::RecordFunction profiler("cudnn_convolution_transpose_backward_input");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, weight )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_convolution_transpose_backward_input is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, weight ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_transpose_backward_input, { grad_output, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding", padding);
      setposattr(trace_info.n, 3, "stride", stride);
      setposattr(trace_info.n, 4, "dilation", dilation);
      setposattr(trace_info.n, 5, "groups", groups);
      setposattr(trace_info.n, 6, "benchmark", benchmark);
      setposattr(trace_info.n, 7, "deterministic", deterministic);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_transpose_backward_input(grad_output_, weight_, padding, stride, dilation, groups, benchmark, deterministic));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_convolution_transpose_backward_weight(IntList weight_size, const Tensor & grad_output, const Tensor & self, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) const {
  profiler::RecordFunction profiler("cudnn_convolution_transpose_backward_weight");
  auto& grad_output_ = unpack(grad_output, "grad_output", 1);
  auto& self_ = unpack(self, "self", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_convolution_transpose_backward_weight is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_convolution_transpose_backward_weight, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "weight_size", weight_size);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "groups", groups);
      setposattr(trace_info.n, 7, "benchmark", benchmark);
      setposattr(trace_info.n, 8, "deterministic", deterministic);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight_size, weight_size);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::groups, groups);
      setattr(trace_info.n, jit::attr::benchmark, benchmark);
      setattr(trace_info.n, jit::attr::deterministic, deterministic);
    }
  }
  auto result = as_variable(baseType->cudnn_convolution_transpose_backward_weight(weight_size, grad_output_, self_, padding, stride, dilation, groups, benchmark, deterministic));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::cudnn_grid_sampler(const Tensor & self, const Tensor & grid) const {
  profiler::RecordFunction profiler("cudnn_grid_sampler");
  auto& self_ = unpack(self, "self", 0);
  auto& grid_ = unpack(grid, "grid", 1);
  std::shared_ptr<CudnnGridSamplerBackward> grad_fn;
  if (compute_requires_grad( self, grid )) {
    grad_fn = std::shared_ptr<CudnnGridSamplerBackward>(new CudnnGridSamplerBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, grid ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->grid_ = SavedVariable(grid, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, grid )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_grid_sampler, { self, grid } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto output = as_variable(baseType->cudnn_grid_sampler(self_, grid_));
  set_history(flatten( output ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { output } );
  }
  return output;
}
std::tuple<Tensor,Tensor> VariableType::cudnn_grid_sampler_backward(const Tensor & self, const Tensor & grid, const Tensor & grad_output) const {
  profiler::RecordFunction profiler("cudnn_grid_sampler_backward");
  auto& self_ = unpack(self, "self", 0);
  auto& grid_ = unpack(grid, "grid", 1);
  auto& grad_output_ = unpack(grad_output, "grad_output", 2);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( self, grid, grad_output )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for cudnn_grid_sampler_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, grid, grad_output ));
  }
  Tensor grad_self;
  Tensor grad_grid;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, grid, grad_output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cudnn_grid_sampler_backward, { self, grid, grad_output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(grad_self, grad_grid) = as_variable(baseType->cudnn_grid_sampler_backward(self_, grid_, grad_output_));
  set_history(flatten( grad_self, grad_grid ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { grad_self, grad_grid } );
  }
  return std::make_tuple(std::move(grad_self), std::move(grad_grid));
}
Tensor VariableType::cumsum(const Tensor & self, int64_t dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("cumsum");
  auto result = Type::cumsum(self, dim, dtype);
  return result;
}
Tensor VariableType::cumsum(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("cumsum");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cumsum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = Type::cumsum(self, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::cumsum_out(Tensor & result, const Tensor & self, int64_t dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("cumsum_out");
  Type::cumsum_out(result, self, dim, dtype);
  return result;
}
Tensor & VariableType::cumsum_out(Tensor & result, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("cumsum_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cumsum_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  Type::cumsum_out(result, self, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::cumprod(const Tensor & self, int64_t dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("cumprod");
  auto result = Type::cumprod(self, dim, dtype);
  return result;
}
Tensor VariableType::cumprod(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("cumprod");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cumprod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = Type::cumprod(self, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::cumprod_out(Tensor & result, const Tensor & self, int64_t dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("cumprod_out");
  Type::cumprod_out(result, self, dim, dtype);
  return result;
}
Tensor & VariableType::cumprod_out(Tensor & result, const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("cumprod_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::cumprod_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  Type::cumprod_out(result, self, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::det(const Tensor & self) const {
  profiler::RecordFunction profiler("det");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<DetBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DetBackward>(new DetBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::det, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->det(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::diagflat(const Tensor & self, int64_t offset) const {
  profiler::RecordFunction profiler("diagflat");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::diagflat, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "offset", offset);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::offset, offset);
    }
  }
  auto result = Type::diagflat(self, offset);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::diagonal(const Tensor & self, int64_t offset, int64_t dim1, int64_t dim2) const {
  profiler::RecordFunction profiler("diagonal");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<DiagonalBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<DiagonalBackward>(new DiagonalBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->offset = offset;
    grad_fn->dim1 = dim1;
    grad_fn->dim2 = dim2;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::diagonal, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "offset", offset);
      setposattr(trace_info.n, 2, "dim1", dim1);
      setposattr(trace_info.n, 3, "dim2", dim2);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::offset, offset);
      setattr(trace_info.n, jit::attr::dim1, dim1);
      setattr(trace_info.n, jit::attr::dim2, dim2);
    }
  }
  auto result = as_view(self, baseType->diagonal(self_, offset, dim1, dim2));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::dot(const Tensor & self, const Tensor & tensor) const {
  profiler::RecordFunction profiler("dot");
  auto& self_ = unpack(self, "self", 0);
  auto& tensor_ = unpack(tensor, "tensor", 1);
  std::shared_ptr<DotBackward> grad_fn;
  if (compute_requires_grad( self, tensor )) {
    grad_fn = std::shared_ptr<DotBackward>(new DotBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, tensor ));
    grad_fn->tensor_ = SavedVariable(tensor, false);
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, tensor )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::dot, { self, tensor } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->dot(self_, tensor_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::dot_out(Tensor & result, const Tensor & self, const Tensor & tensor) const {
  profiler::RecordFunction profiler("dot_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& tensor_ = unpack(tensor, "tensor", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, tensor )) {
    throw_error_out_requires_grad("dot");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("dot");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, tensor )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::dot_out, { result, self, tensor } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->dot_out(result_, self_, tensor_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::einsum(std::string equation, TensorList tensors) const {
  profiler::RecordFunction profiler("einsum");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::einsum, flatten( tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::equation, equation);
    }
  }
  auto result = Type::einsum(equation, tensors);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::embedding(const Tensor & weight, const Tensor & indices, int64_t padding_idx, bool scale_grad_by_freq, bool sparse) const {
  profiler::RecordFunction profiler("embedding");
  auto& weight_ = unpack(weight, "weight", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  std::shared_ptr<EmbeddingBackward> grad_fn;
  if (compute_requires_grad( weight )) {
    grad_fn = std::shared_ptr<EmbeddingBackward>(new EmbeddingBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( weight ));
    grad_fn->weight_argsize_0 = weight.size(0);
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->padding_idx = padding_idx;
    grad_fn->scale_grad_by_freq = scale_grad_by_freq;
    grad_fn->sparse = sparse;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( weight, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding, { weight, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "padding_idx", padding_idx);
      setposattr(trace_info.n, 3, "scale_grad_by_freq", scale_grad_by_freq);
      setposattr(trace_info.n, 4, "sparse", sparse);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding_idx, padding_idx);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
      setattr(trace_info.n, jit::attr::sparse, sparse);
    }
  }
  auto result = as_variable(baseType->embedding(weight_, indices_, padding_idx, scale_grad_by_freq, sparse));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::embedding_backward(const Tensor & grad, const Tensor & indices, int64_t num_weights, int64_t padding_idx, bool scale_grad_by_freq, bool sparse) const {
  profiler::RecordFunction profiler("embedding_backward");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_backward, { grad, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "num_weights", num_weights);
      setposattr(trace_info.n, 3, "padding_idx", padding_idx);
      setposattr(trace_info.n, 4, "scale_grad_by_freq", scale_grad_by_freq);
      setposattr(trace_info.n, 5, "sparse", sparse);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_weights, num_weights);
      setattr(trace_info.n, jit::attr::padding_idx, padding_idx);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
      setattr(trace_info.n, jit::attr::sparse, sparse);
    }
  }
  auto result = Type::embedding_backward(grad, indices, num_weights, padding_idx, scale_grad_by_freq, sparse);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::embedding_dense_backward(const Tensor & grad, const Tensor & indices, int64_t num_weights, int64_t padding_idx, bool scale_grad_by_freq) const {
  profiler::RecordFunction profiler("embedding_dense_backward");
  auto& grad_ = unpack(grad, "grad", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for embedding_dense_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_dense_backward, { grad, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "num_weights", num_weights);
      setposattr(trace_info.n, 3, "padding_idx", padding_idx);
      setposattr(trace_info.n, 4, "scale_grad_by_freq", scale_grad_by_freq);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_weights, num_weights);
      setattr(trace_info.n, jit::attr::padding_idx, padding_idx);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
    }
  }
  auto result = as_variable(baseType->embedding_dense_backward(grad_, indices_, num_weights, padding_idx, scale_grad_by_freq));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::embedding_renorm_(Tensor & self, const Tensor & indices, double max_norm, double norm_type) const {
  profiler::RecordFunction profiler("embedding_renorm_");
  auto& self_ = unpack(self, "self", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  check_inplace(self);
  std::shared_ptr<EmbeddingRenormBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<EmbeddingRenormBackward>(new EmbeddingRenormBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_renorm, { self, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "max_norm", max_norm);
      setposattr(trace_info.n, 3, "norm_type", norm_type);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::max_norm, max_norm);
      setattr(trace_info.n, jit::attr::norm_type, norm_type);
    }
  }
  baseType->embedding_renorm_(self_, indices_, max_norm, norm_type);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::embedding_sparse_backward(const Tensor & grad, const Tensor & indices, int64_t num_weights, int64_t padding_idx, bool scale_grad_by_freq) const {
  profiler::RecordFunction profiler("embedding_sparse_backward");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_sparse_backward, { grad, indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "num_weights", num_weights);
      setposattr(trace_info.n, 3, "padding_idx", padding_idx);
      setposattr(trace_info.n, 4, "scale_grad_by_freq", scale_grad_by_freq);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_weights, num_weights);
      setattr(trace_info.n, jit::attr::padding_idx, padding_idx);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
    }
  }
  auto result = Type::embedding_sparse_backward(grad, indices, num_weights, padding_idx, scale_grad_by_freq);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor,Tensor,Tensor> VariableType::embedding_bag(const Tensor & weight, const Tensor & indices, const Tensor & offsets, bool scale_grad_by_freq, int64_t mode, bool sparse) const {
  profiler::RecordFunction profiler("embedding_bag");
  auto& weight_ = unpack(weight, "weight", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& offsets_ = unpack(offsets, "offsets", 2);
  std::shared_ptr<EmbeddingBagBackward> grad_fn;
  if (compute_requires_grad( weight )) {
    grad_fn = std::shared_ptr<EmbeddingBagBackward>(new EmbeddingBagBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( weight ));
    grad_fn->weight_argsize_0 = weight.size(0);
    grad_fn->indices_ = SavedVariable(indices, false);
    grad_fn->offsets_ = SavedVariable(offsets, false);
    grad_fn->scale_grad_by_freq = scale_grad_by_freq;
    grad_fn->mode = mode;
    grad_fn->sparse = sparse;
  }
  Tensor result0;
  Tensor result1;
  Tensor result2;
  Tensor result3;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( weight, indices, offsets )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_bag, { weight, indices, offsets } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "scale_grad_by_freq", scale_grad_by_freq);
      setposattr(trace_info.n, 4, "mode", mode);
      setposattr(trace_info.n, 5, "sparse", sparse);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
      setattr(trace_info.n, jit::attr::mode, mode);
      setattr(trace_info.n, jit::attr::sparse, sparse);
    }
  }
  std::tie(result0, result1, result2, result3) = as_variable(baseType->embedding_bag(weight_, indices_, offsets_, scale_grad_by_freq, mode, sparse));
  set_history(flatten( result0 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2, result3 } );
  }
  if (grad_fn) {
    grad_fn->result1_ = SavedVariable(result1, true);
    grad_fn->result2_ = SavedVariable(result2, true);
    grad_fn->result3_ = SavedVariable(result3, true);
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2), std::move(result3));
}
Tensor VariableType::embedding_bag_backward(const Tensor & grad, const Tensor & indices, const Tensor & offsets, const Tensor & offset2bag, const Tensor & bag_size, const Tensor & maximum_indices, int64_t num_weights, bool scale_grad_by_freq, int64_t mode, bool sparse) const {
  profiler::RecordFunction profiler("embedding_bag_backward");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad, indices, offsets, offset2bag, bag_size, maximum_indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_bag_backward, { grad, indices, offsets, offset2bag, bag_size, maximum_indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "num_weights", num_weights);
      setposattr(trace_info.n, 7, "scale_grad_by_freq", scale_grad_by_freq);
      setposattr(trace_info.n, 8, "mode", mode);
      setposattr(trace_info.n, 9, "sparse", sparse);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_weights, num_weights);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
      setattr(trace_info.n, jit::attr::mode, mode);
      setattr(trace_info.n, jit::attr::sparse, sparse);
    }
  }
  auto result = Type::embedding_bag_backward(grad, indices, offsets, offset2bag, bag_size, maximum_indices, num_weights, scale_grad_by_freq, mode, sparse);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::embedding_bag_sparse_backward(const Tensor & grad, const Tensor & indices, const Tensor & offsets, const Tensor & offset2bag, const Tensor & bag_size, int64_t num_weights, bool scale_grad_by_freq, int64_t mode) const {
  profiler::RecordFunction profiler("embedding_bag_sparse_backward");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad, indices, offsets, offset2bag, bag_size )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_bag_sparse_backward, { grad, indices, offsets, offset2bag, bag_size } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 5, "num_weights", num_weights);
      setposattr(trace_info.n, 6, "scale_grad_by_freq", scale_grad_by_freq);
      setposattr(trace_info.n, 7, "mode", mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_weights, num_weights);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
      setattr(trace_info.n, jit::attr::mode, mode);
    }
  }
  auto result = Type::embedding_bag_sparse_backward(grad, indices, offsets, offset2bag, bag_size, num_weights, scale_grad_by_freq, mode);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::embedding_bag_dense_backward(const Tensor & grad, const Tensor & indices, const Tensor & offsets, const Tensor & offset2bag, const Tensor & bag_size, const Tensor & maximum_indices, int64_t num_weights, bool scale_grad_by_freq, int64_t mode) const {
  profiler::RecordFunction profiler("embedding_bag_dense_backward");
  auto& grad_ = unpack(grad, "grad", 0);
  auto& indices_ = unpack(indices, "indices", 1);
  auto& offsets_ = unpack(offsets, "offsets", 2);
  auto& offset2bag_ = unpack(offset2bag, "offset2bag", 3);
  auto& bag_size_ = unpack(bag_size, "bag_size", 4);
  auto& maximum_indices_ = unpack(maximum_indices, "maximum_indices", 5);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( grad )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for embedding_bag_dense_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad, indices, offsets, offset2bag, bag_size, maximum_indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::embedding_bag_dense_backward, { grad, indices, offsets, offset2bag, bag_size, maximum_indices } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 6, "num_weights", num_weights);
      setposattr(trace_info.n, 7, "scale_grad_by_freq", scale_grad_by_freq);
      setposattr(trace_info.n, 8, "mode", mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_weights, num_weights);
      setattr(trace_info.n, jit::attr::scale_grad_by_freq, scale_grad_by_freq);
      setattr(trace_info.n, jit::attr::mode, mode);
    }
  }
  auto result = as_variable(baseType->embedding_bag_dense_backward(grad_, indices_, offsets_, offset2bag_, bag_size_, maximum_indices_, num_weights, scale_grad_by_freq, mode));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::empty(IntList size) const {
  profiler::RecordFunction profiler("empty");
  auto result = as_variable(baseType->empty(size));
  return result;
}
Tensor & VariableType::empty_out(Tensor & result, IntList size) const {
  profiler::RecordFunction profiler("empty_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::empty_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  Type::empty_out(result, size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::empty_like(const Tensor & self) const {
  profiler::RecordFunction profiler("empty_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::empty_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::empty_like(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::empty_like(const Tensor & self, const Type & dtype) const {
  profiler::RecordFunction profiler("empty_like");
  auto result = Type::empty_like(self, dtype);
  return result;
}
Tensor VariableType::erf(const Tensor & self) const {
  profiler::RecordFunction profiler("erf");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ErfBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ErfBackward>(new ErfBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::erf, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->erf(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::erf_(Tensor & self) const {
  profiler::RecordFunction profiler("erf_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ErfBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ErfBackward>(new ErfBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::erf, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->erf_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::erf_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("erf_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("erf");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("erf");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::erf_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->erf_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::exp(const Tensor & self) const {
  profiler::RecordFunction profiler("exp");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ExpBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ExpBackward>(new ExpBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::exp, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->exp(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::exp_(Tensor & self) const {
  profiler::RecordFunction profiler("exp_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ExpBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ExpBackward>(new ExpBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::exp, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->exp_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::exp_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("exp_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("exp");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("exp");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::exp_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->exp_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::expm1(const Tensor & self) const {
  profiler::RecordFunction profiler("expm1");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Expm1Backward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Expm1Backward>(new Expm1Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::expm1, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->expm1(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::expm1_(Tensor & self) const {
  profiler::RecordFunction profiler("expm1_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Expm1Backward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Expm1Backward>(new Expm1Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::expm1, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->expm1_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::expm1_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("expm1_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("expm1");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("expm1");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::expm1_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->expm1_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::expand(const Tensor & self, IntList size, bool implicit) const {
  profiler::RecordFunction profiler("expand");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ExpandBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ExpandBackward>(new ExpandBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::expand, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      setposattr(trace_info.n, 2, "implicit", implicit);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::implicit, implicit);
    }
  }
  auto result = as_view(self, baseType->expand(self_, size, implicit));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::expand_as(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("expand_as");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::expand_as, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::expand_as(self, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::eye(int64_t n, int64_t m) const {
  profiler::RecordFunction profiler("eye");
  auto result = as_variable(baseType->eye(n, m));
  return result;
}
Tensor & VariableType::eye_out(Tensor & result, int64_t n, int64_t m) const {
  profiler::RecordFunction profiler("eye_out");
  auto& result_ = unpack(result, "result", 0);
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::eye_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "n", n);
      setposattr(trace_info.n, 2, "m", m);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::n, n);
      setattr(trace_info.n, jit::attr::m, m);
    }
  }
  baseType->eye_out(result_, n, m);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor & VariableType::fill_(Tensor & self, Scalar value) const {
  profiler::RecordFunction profiler("fill_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<FillBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FillBackward0>(new FillBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fill, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "value", value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::value, value);
    }
  }
  baseType->fill_(self_, value);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::fill_(Tensor & self, const Tensor & value) const {
  profiler::RecordFunction profiler("fill_");
  auto& self_ = unpack(self, "self", 0);
  auto& value_ = unpack(value, "value", 1);
  check_inplace(self);
  std::shared_ptr<FillBackward1> grad_fn;
  if (compute_requires_grad( self, value )) {
    grad_fn = std::shared_ptr<FillBackward1>(new FillBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, value ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, value )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fill, { self, value } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->fill_(self_, value_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::floor(const Tensor & self) const {
  profiler::RecordFunction profiler("floor");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<FloorBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FloorBackward>(new FloorBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::floor, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->floor(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::floor_(Tensor & self) const {
  profiler::RecordFunction profiler("floor_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<FloorBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FloorBackward>(new FloorBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::floor, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->floor_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::floor_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("floor_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("floor");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("floor");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::floor_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->floor_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::full(IntList size, Scalar fill_value) const {
  profiler::RecordFunction profiler("full");
  auto result = as_variable(baseType->full(size, fill_value));
  return result;
}
Tensor & VariableType::full_out(Tensor & result, IntList size, Scalar fill_value) const {
  profiler::RecordFunction profiler("full_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::full_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      setposattr(trace_info.n, 2, "fill_value", fill_value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
      setattr(trace_info.n, jit::attr::fill_value, fill_value);
    }
  }
  Type::full_out(result, size, fill_value);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::full_like(const Tensor & self, Scalar fill_value) const {
  profiler::RecordFunction profiler("full_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::full_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "fill_value", fill_value);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::fill_value, fill_value);
    }
  }
  auto result = Type::full_like(self, fill_value);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::full_like(const Tensor & self, Scalar fill_value, const Type & dtype) const {
  profiler::RecordFunction profiler("full_like");
  auto result = Type::full_like(self, fill_value, dtype);
  return result;
}
Tensor VariableType::hinge_embedding_loss(const Tensor & self, const Tensor & target, double margin, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("hinge_embedding_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::hinge_embedding_loss, { self, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "margin", margin);
      setposattr(trace_info.n, 3, "size_average", size_average);
      setposattr(trace_info.n, 4, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto result = Type::hinge_embedding_loss(self, target, margin, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::ger(const Tensor & self, const Tensor & vec2) const {
  profiler::RecordFunction profiler("ger");
  auto& self_ = unpack(self, "self", 0);
  auto& vec2_ = unpack(vec2, "vec2", 1);
  std::shared_ptr<GerBackward> grad_fn;
  if (compute_requires_grad( self, vec2 )) {
    grad_fn = std::shared_ptr<GerBackward>(new GerBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, vec2 ));
    grad_fn->vec2_ = SavedVariable(vec2, false);
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ger, { self, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->ger(self_, vec2_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::ger_out(Tensor & result, const Tensor & self, const Tensor & vec2) const {
  profiler::RecordFunction profiler("ger_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& vec2_ = unpack(vec2, "vec2", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, vec2 )) {
    throw_error_out_requires_grad("ger");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("ger");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, vec2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ger_out, { result, self, vec2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->ger_out(result_, self_, vec2_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::gesv(const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("gesv");
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gesv, { self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(result0, result1) = Type::gesv(self, A);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
std::tuple<Tensor &,Tensor &> VariableType::gesv_out(Tensor & solution, Tensor & lu, const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("gesv_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( solution, lu, self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::gesv_out, { solution, lu, self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::gesv_out(solution, lu, self, A);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {solution, lu} );
  }
  return std::forward_as_tuple(solution, lu);
}
std::tuple<Tensor,Tensor> VariableType::_gesv_helper(const Tensor & self, const Tensor & A) const {
  profiler::RecordFunction profiler("_gesv_helper");
  auto& self_ = unpack(self, "self", 0);
  auto& A_ = unpack(A, "A", 1);
  std::shared_ptr<GesvHelperBackward> grad_fn;
  if (compute_requires_grad( self, A )) {
    grad_fn = std::shared_ptr<GesvHelperBackward>(new GesvHelperBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, A ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->A_ = SavedVariable(A, false);
  }
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, A )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_gesv_helper, { self, A } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(result0, result1) = as_variable(baseType->_gesv_helper(self_, A_));
  set_history(flatten( result0 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  if (grad_fn) {
    grad_fn->result0_ = SavedVariable(result0, true);
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
Tensor VariableType::group_norm(const Tensor & input, int64_t num_groups, const Tensor & weight, const Tensor & bias, double eps, bool cudnn_enabled) const {
  profiler::RecordFunction profiler("group_norm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::group_norm, { input, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "num_groups", num_groups);
      setposattr(trace_info.n, 4, "eps", eps);
      setposattr(trace_info.n, 5, "cudnn_enabled", cudnn_enabled);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::num_groups, num_groups);
      setattr(trace_info.n, jit::attr::eps, eps);
      setattr(trace_info.n, jit::attr::cudnn_enabled, cudnn_enabled);
    }
  }
  auto result = Type::group_norm(input, num_groups, weight, bias, eps, cudnn_enabled);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::fft(const Tensor & self, int64_t signal_ndim, bool normalized) const {
  profiler::RecordFunction profiler("fft");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::fft, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "signal_ndim", signal_ndim);
      setposattr(trace_info.n, 2, "normalized", normalized);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::signal_ndim, signal_ndim);
      setattr(trace_info.n, jit::attr::normalized, normalized);
    }
  }
  auto result = Type::fft(self, signal_ndim, normalized);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::ifft(const Tensor & self, int64_t signal_ndim, bool normalized) const {
  profiler::RecordFunction profiler("ifft");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ifft, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "signal_ndim", signal_ndim);
      setposattr(trace_info.n, 2, "normalized", normalized);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::signal_ndim, signal_ndim);
      setattr(trace_info.n, jit::attr::normalized, normalized);
    }
  }
  auto result = Type::ifft(self, signal_ndim, normalized);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::rfft(const Tensor & self, int64_t signal_ndim, bool normalized, bool onesided) const {
  profiler::RecordFunction profiler("rfft");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rfft, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "signal_ndim", signal_ndim);
      setposattr(trace_info.n, 2, "normalized", normalized);
      setposattr(trace_info.n, 3, "onesided", onesided);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::signal_ndim, signal_ndim);
      setattr(trace_info.n, jit::attr::normalized, normalized);
      setattr(trace_info.n, jit::attr::onesided, onesided);
    }
  }
  auto result = Type::rfft(self, signal_ndim, normalized, onesided);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::irfft(const Tensor & self, int64_t signal_ndim, bool normalized, bool onesided, IntList signal_sizes) const {
  profiler::RecordFunction profiler("irfft");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::irfft, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "signal_ndim", signal_ndim);
      setposattr(trace_info.n, 2, "normalized", normalized);
      setposattr(trace_info.n, 3, "onesided", onesided);
      setposattr(trace_info.n, 4, "signal_sizes", signal_sizes);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::signal_ndim, signal_ndim);
      setattr(trace_info.n, jit::attr::normalized, normalized);
      setattr(trace_info.n, jit::attr::onesided, onesided);
      setattr(trace_info.n, jit::attr::signal_sizes, signal_sizes);
    }
  }
  auto result = Type::irfft(self, signal_ndim, normalized, onesided, signal_sizes);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_fft_with_size(const Tensor & self, int64_t signal_ndim, bool complex_input, bool complex_output, bool inverse, IntList checked_signal_sizes, bool normalized, bool onesided, IntList output_sizes) const {
  profiler::RecordFunction profiler("_fft_with_size");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<FftWithSizeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<FftWithSizeBackward>(new FftWithSizeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->signal_ndim = signal_ndim;
    grad_fn->complex_input = complex_input;
    grad_fn->complex_output = complex_output;
    grad_fn->inverse = inverse;
    grad_fn->checked_signal_sizes = checked_signal_sizes;
    grad_fn->normalized = normalized;
    grad_fn->onesided = onesided;
    grad_fn->output_sizes = output_sizes;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_fft_with_size, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "signal_ndim", signal_ndim);
      setposattr(trace_info.n, 2, "complex_input", complex_input);
      setposattr(trace_info.n, 3, "complex_output", complex_output);
      setposattr(trace_info.n, 4, "inverse", inverse);
      setposattr(trace_info.n, 5, "checked_signal_sizes", checked_signal_sizes);
      setposattr(trace_info.n, 6, "normalized", normalized);
      setposattr(trace_info.n, 7, "onesided", onesided);
      setposattr(trace_info.n, 8, "output_sizes", output_sizes);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::signal_ndim, signal_ndim);
      setattr(trace_info.n, jit::attr::complex_input, complex_input);
      setattr(trace_info.n, jit::attr::complex_output, complex_output);
      setattr(trace_info.n, jit::attr::inverse, inverse);
      setattr(trace_info.n, jit::attr::checked_signal_sizes, checked_signal_sizes);
      setattr(trace_info.n, jit::attr::normalized, normalized);
      setattr(trace_info.n, jit::attr::onesided, onesided);
      setattr(trace_info.n, jit::attr::output_sizes, output_sizes);
    }
  }
  auto result = as_variable(baseType->_fft_with_size(self_, signal_ndim, complex_input, complex_output, inverse, checked_signal_sizes, normalized, onesided, output_sizes));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::index(const Tensor & self, TensorList indices) const {
  profiler::RecordFunction profiler("index");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index, flatten( self, indices ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::index(self, indices);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::index_copy_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) const {
  profiler::RecordFunction profiler("index_copy_");
  auto& self_ = unpack(self, "self", 0);
  auto& index_ = unpack(index, "index", 2);
  auto& source_ = unpack(source, "source", 3);
  check_inplace(self);
  std::shared_ptr<IndexCopyBackward> grad_fn;
  if (compute_requires_grad( self, source )) {
    grad_fn = std::shared_ptr<IndexCopyBackward>(new IndexCopyBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, source ));
    grad_fn->dim = dim;
    grad_fn->index_ = SavedVariable(index, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, index, source )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_copy, { self, index, source } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->index_copy_(self_, dim, index_, source_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::index_put_(Tensor & self, TensorList indices, const Tensor & values) const {
  profiler::RecordFunction profiler("index_put_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, indices, values )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::index_put, flatten( self, indices, values ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::index_put_(self, indices, values);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::isclose(const Tensor & self, const Tensor & other, double rtol, double atol, bool equal_nan) const {
  profiler::RecordFunction profiler("isclose");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::isclose, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "rtol", rtol);
      setposattr(trace_info.n, 3, "atol", atol);
      setposattr(trace_info.n, 4, "equal_nan", equal_nan);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::rtol, rtol);
      setattr(trace_info.n, jit::attr::atol, atol);
      setattr(trace_info.n, jit::attr::equal_nan, equal_nan);
    }
  }
  auto result = Type::isclose(self, other, rtol, atol, equal_nan);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
bool VariableType::is_cuda(const Tensor & self) const {
  auto result = Type::is_cuda(self);
  return result;
}
bool VariableType::is_distributed(const Tensor & self) const {
  auto result = Type::is_distributed(self);
  return result;
}
bool VariableType::is_floating_point(const Tensor & self) const {
  profiler::RecordFunction profiler("is_floating_point");
  auto result = Type::is_floating_point(self);
  return result;
}
bool VariableType::is_nonzero(const Tensor & self) const {
  profiler::RecordFunction profiler("is_nonzero");
  auto result = Type::is_nonzero(self);
  return result;
}
bool VariableType::is_same_size(const Tensor & self, const Tensor & other) const {
  auto result = Type::is_same_size(self, other);
  return result;
}
bool VariableType::is_signed(const Tensor & self) const {
  auto result = Type::is_signed(self);
  return result;
}
bool VariableType::is_sparse(const Tensor & self) const {
  auto result = Type::is_sparse(self);
  return result;
}
Tensor VariableType::layer_norm(const Tensor & input, IntList normalized_shape, const Tensor & weight, const Tensor & bias, double eps, bool cudnn_enable) const {
  profiler::RecordFunction profiler("layer_norm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::layer_norm, { input, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "normalized_shape", normalized_shape);
      setposattr(trace_info.n, 4, "eps", eps);
      setposattr(trace_info.n, 5, "cudnn_enable", cudnn_enable);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::normalized_shape, normalized_shape);
      setattr(trace_info.n, jit::attr::eps, eps);
      setattr(trace_info.n, jit::attr::cudnn_enable, cudnn_enable);
    }
  }
  auto result = Type::layer_norm(input, normalized_shape, weight, bias, eps, cudnn_enable);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::linspace(Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("linspace");
  auto result = as_variable(baseType->linspace(start, end, steps));
  return result;
}
Tensor & VariableType::linspace_out(Tensor & result, Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("linspace_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::linspace_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "steps", steps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::steps, steps);
    }
  }
  Type::linspace_out(result, start, end, steps);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::log(const Tensor & self) const {
  profiler::RecordFunction profiler("log");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LogBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogBackward>(new LogBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->log(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::log_(Tensor & self) const {
  profiler::RecordFunction profiler("log_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<LogBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogBackward>(new LogBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::log_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("log_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("log");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("log");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::log10(const Tensor & self) const {
  profiler::RecordFunction profiler("log10");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Log10Backward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Log10Backward>(new Log10Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log10, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->log10(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::log10_(Tensor & self) const {
  profiler::RecordFunction profiler("log10_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Log10Backward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Log10Backward>(new Log10Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log10, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log10_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::log10_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("log10_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("log10");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("log10");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log10_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log10_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::log1p(const Tensor & self) const {
  profiler::RecordFunction profiler("log1p");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Log1PBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Log1PBackward>(new Log1PBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log1p, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->log1p(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::log1p_(Tensor & self) const {
  profiler::RecordFunction profiler("log1p_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Log1PBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Log1PBackward>(new Log1PBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log1p, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log1p_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::log1p_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("log1p_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("log1p");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("log1p");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log1p_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log1p_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::log2(const Tensor & self) const {
  profiler::RecordFunction profiler("log2");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<Log2Backward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Log2Backward>(new Log2Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log2, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->log2(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::log2_(Tensor & self) const {
  profiler::RecordFunction profiler("log2_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<Log2Backward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<Log2Backward>(new Log2Backward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log2, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log2_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::log2_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("log2_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("log2");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("log2");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log2_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->log2_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::logdet(const Tensor & self) const {
  profiler::RecordFunction profiler("logdet");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LogdetBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogdetBackward>(new LogdetBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::logdet, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->logdet(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::logspace(Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("logspace");
  auto result = as_variable(baseType->logspace(start, end, steps));
  return result;
}
Tensor & VariableType::logspace_out(Tensor & result, Scalar start, Scalar end, int64_t steps) const {
  profiler::RecordFunction profiler("logspace_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::logspace_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "steps", steps);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::steps, steps);
    }
  }
  Type::logspace_out(result, start, end, steps);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::log_softmax(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("log_softmax");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LogSoftmaxBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogSoftmaxBackward>(new LogSoftmaxBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_softmax, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->log_softmax(self_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::log_softmax_backward_data(const Tensor & grad_output, const Tensor & output, int64_t dim, const Tensor & self) const {
  profiler::RecordFunction profiler("log_softmax_backward_data");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& output_ = unpack(output, "output", 1);
  auto& self_ = unpack(self, "self", 3);
  std::shared_ptr<LogSoftmaxBackwardDataBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<LogSoftmaxBackwardDataBackward>(new LogSoftmaxBackwardDataBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->output_ = SavedVariable(output, false);
    grad_fn->dim = dim;
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::log_softmax_backward_data, { grad_output, output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->log_softmax_backward_data(grad_output_, output_, dim, self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::logsumexp(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("logsumexp");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<LogsumexpBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<LogsumexpBackward>(new LogsumexpBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::logsumexp, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->logsumexp(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::logsumexp_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("logsumexp_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("logsumexp");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("logsumexp");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::logsumexp_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->logsumexp_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::margin_ranking_loss(const Tensor & input1, const Tensor & input2, const Tensor & target, double margin, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("margin_ranking_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input1, input2, target )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::margin_ranking_loss, { input1, input2, target } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "margin", margin);
      setposattr(trace_info.n, 4, "size_average", size_average);
      setposattr(trace_info.n, 5, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto result = Type::margin_ranking_loss(input1, input2, target, margin, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::matmul(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("matmul");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::matmul, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::matmul(self, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::matmul_out(Tensor & result, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("matmul_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::matmul_out, { result, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::matmul_out(result, self, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::max_values(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("max_values");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_values, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::max_values(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::max_pool1d(const Tensor & self, IntList kernel_size, IntList stride, IntList padding, IntList dilation, bool ceil_mode) const {
  profiler::RecordFunction profiler("max_pool1d");
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::max_pool1d, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "kernel_size", kernel_size);
      setposattr(trace_info.n, 2, "stride", stride);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "dilation", dilation);
      setposattr(trace_info.n, 5, "ceil_mode", ceil_mode);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::kernel_size, kernel_size);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::ceil_mode, ceil_mode);
    }
  }
  std::tie(result0, result1) = Type::max_pool1d(self, kernel_size, stride, padding, dilation, ceil_mode);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
Tensor VariableType::min_values(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("min_values");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::min_values, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::min_values(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::mkldnn_convolution(const Tensor & self, const Tensor & weight, const Tensor & bias, IntList padding, IntList stride, IntList dilation) const {
  profiler::RecordFunction profiler("mkldnn_convolution");
  auto& self_ = unpack(self, "self", 0);
  auto& weight_ = unpack(weight, "weight", 1);
  auto bias_ = unpack_opt(bias, "bias", 2);
  std::shared_ptr<MkldnnConvolutionBackward> grad_fn;
  if (compute_requires_grad( self, weight, bias )) {
    grad_fn = std::shared_ptr<MkldnnConvolutionBackward>(new MkldnnConvolutionBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, weight, bias ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->weight_ = SavedVariable(weight, false);
    grad_fn->padding = padding;
    grad_fn->stride = stride;
    grad_fn->dilation = dilation;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, weight, bias )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mkldnn_convolution, { self, weight, bias } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
    }
  }
  auto result = as_variable(baseType->mkldnn_convolution(self_, weight_, bias_, padding, stride, dilation));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::mkldnn_convolution_backward_input(IntList self_size, const Tensor & grad_output, const Tensor & weight, IntList padding, IntList stride, IntList dilation, bool bias_defined) const {
  profiler::RecordFunction profiler("mkldnn_convolution_backward_input");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mkldnn_convolution_backward_input, { grad_output, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "self_size", self_size);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "bias_defined", bias_defined);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::self_size, self_size);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::bias_defined, bias_defined);
    }
  }
  auto result = Type::mkldnn_convolution_backward_input(self_size, grad_output, weight, padding, stride, dilation, bias_defined);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::mkldnn_convolution_backward_weights(IntList weight_size, const Tensor & grad_output, const Tensor & self, IntList padding, IntList stride, IntList dilation, bool bias_defined) const {
  profiler::RecordFunction profiler("mkldnn_convolution_backward_weights");
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mkldnn_convolution_backward_weights, { grad_output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 0, "weight_size", weight_size);
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "bias_defined", bias_defined);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::weight_size, weight_size);
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::bias_defined, bias_defined);
    }
  }
  std::tie(result0, result1) = Type::mkldnn_convolution_backward_weights(weight_size, grad_output, self, padding, stride, dilation, bias_defined);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
std::tuple<Tensor,Tensor,Tensor> VariableType::mkldnn_convolution_backward(const Tensor & self, const Tensor & grad_output, const Tensor & weight, IntList padding, IntList stride, IntList dilation, std::array<bool,3> output_mask) const {
  profiler::RecordFunction profiler("mkldnn_convolution_backward");
  Tensor result0;
  Tensor result1;
  Tensor result2;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, grad_output, weight )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mkldnn_convolution_backward, { self, grad_output, weight } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "padding", padding);
      setposattr(trace_info.n, 4, "stride", stride);
      setposattr(trace_info.n, 5, "dilation", dilation);
      setposattr(trace_info.n, 6, "output_mask", output_mask);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::padding, padding);
      setattr(trace_info.n, jit::attr::stride, stride);
      setattr(trace_info.n, jit::attr::dilation, dilation);
      setattr(trace_info.n, jit::attr::output_mask, output_mask);
    }
  }
  std::tie(result0, result1, result2) = Type::mkldnn_convolution_backward(self, grad_output, weight, padding, stride, dilation, output_mask);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1, result2 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1), std::move(result2));
}
Tensor VariableType::mm(const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("mm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mm, { self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::mm(self, mat2);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::mm_out(Tensor & result, const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("mm_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mm_out, { result, self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::mm_out(result, self, mat2);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::mv(const Tensor & self, const Tensor & vec) const {
  profiler::RecordFunction profiler("mv");
  auto& self_ = unpack(self, "self", 0);
  auto& vec_ = unpack(vec, "vec", 1);
  std::shared_ptr<MvBackward> grad_fn;
  if (compute_requires_grad( self, vec )) {
    grad_fn = std::shared_ptr<MvBackward>(new MvBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, vec ));
    grad_fn->vec_ = SavedVariable(vec, false);
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mv, { self, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->mv(self_, vec_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::mv_out(Tensor & result, const Tensor & self, const Tensor & vec) const {
  profiler::RecordFunction profiler("mv_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& vec_ = unpack(vec, "vec", 2);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, vec )) {
    throw_error_out_requires_grad("mv");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("mv");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, vec )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::mv_out, { result, self, vec } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->mv_out(result_, self_, vec_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::narrow(const Tensor & self, int64_t dim, int64_t start, int64_t length) const {
  profiler::RecordFunction profiler("narrow");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::narrow, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "start", start);
      setposattr(trace_info.n, 3, "length", length);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::length, length);
    }
  }
  auto result = Type::narrow(self, dim, start, length);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::ones(IntList size) const {
  profiler::RecordFunction profiler("ones");
  auto result = as_variable(baseType->ones(size));
  return result;
}
Tensor & VariableType::ones_out(Tensor & result, IntList size) const {
  profiler::RecordFunction profiler("ones_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ones_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  Type::ones_out(result, size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::ones_like(const Tensor & self) const {
  profiler::RecordFunction profiler("ones_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::ones_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::ones_like(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::ones_like(const Tensor & self, const Type & dtype) const {
  profiler::RecordFunction profiler("ones_like");
  auto result = Type::ones_like(self, dtype);
  return result;
}
Tensor VariableType::pairwise_distance(const Tensor & x1, const Tensor & x2, double p, double eps, bool keepdim) const {
  profiler::RecordFunction profiler("pairwise_distance");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( x1, x2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pairwise_distance, { x1, x2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "p", p);
      setposattr(trace_info.n, 3, "eps", eps);
      setposattr(trace_info.n, 4, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::eps, eps);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::pairwise_distance(x1, x2, p, eps, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::permute(const Tensor & self, IntList dims) const {
  profiler::RecordFunction profiler("permute");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<PermuteBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PermuteBackward>(new PermuteBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dims = dims;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::permute, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dims", dims);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dims, dims);
    }
  }
  auto result = as_view(self, baseType->permute(self_, dims));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::pin_memory(const Tensor & self) const {
  profiler::RecordFunction profiler("pin_memory");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::pin_memory, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::pin_memory(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::rand(IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("rand");
  auto result = as_variable(baseType->rand(size, generator));
  return result;
}
Tensor & VariableType::rand_out(Tensor & result, IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("rand_out");
  Type::rand_out(result, size, generator);
  return result;
}
Tensor VariableType::rand_like(const Tensor & self) const {
  profiler::RecordFunction profiler("rand_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rand_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::rand_like(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::rand_like(const Tensor & self, const Type & dtype) const {
  profiler::RecordFunction profiler("rand_like");
  auto result = Type::rand_like(self, dtype);
  return result;
}
Tensor VariableType::randint(int64_t high, IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("randint");
  auto result = as_variable(baseType->randint(high, size, generator));
  return result;
}
Tensor VariableType::randint(int64_t low, int64_t high, IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("randint");
  auto result = as_variable(baseType->randint(low, high, size, generator));
  return result;
}
Tensor & VariableType::randint_out(Tensor & result, int64_t high, IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("randint_out");
  Type::randint_out(result, high, size, generator);
  return result;
}
Tensor & VariableType::randint_out(Tensor & result, int64_t low, int64_t high, IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("randint_out");
  Type::randint_out(result, low, high, size, generator);
  return result;
}
Tensor VariableType::randint_like(const Tensor & self, int64_t high) const {
  profiler::RecordFunction profiler("randint_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::randint_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "high", high);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::high, high);
    }
  }
  auto result = Type::randint_like(self, high);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::randint_like(const Tensor & self, int64_t low, int64_t high) const {
  profiler::RecordFunction profiler("randint_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::randint_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "low", low);
      setposattr(trace_info.n, 2, "high", high);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::low, low);
      setattr(trace_info.n, jit::attr::high, high);
    }
  }
  auto result = Type::randint_like(self, low, high);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::randint_like(const Tensor & self, int64_t high, const Type & dtype) const {
  profiler::RecordFunction profiler("randint_like");
  auto result = Type::randint_like(self, high, dtype);
  return result;
}
Tensor VariableType::randint_like(const Tensor & self, int64_t low, int64_t high, const Type & dtype) const {
  profiler::RecordFunction profiler("randint_like");
  auto result = Type::randint_like(self, low, high, dtype);
  return result;
}
Tensor VariableType::randn(IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("randn");
  auto result = as_variable(baseType->randn(size, generator));
  return result;
}
Tensor & VariableType::randn_out(Tensor & result, IntList size, Generator * generator) const {
  profiler::RecordFunction profiler("randn_out");
  Type::randn_out(result, size, generator);
  return result;
}
Tensor VariableType::randn_like(const Tensor & self) const {
  profiler::RecordFunction profiler("randn_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::randn_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::randn_like(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::randn_like(const Tensor & self, const Type & dtype) const {
  profiler::RecordFunction profiler("randn_like");
  auto result = Type::randn_like(self, dtype);
  return result;
}
Tensor VariableType::randperm(int64_t n, Generator * generator) const {
  profiler::RecordFunction profiler("randperm");
  auto result = as_variable(baseType->randperm(n, generator));
  return result;
}
Tensor & VariableType::randperm_out(Tensor & result, int64_t n, Generator * generator) const {
  profiler::RecordFunction profiler("randperm_out");
  Type::randperm_out(result, n, generator);
  return result;
}
Tensor VariableType::range(Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("range");
  auto result = as_variable(baseType->range(start, end, step));
  return result;
}
Tensor & VariableType::range_out(Tensor & result, Scalar start, Scalar end, Scalar step) const {
  profiler::RecordFunction profiler("range_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::range_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "start", start);
      setposattr(trace_info.n, 2, "end", end);
      setposattr(trace_info.n, 3, "step", step);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::step, step);
    }
  }
  Type::range_out(result, start, end, step);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::repeat(const Tensor & self, IntList repeats) const {
  profiler::RecordFunction profiler("repeat");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<RepeatBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RepeatBackward>(new RepeatBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->repeats = repeats;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::repeat, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "repeats", repeats);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::repeats, repeats);
    }
  }
  auto result = as_variable(baseType->repeat(self_, repeats));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::reshape(const Tensor & self, IntList shape) const {
  profiler::RecordFunction profiler("reshape");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::reshape, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "shape", shape);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::shape, shape);
    }
  }
  auto result = Type::reshape(self, shape);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::RoiPooling2d_forward(const Tensor & input, const Tensor & rois, int64_t pooledHeight, int64_t pooledWidth, double spatialScale) const {
  profiler::RecordFunction profiler("RoiPooling2d_forward");
  auto& input_ = unpack(input, "input", 0);
  auto& rois_ = unpack(rois, "rois", 1);
  check_no_requires_grad(rois, "rois");
  std::shared_ptr<Roipooling2DBackward> grad_fn;
  if (compute_requires_grad( input )) {
    grad_fn = std::shared_ptr<Roipooling2DBackward>(new Roipooling2DBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( input ));
    grad_fn->input_ = SavedVariable(input, false);
    grad_fn->rois_ = SavedVariable(rois, false);
    grad_fn->pooledHeight = pooledHeight;
    grad_fn->pooledWidth = pooledWidth;
    grad_fn->spatialScale = spatialScale;
  }
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, rois )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::RoiPooling2d_forward, { input, rois } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "pooledHeight", pooledHeight);
      setposattr(trace_info.n, 3, "pooledWidth", pooledWidth);
      setposattr(trace_info.n, 4, "spatialScale", spatialScale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pooledHeight, pooledHeight);
      setattr(trace_info.n, jit::attr::pooledWidth, pooledWidth);
      setattr(trace_info.n, jit::attr::spatialScale, spatialScale);
    }
  }
  std::tie(result0, result1) = as_variable(baseType->RoiPooling2d_forward(input_, rois_, pooledHeight, pooledWidth, spatialScale));
  set_history(flatten( result0 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  if (grad_fn) {
    grad_fn->result1_ = SavedVariable(result1, true);
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
Tensor VariableType::RoiPooling2d_backward(const Tensor & input, const Tensor & rois, int64_t pooledHeight, int64_t pooledWidth, double spatialScale, const Tensor & gradOutput, const Tensor & argmaxes) const {
  profiler::RecordFunction profiler("RoiPooling2d_backward");
  auto& input_ = unpack(input, "input", 0);
  auto& rois_ = unpack(rois, "rois", 1);
  auto& gradOutput_ = unpack(gradOutput, "gradOutput", 5);
  auto& argmaxes_ = unpack(argmaxes, "argmaxes", 6);
  std::shared_ptr<Error> grad_fn;
  if (compute_requires_grad( input, rois, gradOutput, argmaxes )) {
    grad_fn = std::shared_ptr<Error>(new Error("the derivative for RoiPooling2d_backward is not implemented"), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( input, rois, gradOutput, argmaxes ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( input, rois, gradOutput, argmaxes )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::RoiPooling2d_backward, { input, rois, gradOutput, argmaxes } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "pooledHeight", pooledHeight);
      setposattr(trace_info.n, 3, "pooledWidth", pooledWidth);
      setposattr(trace_info.n, 4, "spatialScale", spatialScale);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::pooledHeight, pooledHeight);
      setattr(trace_info.n, jit::attr::pooledWidth, pooledWidth);
      setattr(trace_info.n, jit::attr::spatialScale, spatialScale);
    }
  }
  auto result = as_variable(baseType->RoiPooling2d_backward(input_, rois_, pooledHeight, pooledWidth, spatialScale, gradOutput_, argmaxes_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::round(const Tensor & self) const {
  profiler::RecordFunction profiler("round");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<RoundBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RoundBackward>(new RoundBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::round, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->round(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::round_(Tensor & self) const {
  profiler::RecordFunction profiler("round_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RoundBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RoundBackward>(new RoundBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::round, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->round_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::round_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("round_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("round");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("round");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::round_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->round_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::rrelu(const Tensor & self, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu");
  auto result = Type::rrelu(self, lower, upper, training, generator);
  return result;
}
Tensor & VariableType::rrelu_(Tensor & self, Scalar lower, Scalar upper, bool training, Generator * generator) const {
  profiler::RecordFunction profiler("rrelu_");
  Type::rrelu_(self, lower, upper, training, generator);
  return self;
}
Tensor VariableType::relu(const Tensor & self) const {
  profiler::RecordFunction profiler("relu");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ReluBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReluBackward>(new ReluBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::relu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->relu(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::relu_(Tensor & self) const {
  profiler::RecordFunction profiler("relu_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<ReluBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ReluBackward>(new ReluBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::relu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->relu_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::rsqrt(const Tensor & self) const {
  profiler::RecordFunction profiler("rsqrt");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<RsqrtBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RsqrtBackward>(new RsqrtBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rsqrt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->rsqrt(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::rsqrt_(Tensor & self) const {
  profiler::RecordFunction profiler("rsqrt_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<RsqrtBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<RsqrtBackward>(new RsqrtBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rsqrt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->rsqrt_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::rsqrt_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("rsqrt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("rsqrt");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("rsqrt");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::rsqrt_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->rsqrt_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::select(const Tensor & self, int64_t dim, int64_t index) const {
  profiler::RecordFunction profiler("select");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::select, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "index", index);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::index, index);
    }
  }
  auto result = Type::select(self, dim, index);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::selu(const Tensor & self) const {
  profiler::RecordFunction profiler("selu");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::selu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::selu(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::selu_(Tensor & self) const {
  profiler::RecordFunction profiler("selu_");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::selu, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  Type::selu_(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::sin(const Tensor & self) const {
  profiler::RecordFunction profiler("sin");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SinBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SinBackward>(new SinBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->sin(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sin_(Tensor & self) const {
  profiler::RecordFunction profiler("sin_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SinBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SinBackward>(new SinBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sin, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sin_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::sin_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("sin_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sin");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sin");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sin_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sin_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::sinh(const Tensor & self) const {
  profiler::RecordFunction profiler("sinh");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SinhBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SinhBackward>(new SinhBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sinh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->sinh(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sinh_(Tensor & self) const {
  profiler::RecordFunction profiler("sinh_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SinhBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SinhBackward>(new SinhBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self.clone(), false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sinh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sinh_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::sinh_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("sinh_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sinh");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sinh");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sinh_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sinh_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
int64_t VariableType::size(const Tensor & self, int64_t dim) const {
  auto result = Type::size(self, dim);
  return result;
}
Tensor VariableType::slice(const Tensor & self, int64_t dim, int64_t start, int64_t end, int64_t step) const {
  profiler::RecordFunction profiler("slice");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::slice, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "start", start);
      setposattr(trace_info.n, 3, "end", end);
      setposattr(trace_info.n, 4, "step", step);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::start, start);
      setattr(trace_info.n, jit::attr::end, end);
      setattr(trace_info.n, jit::attr::step, step);
    }
  }
  auto result = Type::slice(self, dim, start, end, step);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::slogdet(const Tensor & self) const {
  profiler::RecordFunction profiler("slogdet");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SlogdetBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SlogdetBackward>(new SlogdetBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::slogdet, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  std::tie(result0, result1) = as_variable(baseType->slogdet(self_));
  set_history(flatten( result0, result1 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  if (grad_fn) {
    grad_fn->result0_ = SavedVariable(result0, true);
    grad_fn->result1_ = SavedVariable(result1, true);
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
Tensor VariableType::smm(const Tensor & self, const Tensor & mat2) const {
  profiler::RecordFunction profiler("smm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::smm, { self, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::smm(self, mat2);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::softmax(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("softmax");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SoftmaxBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SoftmaxBackward>(new SoftmaxBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softmax, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->softmax(self_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::softmax_backward_data(const Tensor & grad_output, const Tensor & output, int64_t dim, const Tensor & self) const {
  profiler::RecordFunction profiler("softmax_backward_data");
  auto& grad_output_ = unpack(grad_output, "grad_output", 0);
  auto& output_ = unpack(output, "output", 1);
  auto& self_ = unpack(self, "self", 3);
  std::shared_ptr<SoftmaxBackwardDataBackward> grad_fn;
  if (compute_requires_grad( grad_output, self )) {
    grad_fn = std::shared_ptr<SoftmaxBackwardDataBackward>(new SoftmaxBackwardDataBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( grad_output, self ));
    grad_fn->output_ = SavedVariable(output, false);
    grad_fn->dim = dim;
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->grad_output_ = SavedVariable(grad_output, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( grad_output, output, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::softmax_backward_data, { grad_output, output, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->softmax_backward_data(grad_output_, output_, dim, self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::vector<Tensor> VariableType::split(const Tensor & self, int64_t split_size, int64_t dim) const {
  profiler::RecordFunction profiler("split");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SplitBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SplitBackward>(new SplitBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->split_size = split_size;
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::split, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "split_size", split_size);
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::split_size, split_size);
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->split(self_, split_size, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  flatten(result) );
  }
  return result;
}
std::vector<Tensor> VariableType::split_with_sizes(const Tensor & self, IntList split_sizes, int64_t dim) const {
  profiler::RecordFunction profiler("split_with_sizes");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SplitWithSizesBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SplitWithSizesBackward>(new SplitWithSizesBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->split_sizes = split_sizes;
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::split_with_sizes, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "split_sizes", split_sizes);
      setposattr(trace_info.n, 2, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::split_sizes, split_sizes);
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_variable(baseType->split_with_sizes(self_, split_sizes, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  flatten(result) );
  }
  return result;
}
Tensor VariableType::squeeze(const Tensor & self) const {
  profiler::RecordFunction profiler("squeeze");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SqueezeBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SqueezeBackward0>(new SqueezeBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::squeeze, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_view(self, baseType->squeeze(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::squeeze(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("squeeze");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SqueezeBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SqueezeBackward1>(new SqueezeBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::squeeze, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_view(self, baseType->squeeze(self_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::squeeze_(Tensor & self) const {
  profiler::RecordFunction profiler("squeeze_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SqueezeBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SqueezeBackward0>(new SqueezeBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::squeeze, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->squeeze_(self_);
  increment_version(self);
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::squeeze_(Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("squeeze_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SqueezeBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SqueezeBackward1>(new SqueezeBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::squeeze, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->squeeze_(self_, dim);
  increment_version(self);
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::sspaddmm(const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("sspaddmm");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sspaddmm, { self, mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "beta", beta);
      setposattr(trace_info.n, 4, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  auto result = Type::sspaddmm(self, mat1, mat2, beta, alpha);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sspaddmm_out(Tensor & result, const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta, Scalar alpha) const {
  profiler::RecordFunction profiler("sspaddmm_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& mat1_ = unpack(mat1, "mat1", 2);
  auto& mat2_ = unpack(mat2, "mat2", 3);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self, mat1, mat2 )) {
    throw_error_out_requires_grad("sspaddmm");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sspaddmm");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self, mat1, mat2 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sspaddmm_out, { result, self, mat1, mat2 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 4, "beta", beta);
      setposattr(trace_info.n, 5, "alpha", alpha);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::beta, beta);
      setattr(trace_info.n, jit::attr::alpha, alpha);
    }
  }
  baseType->sspaddmm_out(result_, self_, mat1_, mat2_, beta, alpha);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::stack(TensorList tensors, int64_t dim) const {
  profiler::RecordFunction profiler("stack");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::stack, flatten( tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = Type::stack(tensors, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::stack_out(Tensor & result, TensorList tensors, int64_t dim) const {
  profiler::RecordFunction profiler("stack_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, tensors )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::stack_out, flatten( result, tensors ) );
    if (!jit::tracer::ArgumentStash::empty()) {
      throw std::runtime_error("Can't have size-dependent arguments to functions that "
                           "take variable number of tensor arguments");
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  Type::stack_out(result, tensors, dim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::stft(const Tensor & self, int64_t frame_length, int64_t hop, int64_t fft_size, bool normalized, bool onesided, const Tensor & window, int64_t pad_end) const {
  profiler::RecordFunction profiler("stft");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, window )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::stft, { self, window } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "frame_length", frame_length);
      setposattr(trace_info.n, 2, "hop", hop);
      setposattr(trace_info.n, 3, "fft_size", fft_size);
      setposattr(trace_info.n, 4, "normalized", normalized);
      setposattr(trace_info.n, 5, "onesided", onesided);
      setposattr(trace_info.n, 7, "pad_end", pad_end);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::frame_length, frame_length);
      setattr(trace_info.n, jit::attr::hop, hop);
      setattr(trace_info.n, jit::attr::fft_size, fft_size);
      setattr(trace_info.n, jit::attr::normalized, normalized);
      setattr(trace_info.n, jit::attr::onesided, onesided);
      setattr(trace_info.n, jit::attr::pad_end, pad_end);
    }
  }
  auto result = Type::stft(self, frame_length, hop, fft_size, normalized, onesided, window, pad_end);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
int64_t VariableType::stride(const Tensor & self, int64_t dim) const {
  auto result = Type::stride(self, dim);
  return result;
}
Tensor VariableType::sum(const Tensor & self, ScalarType dtype) const {
  profiler::RecordFunction profiler("sum");
  auto result = Type::sum(self, dtype);
  return result;
}
Tensor VariableType::sum(const Tensor & self) const {
  profiler::RecordFunction profiler("sum");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::sum(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_sum(const Tensor & self) const {
  profiler::RecordFunction profiler("_sum");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SumBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SumBackward0>(new SumBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_sum(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::sum(const Tensor & self, IntList dim, bool keepdim, ScalarType dtype) const {
  profiler::RecordFunction profiler("sum");
  auto result = Type::sum(self, dim, keepdim, dtype);
  return result;
}
Tensor VariableType::sum(const Tensor & self, IntList dim, bool keepdim) const {
  profiler::RecordFunction profiler("sum");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::sum(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::sum(const Tensor & self, IntList dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("sum");
  auto result = Type::sum(self, dim, dtype);
  return result;
}
Tensor VariableType::_sum(const Tensor & self, IntList dim, bool keepdim) const {
  profiler::RecordFunction profiler("_sum");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SumBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SumBackward1>(new SumBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sum, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->_sum(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::sum_out(Tensor & result, const Tensor & self, IntList dim, bool keepdim, ScalarType dtype) const {
  profiler::RecordFunction profiler("sum_out");
  Type::sum_out(result, self, dim, keepdim, dtype);
  return result;
}
Tensor & VariableType::sum_out(Tensor & result, const Tensor & self, IntList dim, bool keepdim) const {
  profiler::RecordFunction profiler("sum_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sum_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  Type::sum_out(result, self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor & VariableType::sum_out(Tensor & result, const Tensor & self, IntList dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("sum_out");
  Type::sum_out(result, self, dim, dtype);
  return result;
}
Tensor & VariableType::_sum_out(Tensor & result, const Tensor & self, IntList dim, bool keepdim) const {
  profiler::RecordFunction profiler("_sum_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_sum");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_sum");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sum_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->_sum_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor & VariableType::_sum_cuda_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_sum_cuda_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_sum_cuda");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_sum_cuda");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_sum_cuda_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->_sum_cuda_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::sqrt(const Tensor & self) const {
  profiler::RecordFunction profiler("sqrt");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<SqrtBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SqrtBackward>(new SqrtBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sqrt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->sqrt(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::sqrt_(Tensor & self) const {
  profiler::RecordFunction profiler("sqrt_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<SqrtBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<SqrtBackward>(new SqrtBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sqrt, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sqrt_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::sqrt_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("sqrt_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("sqrt");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("sqrt");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::sqrt_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->sqrt_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::prod(const Tensor & self, ScalarType dtype) const {
  profiler::RecordFunction profiler("prod");
  auto result = Type::prod(self, dtype);
  return result;
}
Tensor VariableType::prod(const Tensor & self) const {
  profiler::RecordFunction profiler("prod");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::prod(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_prod(const Tensor & self) const {
  profiler::RecordFunction profiler("_prod");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ProdBackward1> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ProdBackward1>(new ProdBackward1(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_prod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_prod(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::prod(const Tensor & self, int64_t dim, bool keepdim, ScalarType dtype) const {
  profiler::RecordFunction profiler("prod");
  auto result = Type::prod(self, dim, keepdim, dtype);
  return result;
}
Tensor VariableType::prod(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("prod");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = Type::prod(self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::prod(const Tensor & self, int64_t dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("prod");
  auto result = Type::prod(self, dim, dtype);
  return result;
}
Tensor VariableType::_prod(const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_prod");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<ProdBackward0> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<ProdBackward0>(new ProdBackward0(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
    grad_fn->dim = dim;
    grad_fn->keepdim = keepdim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_prod, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      setposattr(trace_info.n, 2, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  auto result = as_variable(baseType->_prod(self_, dim, keepdim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::prod_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim, ScalarType dtype) const {
  profiler::RecordFunction profiler("prod_out");
  Type::prod_out(result, self, dim, keepdim, dtype);
  return result;
}
Tensor & VariableType::prod_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("prod_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::prod_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  Type::prod_out(result, self, dim, keepdim);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor & VariableType::prod_out(Tensor & result, const Tensor & self, int64_t dim, ScalarType dtype) const {
  profiler::RecordFunction profiler("prod_out");
  Type::prod_out(result, self, dim, dtype);
  return result;
}
Tensor & VariableType::_prod_out(Tensor & result, const Tensor & self, int64_t dim, bool keepdim) const {
  profiler::RecordFunction profiler("_prod_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("_prod");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("_prod");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_prod_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 2, "dim", dim);
      setposattr(trace_info.n, 3, "keepdim", keepdim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
      setattr(trace_info.n, jit::attr::keepdim, keepdim);
    }
  }
  baseType->_prod_out(result_, self_, dim, keepdim);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::t(const Tensor & self) const {
  profiler::RecordFunction profiler("t");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TBackward>(new TBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::t, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_view(self, baseType->t(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::t_(Tensor & self) const {
  profiler::RecordFunction profiler("t_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TBackward>(new TBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::t, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->t_(self_);
  increment_version(self);
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::tan(const Tensor & self) const {
  profiler::RecordFunction profiler("tan");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TanBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TanBackward>(new TanBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tan, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->tan(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::tan_(Tensor & self) const {
  profiler::RecordFunction profiler("tan_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TanBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TanBackward>(new TanBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tan, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->tan_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::tan_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("tan_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("tan");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("tan");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tan_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->tan_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::tanh(const Tensor & self) const {
  profiler::RecordFunction profiler("tanh");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TanhBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TanhBackward>(new TanhBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tanh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->tanh(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor & VariableType::tanh_(Tensor & self) const {
  profiler::RecordFunction profiler("tanh_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TanhBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TanhBackward>(new TanhBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tanh, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->tanh_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(self, true);
  }
  return self;
}
Tensor & VariableType::tanh_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("tanh_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("tanh");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("tanh");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::tanh_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->tanh_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::transpose(const Tensor & self, int64_t dim0, int64_t dim1) const {
  profiler::RecordFunction profiler("transpose");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TransposeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TransposeBackward>(new TransposeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim0 = dim0;
    grad_fn->dim1 = dim1;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::transpose, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim0", dim0);
      setposattr(trace_info.n, 2, "dim1", dim1);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim0, dim0);
      setattr(trace_info.n, jit::attr::dim1, dim1);
    }
  }
  auto result = as_view(self, baseType->transpose(self_, dim0, dim1));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::transpose_(Tensor & self, int64_t dim0, int64_t dim1) const {
  profiler::RecordFunction profiler("transpose_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TransposeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TransposeBackward>(new TransposeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim0 = dim0;
    grad_fn->dim1 = dim1;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::transpose, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim0", dim0);
      setposattr(trace_info.n, 2, "dim1", dim1);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim0, dim0);
      setattr(trace_info.n, jit::attr::dim1, dim1);
    }
  }
  baseType->transpose_(self_, dim0, dim1);
  increment_version(self);
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::_trilinear(const Tensor & i1, const Tensor & i2, const Tensor & i3, IntList expand1, IntList expand2, IntList expand3, IntList sumdim, int64_t unroll_dim) const {
  profiler::RecordFunction profiler("_trilinear");
  auto& i1_ = unpack(i1, "i1", 0);
  auto& i2_ = unpack(i2, "i2", 1);
  auto& i3_ = unpack(i3, "i3", 2);
  std::shared_ptr<TrilinearBackward> grad_fn;
  if (compute_requires_grad( i1, i2, i3 )) {
    grad_fn = std::shared_ptr<TrilinearBackward>(new TrilinearBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( i1, i2, i3 ));
    grad_fn->i1_ = SavedVariable(i1, false);
    grad_fn->i2_ = SavedVariable(i2, false);
    grad_fn->i3_ = SavedVariable(i3, false);
    grad_fn->expand1 = expand1;
    grad_fn->expand2 = expand2;
    grad_fn->expand3 = expand3;
    grad_fn->sumdim = sumdim;
    grad_fn->unroll_dim = unroll_dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( i1, i2, i3 )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_trilinear, { i1, i2, i3 } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "expand1", expand1);
      setposattr(trace_info.n, 4, "expand2", expand2);
      setposattr(trace_info.n, 5, "expand3", expand3);
      setposattr(trace_info.n, 6, "sumdim", sumdim);
      setposattr(trace_info.n, 7, "unroll_dim", unroll_dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::expand1, expand1);
      setattr(trace_info.n, jit::attr::expand2, expand2);
      setattr(trace_info.n, jit::attr::expand3, expand3);
      setattr(trace_info.n, jit::attr::sumdim, sumdim);
      setattr(trace_info.n, jit::attr::unroll_dim, unroll_dim);
    }
  }
  auto result = as_variable(baseType->_trilinear(i1_, i2_, i3_, expand1, expand2, expand3, sumdim, unroll_dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::triplet_margin_loss(const Tensor & anchor, const Tensor & positive, const Tensor & negative, double margin, double p, double eps, bool swap, bool size_average, bool reduce) const {
  profiler::RecordFunction profiler("triplet_margin_loss");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( anchor, positive, negative )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::triplet_margin_loss, { anchor, positive, negative } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 3, "margin", margin);
      setposattr(trace_info.n, 4, "p", p);
      setposattr(trace_info.n, 5, "eps", eps);
      setposattr(trace_info.n, 6, "swap", swap);
      setposattr(trace_info.n, 7, "size_average", size_average);
      setposattr(trace_info.n, 8, "reduce", reduce);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::margin, margin);
      setattr(trace_info.n, jit::attr::p, p);
      setattr(trace_info.n, jit::attr::eps, eps);
      setattr(trace_info.n, jit::attr::swap, swap);
      setattr(trace_info.n, jit::attr::size_average, size_average);
      setattr(trace_info.n, jit::attr::reduce, reduce);
    }
  }
  auto result = Type::triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, size_average, reduce);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::trunc(const Tensor & self) const {
  profiler::RecordFunction profiler("trunc");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<TruncBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TruncBackward>(new TruncBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::trunc, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->trunc(self_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::trunc_(Tensor & self) const {
  profiler::RecordFunction profiler("trunc_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<TruncBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<TruncBackward>(new TruncBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::trunc, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->trunc_(self_);
  increment_version(self);
  rebase_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor & VariableType::trunc_out(Tensor & result, const Tensor & self) const {
  profiler::RecordFunction profiler("trunc_out");
  auto& result_ = unpack(result, "result", 0);
  auto& self_ = unpack(self, "self", 1);
  std::shared_ptr<Function> grad_fn;
  if (compute_requires_grad( self )) {
    throw_error_out_requires_grad("trunc");
  }
  if (compute_requires_grad( result )) {
    throw_error_out_requires_grad("trunc");
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result, self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::trunc_out, { result, self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  baseType->trunc_out(result_, self_);
  increment_version(result);
  rebase_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::type_as(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("type_as");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::type_as, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::type_as(self, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
std::tuple<Tensor,Tensor> VariableType::_unique(const Tensor & self, bool sorted, bool return_inverse) const {
  profiler::RecordFunction profiler("_unique");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UniqueBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UniqueBackward>(new UniqueBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  Tensor result0;
  Tensor result1;
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_unique, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "sorted", sorted);
      setposattr(trace_info.n, 2, "return_inverse", return_inverse);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::sorted, sorted);
      setattr(trace_info.n, jit::attr::return_inverse, return_inverse);
    }
  }
  std::tie(result0, result1) = as_variable(baseType->_unique(self_, sorted, return_inverse));
  set_history(flatten( result0, result1 ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result0, result1 } );
  }
  return std::make_tuple(std::move(result0), std::move(result1));
}
Tensor VariableType::_unsafe_view(const Tensor & self, IntList size) const {
  profiler::RecordFunction profiler("_unsafe_view");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UnsafeViewBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UnsafeViewBackward>(new UnsafeViewBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_sizes = self.sizes();
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_unsafe_view, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  auto result = as_variable(baseType->_unsafe_view(self_, size));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::unsqueeze(const Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("unsqueeze");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<UnsqueezeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UnsqueezeBackward>(new UnsqueezeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::unsqueeze, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  auto result = as_view(self, baseType->unsqueeze(self_, dim));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor & VariableType::unsqueeze_(Tensor & self, int64_t dim) const {
  profiler::RecordFunction profiler("unsqueeze_");
  auto& self_ = unpack(self, "self", 0);
  check_inplace(self);
  std::shared_ptr<UnsqueezeBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<UnsqueezeBackward>(new UnsqueezeBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->dim = dim;
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::unsqueeze, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "dim", dim);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::dim, dim);
    }
  }
  baseType->unsqueeze_(self_, dim);
  increment_version(self);
  set_history(flatten( self ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { self } );
  }
  return self;
}
Tensor VariableType::view_as(const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("view_as");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::view_as, { self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::view_as(self, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::where(const Tensor & condition, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("where");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( condition, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::where, { condition, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::where(condition, self, other);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_s_where(const Tensor & condition, const Tensor & self, const Tensor & other) const {
  profiler::RecordFunction profiler("_s_where");
  auto& condition_ = unpack(condition, "condition", 0);
  auto& self_ = unpack(self, "self", 1);
  auto& other_ = unpack(other, "other", 2);
  std::shared_ptr<SWhereBackward> grad_fn;
  if (compute_requires_grad( self, other )) {
    grad_fn = std::shared_ptr<SWhereBackward>(new SWhereBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self, other ));
    grad_fn->condition_ = SavedVariable(condition, false);
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( condition, self, other )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_s_where, { condition, self, other } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_s_where(condition_, self_, other_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::zeros(IntList size) const {
  profiler::RecordFunction profiler("zeros");
  auto result = as_variable(baseType->zeros(size));
  return result;
}
Tensor & VariableType::zeros_out(Tensor & result, IntList size) const {
  profiler::RecordFunction profiler("zeros_out");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( result )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::zeros_out, { result } );
    if (!jit::tracer::ArgumentStash::empty()) {
      setposattr(trace_info.n, 1, "size", size);
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
      setattr(trace_info.n, jit::attr::size, size);
    }
  }
  Type::zeros_out(result, size);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  {result} );
  }
  return result;
}
Tensor VariableType::zeros_like(const Tensor & self) const {
  profiler::RecordFunction profiler("zeros_like");
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::zeros_like, { self } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = Type::zeros_like(self);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::zeros_like(const Tensor & self, const Type & dtype) const {
  profiler::RecordFunction profiler("zeros_like");
  auto result = Type::zeros_like(self, dtype);
  return result;
}
Tensor VariableType::_standard_gamma_grad(const Tensor & self, const Tensor & output) const {
  profiler::RecordFunction profiler("_standard_gamma_grad");
  auto& self_ = unpack(self, "self", 0);
  auto& output_ = unpack(output, "output", 1);
  std::shared_ptr<StandardGammaGradBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<StandardGammaGradBackward>(new StandardGammaGradBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
  }
  jit::tracer::PreTraceInfo trace_info;
  if (jit::tracer::isTracing( self, output )) {
    trace_info = jit::tracer::preRecordTrace( jit::aten::_standard_gamma_grad, { self, output } );
    if (!jit::tracer::ArgumentStash::empty()) {
  
      TORCH_ASSERT(jit::tracer::ArgumentStash::empty());
    } else {
  
    }
  }
  auto result = as_variable(baseType->_standard_gamma_grad(self_, output_));
  set_history(flatten( result ), grad_fn);
  if (trace_info.state != nullptr) {
    jit::tracer::postRecordTrace( trace_info,  { result } );
  }
  return result;
}
Tensor VariableType::_standard_gamma(const Tensor & self, Generator * generator) const {
  profiler::RecordFunction profiler("_standard_gamma");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<StandardGammaBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<StandardGammaBackward>(new StandardGammaBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_ = SavedVariable(self, false);
  }
  auto result = as_variable(baseType->_standard_gamma(self_, generator));
  set_history(flatten( result ), grad_fn);
  if (grad_fn) {
    grad_fn->result_ = SavedVariable(result, true);
  }
  return result;
}
Tensor VariableType::poisson(const Tensor & self, Generator * generator) const {
  profiler::RecordFunction profiler("poisson");
  auto& self_ = unpack(self, "self", 0);
  std::shared_ptr<PoissonBackward> grad_fn;
  if (compute_requires_grad( self )) {
    grad_fn = std::shared_ptr<PoissonBackward>(new PoissonBackward(), deleteFunction);
    grad_fn->set_next_edges(collect_next_edges( self ));
    grad_fn->self_info = self;
  }
  auto result = as_variable(baseType->poisson(self_, generator));
  set_history(flatten( result ), grad_fn);
  return result;
}

}} // namespace torch::autograd
